{"meta":{"title":"phachon's blog","subtitle":"notes blog","description":"I am a free Goper/Phper","author":"phachon","url":"http://phachon.github.io"},"pages":[{"title":"开源项目","date":"2018-04-12T16:00:00.000Z","updated":"2022-07-11T01:59:03.333Z","comments":true,"path":"opensource/index.html","permalink":"http://phachon.github.io/opensource/index.html","excerpt":"","text":"以下是本人的一些开源项目, 欢迎 Star 或 Fork codepub 一个快速可持续的Git代码发布系统 MM-Wiki 一个轻量级的企业知识分享与团队协同软件，可用于快速构建企业 Wiki 和团队知识分享平台 go-logger 一个简单而强大的 golang 日志工具包 wmqx 一个基于 Rabbitmq 的 Http 消息推送服务 fasthttpsession 一个快速且强大的 fasthttp session 管理包 一些 html、bootstrap框架的后台模板集合"},{"title":"分类","date":"2022-07-11T01:59:03.327Z","updated":"2022-07-11T01:59:03.327Z","comments":false,"path":"categories/index.html","permalink":"http://phachon.github.io/categories/index.html","excerpt":"","text":""},{"title":"","date":"2022-07-11T01:59:03.318Z","updated":"2022-07-11T01:59:03.318Z","comments":true,"path":"404.html","permalink":"http://phachon.github.io/404.html","excerpt":"","text":""},{"title":"","date":"2022-07-11T01:59:03.327Z","updated":"2022-07-11T01:59:03.327Z","comments":true,"path":"about/index.html","permalink":"http://phachon.github.io/about/index.html","excerpt":"","text":"关于我Phper / Goper 喜欢开源，也喜欢写些博客总结一下，希望也能帮到你 联系方式 email: phachon@163.com github: https://github.com/phachon"},{"title":"标签","date":"2022-07-11T01:59:03.334Z","updated":"2022-07-11T01:59:03.334Z","comments":false,"path":"tags/index.html","permalink":"http://phachon.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Redis应用 - Redis BitMap 应用","slug":"redis/redis-app-bit","date":"2022-07-10T09:10:19.000Z","updated":"2022-07-11T01:59:03.325Z","comments":true,"path":"redis/redis-app-bit.html","link":"","permalink":"http://phachon.github.io/redis/redis-app-bit.html","excerpt":"","text":"参考资料：","categories":[{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://phachon.github.io/tags/redis/"}]},{"title":"Redis应用 - Redis 实现布隆过滤器","slug":"redis/redis-app-bloom","date":"2022-07-10T09:10:19.000Z","updated":"2022-07-11T01:59:03.325Z","comments":true,"path":"redis/redis-app-bloom.html","link":"","permalink":"http://phachon.github.io/redis/redis-app-bloom.html","excerpt":"","text":"参考资料：","categories":[{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://phachon.github.io/tags/redis/"}]},{"title":"Redis应用 - Redis 实现分布式锁","slug":"redis/redis-app-lock","date":"2022-07-10T09:10:19.000Z","updated":"2022-07-15T04:07:08.385Z","comments":true,"path":"redis/redis-app-lock.html","link":"","permalink":"http://phachon.github.io/redis/redis-app-lock.html","excerpt":"","text":"参考资料： 分布式锁的作用及实现 Redis实现分布式锁 php 聊聊分布式锁","categories":[{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://phachon.github.io/tags/redis/"}]},{"title":"Redis应用 - Redis 网络模型（单线程）","slug":"redis/redis-app-net","date":"2022-07-10T09:10:19.000Z","updated":"2022-07-11T01:59:03.326Z","comments":true,"path":"redis/redis-app-net.html","link":"","permalink":"http://phachon.github.io/redis/redis-app-net.html","excerpt":"","text":"参考资料： 为什么说Redis是单线程的以及Redis为什么这么快！","categories":[{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://phachon.github.io/tags/redis/"}]},{"title":"Redis应用 - Redis pipe","slug":"redis/redis-app-pipe","date":"2022-07-10T09:10:19.000Z","updated":"2022-07-11T01:59:03.326Z","comments":true,"path":"redis/redis-app-pipe.html","link":"","permalink":"http://phachon.github.io/redis/redis-app-pipe.html","excerpt":"","text":"参考资料：","categories":[{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://phachon.github.io/tags/redis/"}]},{"title":"Redis应用 - Redis 消息队列实现","slug":"redis/redis-app-queue","date":"2022-07-10T09:10:19.000Z","updated":"2022-07-11T01:59:03.326Z","comments":true,"path":"redis/redis-app-queue.html","link":"","permalink":"http://phachon.github.io/redis/redis-app-queue.html","excerpt":"","text":"参考资料：","categories":[{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://phachon.github.io/tags/redis/"}]},{"title":"Redis应用 - Redis 防止雪崩和穿透","slug":"redis/redis-app-xb","date":"2022-07-10T00:10:19.000Z","updated":"2022-07-11T01:59:03.326Z","comments":true,"path":"redis/redis-app-xb.html","link":"","permalink":"http://phachon.github.io/redis/redis-app-xb.html","excerpt":"","text":"参考资料： Redis架构之防雪崩设计","categories":[{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://phachon.github.io/tags/redis/"}]},{"title":"Go 应用之 - LocalCache本地缓存库分析","slug":"go/go-app-cache","date":"2022-07-09T16:00:00.000Z","updated":"2022-07-11T01:59:03.319Z","comments":true,"path":"go/go-app-cache.html","link":"","permalink":"http://phachon.github.io/go/go-app-cache.html","excerpt":"","text":"","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"Go 性能优化系列 - 优化案例总结","slug":"go/go-pprof-1","date":"2022-07-09T16:00:00.000Z","updated":"2022-07-11T01:59:03.320Z","comments":true,"path":"go/go-pprof-1.html","link":"","permalink":"http://phachon.github.io/go/go-pprof-1.html","excerpt":"","text":"最近看了不少 Go 性能优化的案例，相关文章总结在此，为后续优化总结经验 聊聊Go内存优化和相关底层机制 Go内存泄漏？不是那么简单! Go程序的问题诊断和性能调优指南 Go程序GC优化经验分享 go pprof 性能分析 Go 应用内存占用太多，让排查？ Go语言的GC优化技巧","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"【转载】在 Go 中恰到好处的内存对齐","slug":"go/go-mem-align","date":"2022-07-08T16:00:00.000Z","updated":"2022-07-11T01:59:03.320Z","comments":true,"path":"go/go-mem-align.html","link":"","permalink":"http://phachon.github.io/go/go-mem-align.html","excerpt":"","text":"本文转载自：https://mp.weixin.qq.com/s/OUY5T8_o7mS5jB386WWWfA","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"【翻译】高性能 GO 服务的内存优化","slug":"go/go-mem-leak","date":"2022-07-08T16:00:00.000Z","updated":"2022-07-11T01:59:03.320Z","comments":true,"path":"go/go-mem-leak.html","link":"","permalink":"http://phachon.github.io/go/go-mem-leak.html","excerpt":"本文转载：https://www.freesion.com/article/7060589908/ 作者：达菲格；来源：简书 原文地址: Allocation Efficiency in High-Performance Go Services 关于工具我们的第一个建议就是: 不要过早优化。Go 提供了很棒的性能调优工具可以直接指出代码上哪里消耗了大量内存。没必要重复造轮子，建议读者阅读下 Go 官方博客上的这篇很赞的文章；里面会一步步教你使用 pprof 对 CPU 和内存进行调优。在 Segment 我们也是用这些工具去找到项目的性能瓶颈的。 用数据来驱动优化。","text":"本文转载：https://www.freesion.com/article/7060589908/ 作者：达菲格；来源：简书 原文地址: Allocation Efficiency in High-Performance Go Services 关于工具我们的第一个建议就是: 不要过早优化。Go 提供了很棒的性能调优工具可以直接指出代码上哪里消耗了大量内存。没必要重复造轮子，建议读者阅读下 Go 官方博客上的这篇很赞的文章；里面会一步步教你使用 pprof 对 CPU 和内存进行调优。在 Segment 我们也是用这些工具去找到项目的性能瓶颈的。 用数据来驱动优化。 逃逸分析Go 可以自动的管理内存，这帮我们避免了大量潜在 bug，但它并没有将程序员彻底的从内存分配的事情上解脱出来。因为 Go 没有提供直接操作内存的方式，所以开发者必须要搞懂其内部机制，这样才能将收益最大化。 如果读了这篇文章后，你只能记住一点，那请记住这个：栈分配廉价，堆分配昂贵。现在让我们深入讲述下这是什么意思。 Go 有两个地方可以分配内存：一个全局堆空间用来动态分配内存，另一个是每个 goroutine 都有的自身栈空间。Go 更倾向于在栈空间上分配内存 —— 一个 Go 程序大部分的内存分配都是在栈空间上的。它的代价很低，因为只需要两个 CPU 指令：一个是把数据 push 到栈空间上以完成分配，另一个是从栈空间上释放。 不幸的是, 不是所有的内存都可以在栈空间上分配的。栈空间分配要求一个变量的生命周期和内存足迹能在编译时确定。否则就需要在运行时在堆空间上进行动态分配。 malloc 必须找到一块足够大的内存来存放新的变量数据。后续释放时，垃圾回收器扫描堆空间寻找不再被使用的对象。不用多说，这明显要比只需两个指令的栈分配更加昂贵。 译者注: 内存足迹, 代表和一个变量相关的所有内存块。比如一个 struct 中含有成员 int, 那么这个 int 所指向的内存块属于该 struct 的足迹。 编译器使用逃逸分析的技术来在这两者间做选择。基本的思路就是在编译时做垃圾回收的工作。编译器会追踪变量在代码块上的作用域。变量会携带有一组校验数据，用来证明它的整个生命周期是否在运行时完全可知。如果变量通过了这些校验，它就可以在栈上分配。否则就说它 逃逸 了，必须在堆上分配。 逃逸分析的机制，并没有在 Go 语言官方说明上阐述。对 Go 程序员来说，学习这些规则最有效的方式就是凭经验。编译命令 go build -gcflags ‘-m’ 会让编译器在编译时输出逃逸分析的结果。让我们来看一个例子： 12345678package mainimport &quot;fmt&quot;func main() &#123; x := 42 fmt.Println(x)&#125; 1234go build -gcflags &#x27;-m&#x27; ./main.go# command-line-arguments./main.go:7: x escapes to heap./main.go:7: main ... argument does not escape 我们看到 x escapes to heap , 表示它会在运行时在堆空间上动态分配。这个例子让人有些费解，直觉上，很明显变量 x 并没有逃出 main() 函数之外。编译器没有说明它为什么认为这个变量逃逸了。为得到更详细的内容，多传几个 -m 参数给编译器，会打印出更详细的内容。 12345678go build -gcflags &#x27;-m -m&#x27; ./main.go# command-line-arguments./main.go:5: cannot inline main: non-leaf function./main.go:7: x escapes to heap./main.go:7: from ... argument (arg to ...) at ./main.go:7./main.go:7: from *(... argument) (indirection) at ./main.go:7./main.go:7: from ... argument (passed to call[argument content escapes]) at ./main.go:7./main.go:7: main ... argument does not escape 是的，上面显示了，变量 x 之所以逃逸了，是因为它被传入了一个逃逸的函数内。 这个机制乍看上去有些难以捉摸，但多用几次这个工具后，就能搞明白这其中的规律了。长话短说，下面是一些我们找到的，能引起变量逃逸到堆上的典型情况： 1、发送指针或带有指针的值到 channel 中。在编译时，是没有办法知道哪个 goroutine 会在 channel 上接收数据。所以编译器没法知道变量什么时候才会被释放。 2、在一个切片上存储指针或带指针的值。一个典型的例子就是 []*string 。这会导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上。 3、slice 的背后数组被重新分配了，因为 append 时可能会超出其容量( cap )。slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。 4、在 interface 类型上调用方法。在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。想像一个 io.Reader 类型的变量 r , 调用 r.Read(b) 会使得 r 的值和切片 b 的背后存储都逃逸掉，所以会在堆上分配。 以我们的经验，这四点是 Go 程序中最常见的导致堆分配的原因。幸运的是，是有解决办法的！下面我们深入几个具体例子说明，如何定位线上系统的内存性能问题。 关于指针一个经验是：指针指向的数据都是在堆上分配的。因此，在程序中减少指针的运用可以减少堆分配。这不是绝对的，但是我们发现这是在实际问题中最常见的问题。 一般情况下我们会这样认为：“值的拷贝是昂贵的，所以用一个指针来代替。”但是，在很多情况下，直接的值拷贝要比使用指针廉价的多。你可能要问为什么。 1、编译器会在解除指针时做检查。目的是在指针是 nil 的情况下直接 panic() 以避免内存泄露。这就必须在运行时执行更多的代码。如果数据是按值传递的，那就不需要做这些了，它不可能是 nil 2、指针通常有糟糕的局部引用。一个函数内部的所有值都会在栈空间上分配。局部引用是编写高效代码的重要环节。它会使得变量数据在 CPU Cache(cpu 的一级二级缓存) 中的热度更高，进而减少指令预取时 Cache 不命中的的几率。 3、在 Cache 层拷贝一堆对象，可粗略地认为和拷贝一个指针效率是一样的。CPU 在各 Cache 层和主内存中以固定大小的 cache 进行内存移动。x86 机器上是 64 字节。而且，Go 使用了Duff’s device 技术来使得常规内存操作变得更高效。 指针应该主要被用来做映射数据的所有权和可变性的。实际项目中，用指针来避免拷贝的方式应该尽量少用。不要掉进过早优化的陷阱。养成一个按值传递的习惯，只在需要的时候用指针传递。另一个好处就是可以较少 nil 带来的安全问题。减少程序中指针的使用的另一个好处是，如果可以证明它里面没有指针，垃圾回收器会直接越过这块内存。例如，一块作为 []byte 背后存储的堆上内存，是不需要进行扫描的。对于那些不包含指针的数组和 struct 数据类型也是一样的。 译者注: 垃圾回收器回收一个变量时，要检查该类型里是否有指针。如果有，要检查指针所指向的内存是否可被回收，进而才能决定这个变量能否被回收。如此递归下去。如果被回收的变量里面没有指针, 就不需要进去递归扫描了，直接回收掉就行。 减少指针的使用不仅可以降低垃圾回收的工作量，它会产生对 cache 更加友好的代码。读内存是要把数据从主内存读到 CPU 的 cache 中。Cache 的空间是有限的，所以其他的数据必须被抹掉，好腾出空间。被抹掉的数据很可能程序的另外一部分相关。由此产生的 cache 抖动会引起线上服务的一些意外的和突然的抖动。 还是关于指针减少指针的使用就意味着要深入我们自定义的数据类型。我们的一个服务，用带有一组数据结构的循环 buffer 构建了一个失败操作的队列好做重试；它大致是这个样子： 12345678910type retryQueue struct &#123; buckets [][]retryItem // each bucket represents a 1 second interval currentTime time.Time currentOffset int&#125; type retryItem struct &#123; id ksuid.KSUID // ID of the item to retry time time.Time // exact time at which the item has to be retried&#125; buckets 中外面的数组大小是固定的, 但是 []retryItem 中 item 的数量是在运行时变化的。重试次数越多, 切片增长的越大。 挖掘一下 retryItem 的具体实现，我们发现 KSUID 是 [20]byte 的别名, 里面没有指针，所以可以排除。 currentOffset 是一个 int 类型, 也是固定长度的，故也可排除。接下来，看一下 time.Time 的实现: 12345type Time struct &#123; sec int64 nsec int32 loc *Location // pointer to the time zone structure&#125; time.Time 的结构体中包含了一个指针成员 loc 。在 retryItem 中使用它会导致 GC 每次经过堆上的这块区域时。都要去追踪到结构体里面的指针。 我们发现，这个案例很典型。 在正常运行期间失败情况很少。 只有少量内存用于存储重试操作。 当失败突然飙升时，重试队列中的对象数量每秒增长好几千，从而对垃圾回收器增加很多压力。 在这种情况下， time.Time 中的时区信息不是必要的。这些保存在内存中的时间截从来不会被序列化。所以可以重写这个数据结构来避免这种情况: 12345678910111213141516type retryItem struct &#123; id ksuid.KSUID nsec uint32 sec int64&#125;func (item *retryItem) time() time.Time &#123; return time.Unix(item.sec, int64(item.nsec))&#125;func makeRetryItem(id ksuid.KSUID, time time.Time) retryItem &#123; return retryItem&#123; id: id, nsec: uint32(time.Nanosecond()), sec: time.Unix(),&#125; 注意现在的 retryItem 不包含任何指针。这大大降低了 gc 压力，因为 retryItem 的整个足迹都可以在编译时知道。 传递 SLICE切片是造成低效内存分配行为的狂热区域。除非切片的大小在编译时就能知道，否则切片背后的数组(map也一样)会在堆上分配。让我们来讲几个方法，让切片在栈上分配而不是在堆上。 一个重度依赖于 MySQL 的项目。整个项目的性能严重依赖 MySQL 客户端驱动的性能。使用 pprof 对内存分配进行分析后，我们发现 MySQL driver 中序列化 time.Time 的那段代码非常低效。 性能分析器显示了堆上分配的内存有很大比例都是用来序列化 time.Time 的，所以才导致了 MySQL driver 低效。 这段低效的代码就是调用了 time.Time 的 Format() 方法, 它返回一个 string 。等等，我们不是在讨论切片嘛？好吧，根据 Go 官方的博客，一个 string 实际就是一个只读的 []byte ，只是语言上在语法上多了点支持。在内存分配上规则都是一样的。 分析结果告诉我们 12.38% 的内存分配都是 Format() 引起的， Format() 都做了什么？ 它表示使用标准库还有更高效的方式来达到通样的效果。但是 Format() 用起来很方便，使用 AppendFormat() 在内存分配上更友好。剖析下 time 包的源码，我们发现里面都是使用 AppendFormat() 而不是 Format() 。这更说明了 AppendFormat() 可以带来更高的性能。 实际上， Format() 函数只是对 AppendFormat() 的一层封装。 12345678910111213func (t Time) Format(layout string) string &#123; const bufSize = 64 var b []byte max := len(layout) + 10 if max &lt; bufSize &#123; var buf [bufSize]byte b = buf[:0] &#125; else &#123; b = make([]byte, 0, max) &#125; b = t.AppendFormat(b, layout) return string(b)&#125; 更重要的是， AppendFormat() 给程序员留了更多的优化空间。它需要传入一个切片进行存储，而不是直接返回一个 string 。使用 AppendFormat() 代替 Format() 可以用固定大小的内存空间来完成同样的事，而且这些操作是在栈空间完成的。 Interface 类型众所周知的，在 Interface 类型上调用方法要比直接在 Struct 上调用方法效率低。在 interface 类型上调用方法是动态调度的。这就极大的限制了编译器确定运行时代码执行方式的能力。到目前为止我们已经大量的讨论了，调整代码好让编译器能在编译时更好的理解你的代码行为。但 interface 类型会让这一切都白做。 不幸的是，interface 类型还是一个非常有用的抽象方式 —— 它能让我们写出扩展性更高的代码。interface 的一个普遍应用场景是标准库里的 hash 包中的哈希函数。 hash 包定义了通用的接口，然后提供了几个具体的实现。让我们看几个例子： 123456789101112131415161718package mainimport ( &quot;fmt&quot; &quot;hash/fnv&quot;)func hashIt(in string) uint64 &#123; h := fnv.New64a() h.Write([]byte(in)) out := h.Sum64() return out&#125;func main() &#123; s := &quot;hello&quot; fmt.Printf(&quot;The FNV64a hash of &#x27;%v&#x27; is &#x27;%v&#x27;\\n&quot;, s, hashIt(s))&#125; 编译上段代码，加上逃逸分析参数，会有以下输出： 123456789./foo1.go:9:17: inlining call to fnv.New64a./foo1.go:10:16: ([]byte)(in) escapes to heap./foo1.go:9:17: hash.Hash64(&amp;fnv.s·2) escapes to heap./foo1.go:9:17: &amp;fnv.s·2 escapes to heap./foo1.go:9:17: moved to heap: fnv.s·2./foo1.go:8:24: hashIt in does not escape./foo1.go:17:13: s escapes to heap./foo1.go:17:59: hashIt(s) escapes to heap./foo1.go:17:12: main ... argument does not escape 这说明了， hash 对象，输入字符串，和 []byte 都会逃逸到堆上。人肉眼看上去很明显这些数据根本没有逃逸，但是 interface 类型限制了编译器的功能。没有办法不进入 hash 的 interface 结构而安全的调用其具体实现。所以碰到这种情况，除非自己手动实现一个不使用 interface 的库，没什么好办法。 一个小把戏最后一点要比实际情况更搞笑。但是，它能让我们对编译器的逃逸分析机制有更深刻的理解。当通过阅读标准库源码来解决性能问题时，我们看到了下面这样的代码: 1234func noescape(p unsafe.Pointer) unsafe.Pointer &#123; x := uintptr(p) return unsafe.Pointer(x ^ 0)&#125; 这个函数会把指针参数从编译器的逃逸分析中隐藏掉。这意味着什么呢？让我们来举个例子看下。 1234567891011121314151617181920212223242526272829303132333435363738394041package mainimport ( &quot;unsafe&quot;)type Foo struct &#123; S *string&#125;func (f *Foo) String() string &#123; return *f.S&#125;type FooTrick struct &#123; S unsafe.Pointer&#125;func (f *FooTrick) String() string &#123; return *(*string)(f.S)&#125;func NewFoo(s string) Foo &#123; return Foo&#123;S: &amp;s&#125;&#125;func NewFooTrick(s string) FooTrick &#123; return FooTrick&#123;S: noescape(unsafe.Pointer(&amp;s))&#125;&#125;func noescape(p unsafe.Pointer) unsafe.Pointer &#123; x := uintptr(p) return unsafe.Pointer(x ^ 0)&#125;func main() &#123; s := &quot;hello&quot; f1 := NewFoo(s) f2 := NewFooTrick(s) s1 := f1.String() s2 := f2.String()&#125; 上段代码对同样的功能有两种实现：他们包含一个 string ，然后用 String() 函数返回这个字符串。但是编译器的逃逸分析输出表名了 FooTrick 版本没有逃逸。 123456789./foo3.go:24:16: &amp;s escapes to heap./foo3.go:23:23: moved to heap: s./foo3.go:27:28: NewFooTrick s does not escape./foo3.go:28:45: NewFooTrick &amp;s does not escape./foo3.go:31:33: noescape p does not escape./foo3.go:38:14: main &amp;s does not escape./foo3.go:39:19: main &amp;s does not escape./foo3.go:40:17: main f1 does not escape./foo3.go:41:17: main f2 does not escape 关键在这两行 12./foo3.go:24:16: &amp;s escapes to heap./foo3.go:23:23: moved to heap: s 编译器识别出了 NewFoo() 函数引用了字符串并将其存储在结构体中，导致了逃逸。但是， NewFooTrick() 却没有这样的输出。如果把调用 noescape() 的代码删掉，就会出现逃逸的情况。到底发生了什么？ 1234func noescape(p unsafe.Pointer) unsafe.Pointer &#123; x := uintptr(p) return unsafe.Pointer(x ^ 0)&#125; noescape() 函数遮蔽了输入和输出的依赖关系。编译器不认为 p 会通过 x 逃逸， 因为 uintptr() 产生的引用是编译器无法理解的。内置的 uintptr 类型让人相信这是一个真正的指针类型，但是在编译器层面，它只是一个足够存储一个 point 的 int 类型。代码的最后一行返回 unsafe.Pointer 也是一个 int。 noescape() 在 runtime 包中使用 unsafe.Pointer 的地方被大量使用。如果作者清楚被 unsafe.Pointer 引用的数据肯定不会被逃逸，但编译器却不知道的情况下，这是很有用的。 但是请记住，我们强烈不建议使用这种技术。这就是为什么包的名字叫做 unsafe 而且源码中包含了 USE CAREFULLY! 注释的原因。 小贴士1、不要过早优化，用数据来驱动我们的优化工作。2、栈空间分配是廉价的，堆空间分配是昂贵的。3、了解逃逸机制可以让我们写出更高效的代码。4、指针的使用会导致栈分配更不可行。5、找到在低效代码块中提供分配控制的 api。6、在调用频繁的地方慎用 interface。 参考：https://www.freesion.com/article/7060589908/","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"Go 应用之 - go 问题总结","slug":"go/go-qa","date":"2022-07-08T16:00:00.000Z","updated":"2022-07-11T01:59:03.320Z","comments":true,"path":"go/go-qa.html","link":"","permalink":"http://phachon.github.io/go/go-qa.html","excerpt":"","text":"Go 语言问题集","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/tags/Go/"}]},{"title":"Go 数据结构之 - channel","slug":"go/go-struct-channel","date":"2022-07-08T16:00:00.000Z","updated":"2022-07-25T14:14:58.772Z","comments":true,"path":"go/go-struct-channel.html","link":"","permalink":"http://phachon.github.io/go/go-struct-channel.html","excerpt":"","text":"channel 是 Goroutine 之间实现通信的数据核心数据结构，channel 是支撑 Go 语言高性能并发编程模型的重要结构，我们简单介绍下 channel 的设计原理、数据结构和常见操作。 设计原理Go 语言的并发模型是通信顺序进程（Communicating sequential processes，CSP），Goroutine 和 Channel 分别对应 CSP 中的实体和传递信息的媒介，Goroutine 之间会通过 Channel 来传递数据。 数据结构Channel 操作并发参考资料： Golang并发：再也不愁选channel还是选锁 Channel","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"Go 数据结构之 - interface","slug":"go/go-struct-interface","date":"2022-07-08T16:00:00.000Z","updated":"2022-07-20T04:12:46.298Z","comments":true,"path":"go/go-struct-interface.html","link":"","permalink":"http://phachon.github.io/go/go-struct-interface.html","excerpt":"interface 是 go 语言中非常重要的数据结构之一，利用 interface 我们可以实现类似面向对象的语言里的继承和封装的思想（go 语言里叫组合），同时对于复杂业务场景下，类型无法确定，经常需要定义一个能覆盖多种类型的变量，这个时候需要定义成 interface","text":"interface 是 go 语言中非常重要的数据结构之一，利用 interface 我们可以实现类似面向对象的语言里的继承和封装的思想（go 语言里叫组合），同时对于复杂业务场景下，类型无法确定，经常需要定义一个能覆盖多种类型的变量，这个时候需要定义成 interface 数据类型接口也是 Go 语言中的一种类型，它能够出现在变量的定义、函数的入参和返回值中并对它们进行约束，不过 Go 语言中有两种略微不同的接口，一种是带有一组方法的接口，另一种是不带任何方法的 interface{} 带方法的接口interface 作为 任意类型的变量数据结构Go 语言根据接口类型是否包含一组方法将接口类型分成了两类： 使用 runtime.iface 结构体表示包含方法的接口 使用 runtime.eface 结构体表示不包含任何方法的 interface{} 类型； 类型结构体用于表示接口的结构体是 runtime.iface，这个结构体中有指向原始数据的指针 data，不过更重要的是 runtime.itab 类型的 tab 字段。1234type iface struct &#123; // 16 字节 tab *itab data unsafe.Pointer&#125; 任意变量结构体runtime.eface 结构体在 Go 语言中的定义是这样的：1234type eface struct &#123; // 16 字节 _type *_type data unsafe.Pointer&#125;由于 interface{} 类型不包含任何方法，所以它的结构也相对来说比较简单，只包含指向底层数据和类型的两个指针。从上述结构我们也能推断出 — Go 语言的任意类型都可以转换成 interface{} 类型转换类型断言参考资料 golang-interface","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"Go 数据结构之 - map","slug":"go/go-struct-map","date":"2022-07-08T16:00:00.000Z","updated":"2022-07-13T08:37:34.417Z","comments":true,"path":"go/go-struct-map.html","link":"","permalink":"http://phachon.github.io/go/go-struct-map.html","excerpt":"golang 中，map 是最常用的数据结构之一，golang 的 map 具有无序、非线程安全等特点，为了减少使用过程中的容易出错的问题以及达到最优的程序性能，我们有必要了解下 map 的底层实现原理，本文从 map 的概念到 golang map 的实现，在阅读了其他文档和博客的基础上总结整理在此。","text":"golang 中，map 是最常用的数据结构之一，golang 的 map 具有无序、非线程安全等特点，为了减少使用过程中的容易出错的问题以及达到最优的程序性能，我们有必要了解下 map 的底层实现原理，本文从 map 的概念到 golang map 的实现，在阅读了其他文档和博客的基础上总结整理在此。 什么是 map？维基百科的定义 In computer science, an associative array, map, symbol table, or dictionary is an abstract data type composed of a collection of (key, value) pairs, such that each possible key appears at most once in the collection. 包含键值对（key-value）集合的抽象数据结构（关联数组、符号表或字典），其每个可能的键在该集合中最多出现一次，这样的数据结构就是一种 Map。 为什么要使用 map？反过来思考，如果不使用 map，一般基础的数据类型就是数组，如果我们使用数组来存储一系列的健值对，无论是查找还是修改，都会变得非常麻烦，最粗暴的办法就是我们需要把 key 哈希一个数字，根据数字来获取数组索引位置的值实现。但是如果每次都自己实现这一套逻辑，无疑会增加我们的工作量，所以实现一个可存储 key value 方便根据 key 高效查找、修改、删除的数据结构就非常迫切。 常见的 map 实现方式HashTable 哈希表哈希表是用作最多的 map 的底层实现方式，大概思路是： 先初始化一个数组 根据 key 哈希计算到一个索引位置 添加和删除直接通过计算的哈希值来操作数组对应的索引位置 由于数组在内存是连续的一块内存地址，所以通过索引获取或者修改的操作的时间复杂度为 O(1)，做到了高效添加、修改和删除 哈希表的核心是哈希算法的随机性，试想如何哈希算法不够随机，会导致大量的集中的 key 被哈希到相同的桶位置上，那么会造成哈希冲突。一般常见的哈希算法有： 直接寻址法（direct-address table）：取关键字或关键字的某个线性函数值为散列地址。 数字分析法：通过对数据的分析，发现数据中冲突较少的部分，并构造散列地址。例如同学们的学号，通常同一届学生的学号，其中前面的部分差别不太大，所以用后面的部分来构造散列地址。 平方取中法 (midsquare method) ：当无法确定关键字里哪几位的分布相对比较均匀时，可以先求出关键字的平方值，然后按需要取平方值的中间几位作为散列地址。这是因为：计算平方之后的中间几位和关键字中的每一位都相关，所以不同的关键字会以较高的概率产生不同的散列地址。 取随机数法：使用一个随机函数，取关键字的随机值作为散列地址，这种方式通常用于关键字长度不同的场合。 除留取余法：取关键字被某个不大于散列表的表长 n 的数 m 除后所得的余数 p 为散列地址。这种方式也可以在用过其他方法后再使用。该函数对 m 的选择很重要，一般取素数或者直接用 n。 注：这里摘自 《哈希表（Hash Table）与哈希算法》 解决哈希冲突问题在数据量大的情况下，哈希表肯定会遇到哈希冲突问题，即不同的哈希 key 计算得到相同的哈希值，那么解决哈希冲突的方法一般有两种： 链地址法 开放寻址法 哈希冲突的影响因素装载因子：装载因子是表示哈希表中元素的填满程度。它的计算公式：装载因子=填入哈希表中的元素个数/哈希表的长度。装载因子越大，填入的元素越多，空间利用率就越高，但发生哈希冲突的几率就变大。反之，装载因子越小，填入的元素越少，冲突发生的几率减小，但空间浪费也会变得更多，而且还会提高扩容操作的次数。装载因子也是决定哈希表是否进行扩容的关键指标，在java的HashMap的中，其默认装载因子为0.75；Python 的 dict 默认装载因子为2/3 链地址法链地址法的思想是将哈希在同一个桶位置的元素用一个链表串联起来；查找和修改在计算到对应的哈希值之后都需要遍历整个链表。 链地址法优势： 合理利用空间，内存使用率高 发生冲突后的代价小，不需要过多计算 可优化空间大，链表可采用其他数等数据结构来优化 链地址法劣势： 查找和修改的时间复杂度升高 开放寻指法开放寻址法的思想是当遇到哈希冲突时，按照一定的策略再次进行哈希，直到找到没有值的空槽位；所以开放寻址法的前提条件是，槽位的数量必须大于等于元素的数量（必要时候需要进行动态扩容）；常见的开放寻址的策略有：线性探测、平方探测、随机探测、双重哈希等 开放寻址法优势： 存储还是数组，对 CPU 缓存友好，易于序列化操作 读取和修改的时间复杂度底 开放寻址法劣势： 需要重新计算槽位，计算复杂度高 使用空间相对增加，内存利用率低 总结：对于小数据量或者确定数据量大小的适合用开放寻址法；对于大数据量的，冲突更多的适合用链地址法 平衡搜索树数的数据结构的查询复杂度一般在 log(n)，包括：AVL 平衡树和红黑树，这里不做详细解释； 总体比较来看，从时间复杂度上还是哈希表的方式最优；所以更多是采用哈希表来实现 map 、dict、或者字典等数据结构，例如： Redis 字典：使用的哈希表，哈希冲突使用的链地址法 PHP 的字典：使用的哈希表，哈希冲突使用的链地址法 Java 的 map：使用的哈希表，哈希冲突使用的链地址法 Python 中 dict：使用的哈希表，哈希冲突使用的开放寻址法 Go 中的 map：使用的哈希表，哈希冲突使用的链地址法 golang map 实现golang 的 map 也是使用的哈希表实现，解决哈希冲突也是使用的链地址法，map 的内部结构位 hmap，结构简单如下： 1234567891011121314151617181920// A header for a Go map.type hmap struct &#123; // 元素个数，调用 len(map) 时，直接返回此值 count int flags uint8 // buckets 的对数 log_2 B uint8 // overflow 的 bucket 近似数 noverflow uint16 // 计算 key 的哈希的时候会传入哈希函数 hash0 uint32 // 指向 buckets 数组，大小为 2^B // 如果元素个数为0，就为 nil buckets unsafe.Pointer // 扩容的时候，buckets 长度会是 oldbuckets 的两倍 oldbuckets unsafe.Pointer // 指示扩容进度，小于此地址的 buckets 迁移完成 nevacuate uintptr extra *mapextra // optional fields&#125; B 是 buckets 数组的长度的对数，buckets 数组的长度就是 2^B。bucket 里面存储了 key 和 value，buckets 是一个指针，最终它指向的是一个结构体： 123type bmap struct &#123; tophash [bucketCnt]uint8&#125; 但这只是表面(src/runtime/hashmap.go)的结构，编译期间会给它加料，动态地创建一个新的结构： 1234567type bmap struct &#123; topbits [8]uint8 keys [8]keytype // 存储多个 key values [8]valuetype // 存储多个 value pad uintptr overflow uintptr&#125; bmap 其实就是一个桶的结构，桶里最多装8个key，这8个key的哈希计算得到的值是一样的。在桶内又会根据计算出来的高8位来决定 key 到底落到桶里的哪个位置（一个桶内最多8个位置） 从图中可以看出，[]bmap 是整个哈希表数组，每个桶的结构为 bmap，每一个 bmap 可以存储最多 8 个元素（根据元素的高8位和低8位决定在哪个位置），overflow 指针会指向新扩容的新的桶，下面我们针对 map 的具体操作捞说明整个哈希map的实现是怎样的。 map 操作实现添加元素添加或创建 map：1a := make(map[string]int)汇编语言可以看到，实际上底层调用的是 makemap 函数，主要做的工作就是初始化 hmap 结构体的各种字段，例如计算 B 的大小，设置哈希种子 hash0 等等，函数大概如下：12345678910111213141516func makemap(t *maptype, hint int64, h *hmap, bucket unsafe.Pointer) *hmap &#123; // 初始化 hamp if h == nil &#123; h = (*hmap)(newobject(t.hmap)) &#125; h.count = 0 h.B = B h.extra = extra h.flags = 0 h.hash0 = fastrand() h.buckets = buckets h.oldbuckets = nil h.nevacuate = 0 h.noverflow = 0 return h&#125; 注意：这里可以看到 makemap 函数返回的是一个指针，*hmap，所以这里我们就会明白，map 数据结构本身是引用类型，传递到函数内部，即使 copy 了一份新的结构，但是底层的指针指向的内存不变。 这里可以回回顾下 slice 的底层实现：123456// runtime/slice.gotype slice struct &#123; array unsafe.Pointer // 元素指针 len int // 长度 cap int // 容量&#125;结构体内部包含底层的数据指针。makeslice 返回的值。 主要原因：一个是指针（hmap），一个是结构体（slice）。Go 语言中的函数传参都是值传递，在函数内部，参数会被 copy 到本地。hmap指针 copy 完之后，仍然指向同一个 map，因此函数内部对 map 的操作会影响实参。而 slice 被 copy 后，会成为一个新的 slice，对它进行的操作不会影响到实参。 查找key值查找key对应的值，首先我们需要定位到 key 在哈希表中的位置。key 定位的流程如下： 简化下整体的查找流程： 将 key 传入哈希函数（不同类型的key的哈希函数可能不同） 计算得到对应的哈希值 int64 位的二进制数值 当前哈希对象的生成的桶的数量 buckets 的数量，取决于 B 的大小，即 2^B 的桶的数量。取哈希值对应的末尾的 B 位二进制数。举例：图中的哈希对象的桶的对数 B=5，即 2^5 = 32 个 buckets，那么就取哈希结果二进制的末尾 5 位 00110 = 6，就定位到了 bucket 的位置 找到对应的 bucket 位置，bucket 里是一个 bmap 的链表，循环 bmap 的链表中的每一个 tophash 列表，根据哈希结果二进制对应的高 8 位的值和每个 bmap 结构里的 tophash 值进行对比 如果值相等，就找到了具体的 key 和 value 的位置，即相等的 tophash 的索引位置 如果值不相等，就继续循环直到 overflow 指针找到末尾链表，没有找到返回 nil 定位到 key 的位置之后，里面存储着 8 个对应的 key 和 value 返回对应 key 在 bmap 索引位置的 value 更新key值更新 key 值和查找基本一样的流程，区别只是在于最后更新一下 value 的值。核心还是一个双层循环，外层根据低位值遍历 bucket 和它的 overflow bucket，内层根据高8位遍历整个 bucket 的 tophash 找到对应的 key 的索引 注意：更新和读取的时候，go 会设置一个标志位 flag，用来标记是否有其他的程序正在写入数据，如果有的话会触发并发读写的 panic 删除key值删除 key 值也比较简单，找到之后清空对应的 key 和 val 以及 tophash 置为空 遍历 mapmap遍历的过程，是按序遍历 bucket 的，同时遍历 bucket 里面的 tophash 对应的 key 和 value，但其实，为了保证遍历map的结果是无序的，还做了以下事情：map在遍历时，并不是从固定的0号bucket开始遍历的，每次遍历，都会从一个随机值序号的bucket，再从其中随机的cell开始遍历。然后再按照桶序遍历下去，直到回到起始桶结束。 注意：go map 的遍历总是无序的，不能用map来作为有序数据存储 map 扩容为什么需要扩容如果 map 添加的数据越来越多，导致 hash 碰撞的几率越来越大，造成 bmap 里的链表会越来越长，整个的查找的时间复杂度将会严重退化，直至变成一个链表的查找时间复杂度。当 map 将要添加、修改或删除 key 时，都会检查是否需要扩容，扩容实际上是以空间换时间的手段。 扩容的时机哈希表只有在添加元素的时候会触发扩容，在赋值、删除的动作下会触发扩容行为，扩容的条件如下： 触发 load factor 的最大值，负载因子已达到当前界限 溢出桶 overflow buckets 过多 扩容的方案扩容的方案主要如下： 根据需扩容的原因不同（overLoadFactor/tooManyOverflowBuckets），分为两类容量规则方向，为等量扩容（不改变原有大小）或双倍扩容 新申请的扩容空间（newbuckets/newoverflow）都是预分配，等真正使用的时候才会初始化 扩容完毕后（预分配），不会马上就进行迁移。而是采取增量扩容的方式，当有访问到具体 bukcet 时，才会逐渐的进行迁移（将 oldbucket 迁移到 bucket） 扩容完成后迁移（搬迁）：插入（包括修改）、删除 key 的时候，都会尝试进行搬迁 buckets 的工作： 每次至多搬迁 2 个 bucket 一次性搬迁将会造成比较大的延时，采用逐步搬迁策略 map 常见问题 float 类型可以作为 map 的 key 可以的，除了 slice，map，functions 其他都可以 map 中的 key 为什么是无序的 map 在扩容后，会发生 key 的迁移，导致在原来的桶里的位置改变 map 的遍历不是从0开始遍历的，每次随机取一个值遍历的 map 是不是线程安全的？ 不是线程安全的；在添加、修改、删除的时候都会写一个标志位，发现有标记为1，直接 panic map 删除一个 key 发生了什么？ 计算 key 的哈希结果 如果发生在扩容，直接搬迁 如果不是扩容，定位到 key 的位置 直接清零 map 的扩容过程是怎样的？ 参考上面的扩容介绍 map 如何赋值的？ 计算 key 的哈希结果 判断是否有标记位 如果有标记位，直接 panic 定位到 key 的位置，修改 map 如何遍历？ 每次随机生成一个数字 双层循环 如果正在扩容搬迁，也需要循环搬迁的内容 比较两个 map 相等？ 只能循环遍历 map 的每一个元素 赋值的时候会触发扩容吗？ 不会，只有添加元素才会 负载因子是什么？过高会带来什么问题？它的变动会对哈希表操作带来什么影响吗？ 过高会触发扩容 溢出桶越多会带来什么问题？ 触发扩容，时间复杂度高 是否要扩容的基准条件是什么？ 负载因子和链表长度 扩容的步骤是怎么样的？涉及到了哪些数据结构？ 扩容是一次性扩容还是增量扩容？ 增量扩容 正在扩容的时候又要扩容怎么办？ 扩容完成后下一次扩容 总结Go语言的map，底层是哈希表实现的，通过链地址法解决哈希冲突，它依赖的核心数据结构是数组加链表。 map中定义了2的B次方个桶，每个桶中能够容纳8个key。根据key的不同哈希值，将其散落到不同的桶中。哈希值的低位（哈希值的后B个bit位）决定桶序号，高位（哈希值的前8个bit位）标识同一个桶中的不同 key。 当向桶中添加了很多 key，造成元素过多，超过了装载因子所设定的程度，或者多次增删操作，造成溢出桶过多，均会触发扩容。 扩容分为增量扩容和等量扩容。增量扩容，会增加桶的个数（增加一倍），把原来一个桶中的 keys 被重新分配到两个桶中。等量扩容，不会更改桶的个数，只是会将桶中的数据变得紧凑。不管是增量扩容还是等量扩容，都需要创建新的桶数组，并不是原地操作的。 扩容过程是渐进性的，主要是防止一次扩容需要搬迁的 key 数量过多，引发性能问题。触发扩容的时机是增加了新元素， 桶搬迁的时机则发生在赋值、删除期间，每次最多搬迁两个 桶。查找、赋值、删除的一个很核心的内容是如何定位到 key 所在的位置。 参考资料 哈希表（Hash Table）与哈希算法 深入理解 Go map：赋值和扩容迁移 深入理解Golang中map设计","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"Go 数据结构之 - 数组和 slice","slug":"go/go-struct-slice","date":"2022-07-08T16:00:00.000Z","updated":"2022-07-13T14:03:41.860Z","comments":true,"path":"go/go-struct-slice.html","link":"","permalink":"http://phachon.github.io/go/go-struct-slice.html","excerpt":"golang 中的数组和 slice 也是比较常见的数据结构，但是 slice 和数组的区别初学者往往会搞不清楚；这里从底层数据结构来一探 slice 和数组的实现和差异。","text":"golang 中的数组和 slice 也是比较常见的数据结构，但是 slice 和数组的区别初学者往往会搞不清楚；这里从底层数据结构来一探 slice 和数组的实现和差异。 数组数组是由相同类型的数据组成的集合的数据结构，计算机会分配一段连续的内存来保存数组元素，我们可以利用数组的索引快速访问到特定的元素。 1a := [4]int&#123;1, 2, 3&#125; // 初始化数组 关于数组的几点注意： Go 语言中，数组属于值类型，因此当一个数组被赋值或者传递时，是会 copy 整个数组 不同长度的数组代表不同的类型，例如 [4]int{} 和 [5]int{} 是不同的类型 函数参数函数传递参数数组，由于 slice 是值类型，所以会 copy 一份数据 总结数组类型比较简单，使用也相对比较局限，因为必须是固定大小空间的元素，且不能动态扩容，所以当已知数量的元素的时候适合用数组数据结构 sliceslice 也叫切片，相比数组来说更加灵活和动态，是在数组的基础上做了补充，支持不定长度，动态扩容等特性，所以比数组的使用场景更广泛。切片本质是一个数组片段的描述，包括了数组的指针，这个片段的长度和容量(不改变内存分配情况下的最大长度)。 12345struct &#123; ptr *[]T // 数组的指针 len int // 当前切片的长度 cap int // 当前切片的容量，即数组的大小：&#125; 我们可以在运行区间改变长度和范围，当底层的数组长度不足时候，就会触发扩容，切片指向的数组就会发生变化 函数参数函数传递参数数组，由于数组是值类型，所以会 copy 一份数据 追加和扩容使用 append 关键字来追加元素，这里分两种情况会进入不同的流程，如果 append 返回的新切片不需要赋值回已有的变量：1234567891011// append(slice, 1, 2, 3)ptr, len, cap := slicenewlen := len + 3if newlen &gt; cap &#123; // 新的长度大于数组的长度 ptr, len, cap = growslice(slice, newlen) // 生成新的切片 newlen = len + 3&#125;*(ptr+len) = 1*(ptr+len+1) = 2*(ptr+len+2) = 3return makeslice(ptr, newlen, cap) // 返回新切片 如果 append 返回的新切片需要赋值给已有的变量，即需要覆盖已有的变量：12345678910111213141516// slice = append(slice, 1, 2, 3)a := &amp;sliceptr, len, cap := slicenewlen := len + 3if uint(newlen) &gt; uint(cap) &#123; newptr, len, newcap = growslice(slice, newlen) vardef(a) // 区别在于这里，这里新生成的切片直接修改掉原来切片的指针 *a.cap = newcap *a.ptr = newptr&#125;newlen = len + 3*a.len = newlen*(ptr+len) = 1*(ptr+len+1) = 2*(ptr+len+2) = 3所以 append 赋值给原来的切片不会存在拷贝的问题，只是改变了数组的指针 扩容操作会调用 runtime.growslice 函数为切片扩容，扩容是为切片分配新的内存空间并拷贝原切片中元素的过程 在分配内存空间之前需要先确定新的切片容量，运行时根据切片的当前容量选择不同的策略进行扩容： 如果期望容量大于当前容量的两倍就会使用期望容量； 如果当前切片的长度小于 1024 就会将容量翻倍； 如果当前切片的长度大于 1024 就会每次增加 25% 的容量，直到新容量大于期望容量； 拷贝切片copy(a, b) 的形式对切片进行拷贝，无论是编译期间拷贝还是运行时拷贝，两种拷贝方式都会通过 runtime.memmove 将整块内存的内容拷贝到目标的内存区域中，相比于依次拷贝元素，runtime.memmove 能够提供更好的性能。需要注意的是，整块拷贝内存仍然会占用非常多的资源，在大切片上执行拷贝操作时一定要注意对性能的影响。 切片截取切片操作并不复制切片指向的元素，创建一个新的切片会复用原来切片的底层数组，因此切片操作是非常高效的。下面的例子展示了这个过程： 123456789nums := make([]int, 0, 8)nums = append(nums, 1, 2, 3, 4, 5)nums2 := nums[2:4]printLenCap(nums) // len: 5, cap: 8 [1 2 3 4 5]printLenCap(nums2) // len: 2, cap: 6 [3 4]nums2 = append(nums2, 50, 60)printLenCap(nums) // len: 5, cap: 8 [1 2 3 4 50]printLenCap(nums2) // len: 4, cap: 6 [3 4 50 60] nums2 执行了一个切片操作 [2, 4]，此时 nums 和 nums2 指向的是同一个数组。 nums2 增加 2 个元素 50 和 60 后，将底层数组下标 [4] 的值改为了 50，下标[5] 的值置为 60。 因为 nums 和 nums2 指向的是同一个数组，因此 nums 被修改为 [1, 2, 3, 4, 50]。 Go 语言在 Github 上的官方 wiki - SliceTricks 介绍了切片常见的操作技巧。另一个项目 Go Slice Tricks Cheat Sheet 将这些操作以图片的形式呈现了出来，非常直观。 这部分摘自：切片(slice)性能及陷阱 常见陷阱 大量内存得不到释放在已有切片的基础上进行切片，不会创建新的底层数组。因为原来的底层数组没有发生变化，内存会一直占用，直到没有变量引用该数组。因此很可能出现这么一种情况，原切片由大量的元素构成，但是我们在原切片的基础上切片，虽然只使用了很小一段，但底层数组在内存中仍然占据了大量空间，得不到释放。比较推荐的做法，使用 copy 替代 re-slice。 slice 作为函数参数slice 作为函数参数本身是值传递，slice 本身也是结构体，所以函数内部回重新 copy 一个结构体。值的注意的是，不管传的是 slice 还是 slice 指针，如果改变了 slice 底层数组的数据，会反应到实参 slice 的底层数据。为什么能改变底层数组的数据？很好理解：底层数据在 slice 结构体里是一个指针，仅管 slice 结构体自身不会被改变，也就是说底层数据地址不会被改变。 但是通过指向底层数据的指针，可以改变切片的底层数据，没有问题。 12345678910111213141516package mainfunc main() &#123; s := []int&#123;1, 1, 1&#125; f(s) fmt.Println(s)&#125;func f(s []int) &#123; // i只是一个副本，不能改变s中元素的值 /*for _, i := range s &#123; i++ &#125; */ for i := range s &#123; s[i] += 1 &#125;&#125; 运行一下，程序输出： 1[2 2 2] 如果函数里 append 追加覆盖回如何呢？ 1234567891011121314151617181920212223242526package mainimport &quot;fmt&quot;func Append(s []int) []int &#123; // 这里 s 是 main 里面的 s 的拷贝 // append 发生扩容返回的新的 slice 改变的是拷贝的 s，不是原来的 s s = append(s, 10) return s&#125;func AppendPtr(s *[]int) &#123; // 这里 *s 是 main 里面的 s 指针的拷贝 // append 发生扩容返回的新的 slice 的指针就是原来 s 的指针 *s = append(*s, 10) return&#125;func main() &#123; s := []int&#123;1, 1, 1&#125; newS := Append(s) fmt.Println(s) // [1, 1, 1] fmt.Println(newS) // [1, 1, 1, 10] s = newS AppendPtr(&amp;s) fmt.Println(s) // [1, 1, 1, 10, 10]&#125; 参考资料 切片(slice)性能及陷阱 切片 切片作为函数参数","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"【转载】字节跳动在 Go 网络库上的实践","slug":"go/go-netpoll","date":"2021-07-08T16:00:00.000Z","updated":"2022-07-11T01:59:03.320Z","comments":true,"path":"go/go-netpoll.html","link":"","permalink":"http://phachon.github.io/go/go-netpoll.html","excerpt":"","text":"本文转载自：https://www.cloudwego.io/zh/blog/2021/10/09/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E5%9C%A8-go-%E7%BD%91%E7%BB%9C%E5%BA%93%E4%B8%8A%E7%9A%84%E5%AE%9E%E8%B7%B5/","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"Consul系列（二）：Consul + Docker 搭建集群","slug":"consul/consul-2","date":"2019-07-02T05:51:00.000Z","updated":"2022-07-11T01:59:03.319Z","comments":true,"path":"consul/consul-2.html","link":"","permalink":"http://phachon.github.io/consul/consul-2.html","excerpt":"微服务的架构下，生产环境的服务一般都是部署在 docker 中，而 Consul 和 Docker 也可以很好的衔接。","text":"微服务的架构下，生产环境的服务一般都是部署在 docker 中，而 Consul 和 Docker 也可以很好的衔接。 搭建环境 Consul MacOS— Docker docker 在 macos 下的安装比较简单。略过。 ##","categories":[{"name":"Consul","slug":"Consul","permalink":"http://phachon.github.io/categories/Consul/"}],"tags":[{"name":"consul","slug":"consul","permalink":"http://phachon.github.io/tags/consul/"}]},{"title":"Consul系列（四）：Consul—Template + Nginx 实现服务动态负载均衡","slug":"consul/consul-4","date":"2019-07-02T05:51:00.000Z","updated":"2022-07-11T01:59:03.319Z","comments":true,"path":"consul/consul-4.html","link":"","permalink":"http://phachon.github.io/consul/consul-4.html","excerpt":"Consul 用于实现分布式的服务发现和配置，内置了服务注册与发现框架，分布一致性协议实现，健康检查，Key/Value 存储，多数据中心方案，不再依赖其他工具。使用相对比较简单。","text":"Consul 用于实现分布式的服务发现和配置，内置了服务注册与发现框架，分布一致性协议实现，健康检查，Key/Value 存储，多数据中心方案，不再依赖其他工具。使用相对比较简单。","categories":[{"name":"Consul","slug":"Consul","permalink":"http://phachon.github.io/categories/Consul/"}],"tags":[{"name":"consul","slug":"consul","permalink":"http://phachon.github.io/tags/consul/"}]},{"title":"Consul系列（三）：Consul-Template 的介绍与使用","slug":"consul/consul-3","date":"2019-07-02T05:51:00.000Z","updated":"2022-07-11T01:59:03.319Z","comments":true,"path":"consul/consul-3.html","link":"","permalink":"http://phachon.github.io/consul/consul-3.html","excerpt":"Consul 用于实现分布式的服务发现和配置，内置了服务注册与发现框架，分布一致性协议实现，健康检查，Key/Value 存储，多数据中心方案，不再依赖其他工具。使用相对比较简单。","text":"Consul 用于实现分布式的服务发现和配置，内置了服务注册与发现框架，分布一致性协议实现，健康检查，Key/Value 存储，多数据中心方案，不再依赖其他工具。使用相对比较简单。","categories":[{"name":"Consul","slug":"Consul","permalink":"http://phachon.github.io/categories/Consul/"}],"tags":[{"name":"consul","slug":"consul","permalink":"http://phachon.github.io/tags/consul/"}]},{"title":"vue 基本配置与环境搭建","slug":"vue/vue_env","date":"2019-06-28T16:00:00.000Z","updated":"2022-07-11T01:59:03.327Z","comments":true,"path":"vue/vue_env.html","link":"","permalink":"http://phachon.github.io/vue/vue_env.html","excerpt":"","text":"参考文档：https://segmentfault.com/a/1190000014785115","categories":[{"name":"Vue","slug":"Vue","permalink":"http://phachon.github.io/categories/Vue/"}],"tags":[{"name":"vue","slug":"vue","permalink":"http://phachon.github.io/tags/vue/"}]},{"title":"Go 应用之 - switch 踩坑记录","slug":"go/go-app-switch","date":"2019-06-27T16:00:00.000Z","updated":"2022-07-11T01:59:03.320Z","comments":true,"path":"go/go-app-switch.html","link":"","permalink":"http://phachon.github.io/go/go-app-switch.html","excerpt":"在一次工作中使用 switch 才发现和其他的语言的 switch 有些不一样，避免再次踩坑，在这里总结一下。","text":"在一次工作中使用 switch 才发现和其他的语言的 switch 有些不一样，避免再次踩坑，在这里总结一下。 示例代码 1234567891011121314151617// 获取考试成绩func GetGrade(score string) (grade string) &#123; switch score &#123; case &quot;A&quot;: fmt.Println(&quot;优秀&quot;) case &quot;B&quot;: fmt.Println(&quot;良好&quot;) break case &quot;C&quot;: fmt.Println(&quot;及格&quot;) case &quot;D&quot;: fmt.Println(&quot;不及格&quot;) default: fmt.Println(&quot;没考试&quot;) &#125; return grade&#125; 调用例子12GetGrade(&quot;A&quot;) // 输出 “优秀”GetGrade(&quot;B&quot;) // 输出 “良好” 结论：和其他语言的 break 不一样，go 里面只要 case 是 true，会在末尾自动加 break, 不会走其他的 case , 所以，break 的意义不是很大。 如果想要走下面的 case 怎么办？","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"【翻译】Golang 编译优化","slug":"go/go-compiler-optimizations","date":"2019-01-11T04:19:10.000Z","updated":"2022-07-11T01:59:03.320Z","comments":true,"path":"go/go-compiler-optimizations.html","link":"","permalink":"http://phachon.github.io/go/go-compiler-optimizations.html","excerpt":"","text":"本篇文章翻译自：https://github.com/golang/go/wiki/CompilerOptimizations#string-and-byte","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"Go 应用之 - Fasthttp 高性能分析","slug":"go/go-app-fasthttp","date":"2019-01-10T16:00:00.000Z","updated":"2022-07-11T01:59:03.319Z","comments":true,"path":"go/go-app-fasthttp.html","link":"","permalink":"http://phachon.github.io/go/go-app-fasthttp.html","excerpt":"fasthttp 号称比 net/http 要快 10 倍左右，之前使用 fasthttp 写过也写过一些项目，这里试图刨析一下 fasthttp 高性能的原因","text":"fasthttp 号称比 net/http 要快 10 倍左右，之前使用 fasthttp 写过也写过一些项目，这里试图刨析一下 fasthttp 高性能的原因 fasthttp介绍github: https://github.com/valyala/fasthttp这里先翻译一下官网的介绍 FastHTTP最佳实践 不要分配 object 和 []byte 缓冲区, 要尽可能地重用它们。FastHTTP API设计鼓励这样做。 sync.Pool 使用对象池 在项目中开启 go tool pprof –alloc_objects your-program mem.ppro 通常会比 go tool pprof your-program cpu.pprof 更好 写 tests 和 benchmarks 避免在 []byte 和 string 之间进行转换，因为这可能导致 内存分配+复制 。FastHTTP API同时为[]byte 和 string 提供函数，使用这些函数，而不是在[]byte 和 string 之间手动转换。wiki: https://github.com/golang/go/wiki/CompilerOptimizations#string-and-byte 在并发的环境下测试代码 合理使用 []byte 字节缓冲区为什么还要创建另一个 HTTP 包而不是优化 net/http？因为 net/http api 限制了许多优化机会。例如： net/http 请求对象生存期不受请求处理程序执行时间的限制。因此，服务器必须为每个请求创建一个新的请求对象，而不是像 fasthttp 那样重用现有对象。 net/http api 要求每个请求创建一个新的响应对象。 net/http 头存储在 map[string][] 字符串中。因此，在调用用户提供的请求处理程序之前，服务器必须解析所有头，将它们从 []byte 转换为 string，并将它们放入映射中。这都需要 fasthttp 避免不必要的内存分配。 为什么 fasthttp api 与 net/http 不兼容？因为 net/http API 限制了许多优化机会。请参阅上面的答案了解更多详细信息。此外，某些 net/http API部件的使用还不理想：比较 net/http connection hijacking 与 fasthttp connection hijacking.比较 net/http Request.Body reading t与 fasthttp request body reading. 与 fasthttp 相比，net/http有什么优势？ net/http 支持从 GO1.6 开始支持 HTTP/2.0 net/http API是稳定的，而 FastHTTP API 不断发展 net/http 处理更多的 http 情况 net/http 应该包含更少的bug，因为它被更广泛的受众使用和测试。 net/http 支持 go1.5 的旧版本 为什么 fastHttp API 返回 []byte 而不是 string？因为 []byte 到 string 的转换需要内存重分配和复制 fasthttp 支持哪些 go 版本？go1.5+ 优势总结根据作者的解释，fasthttp 对性能提高的优化点主要在于： 协程池 对象的复用 减少 []byte 到 string 的转化 源码分析接下来我们从源码来分析一下 fasthttp 究竟做了哪些优化 协程池go 官方原生的 server.go123456789l := listen()func (srv *Server) Serve(l net.Listener) error &#123; for &#123; rw, err := l.accept() .... // 处理请求, 每次都开启一个 gorotine go c.serve(ctx) &#125;&#125; fasthttp 的 Serve123456789101112func (s *Server) Serve(ln net.Listener) error &#123; for &#123; if c, err = acceptConn(s, ln, &amp;lastPerIPErrorTime); err != nil &#123; ...... &#125; // 对应 go c.serve(ctx) if !wp.Serve(c) &#123; //...... &#125; //...... &#125;&#125;很明显，go 原生的 net/http 中，当接受到新的请求后就启动一个新的斜程，而 fasthttp 使用斜程池处理","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"Redis系列（十一）：Redis 的 ZSet 性能分析","slug":"redis/redis-11","date":"2019-01-07T04:22:10.000Z","updated":"2022-07-11T01:59:03.325Z","comments":true,"path":"redis/redis-11.html","link":"","permalink":"http://phachon.github.io/redis/redis-11.html","excerpt":"","text":"总结","categories":[{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://phachon.github.io/tags/redis/"}]},{"title":"Redis系列（十二）：Redis 设计与实现","slug":"redis/redis-book","date":"2019-01-07T04:22:10.000Z","updated":"2022-07-11T01:59:03.326Z","comments":true,"path":"redis/redis-book.html","link":"","permalink":"http://phachon.github.io/redis/redis-book.html","excerpt":"https://www.kancloud.cn/kancloud/redisbook/63822","text":"https://www.kancloud.cn/kancloud/redisbook/63822","categories":[{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://phachon.github.io/tags/redis/"}]},{"title":"Redis系列（十）：Redis 的 Mget 性能分析","slug":"redis/redis-10","date":"2019-01-06T04:22:10.000Z","updated":"2022-07-11T01:59:03.325Z","comments":true,"path":"redis/redis-10.html","link":"","permalink":"http://phachon.github.io/redis/redis-10.html","excerpt":"","text":"总结","categories":[{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://phachon.github.io/tags/redis/"}]},{"title":"Redis系列（久）：Redis 数据结构之整数集合","slug":"redis/redis-9","date":"2019-01-05T04:22:10.000Z","updated":"2022-07-11T01:59:03.325Z","comments":true,"path":"redis/redis-9.html","link":"","permalink":"http://phachon.github.io/redis/redis-9.html","excerpt":"","text":"总结","categories":[{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://phachon.github.io/tags/redis/"}]},{"title":"Redis系列（七）：Redis 数据结构之 dict","slug":"redis/redis-7","date":"2018-12-30T04:22:10.000Z","updated":"2022-07-11T01:59:03.325Z","comments":true,"path":"redis/redis-7.html","link":"","permalink":"http://phachon.github.io/redis/redis-7.html","excerpt":"redis 作为 key value 的数据库，字典是 redis 使用非常多的数据结构之一，本篇文章简单来了解一下 redis 的内部字典的实现","text":"redis 作为 key value 的数据库，字典是 redis 使用非常多的数据结构之一，本篇文章简单来了解一下 redis 的内部字典的实现 字典的数据结构redis 的字典的数据结构如下：123456789101112131415typedef struct dict &#123; // 类型特定函数 dictType *type; // 私有函数 void *privatdata; // 哈希表 dictht ht[2]; // rehash 索引 // 当 rehash 不在进行时，为 -1 int trehashidx;&#125;ht属性，一个包含两个项的数组，数组的\b每一个元素都是 dicth 哈希表，一般情况下\b，字典只会使用 dict[0] 的哈希表，当进行 rehash 时候，才会需要用到 dicth[1] 的哈希表。 trehashidex 属性，跟 rehash \b相关，记录当前 rehash 的索引值。 dictht 的数据结构如下：1234567891011121314typedef struct dictht &#123; // 哈希\b表数组 dictEntry *table[]; // \btable 大小 int size; // 计算索引的掩码 int sizemask; // 已使用的大小 int used&#125; 每一个的 dictEntry 结构里都存着两个属性，key 和 val，也就是字典的 key 和 value 哈希算法redis 的 hash 算法相对比较简单。分为两步： 根据哈希函数计算出 key 的哈希值，得到哈希值 1hash = hashFunc(key); 根据\b哈希值和哈希表的\b掩码进行运算，得到哈希表的索引值 1idx = hash &amp; sizemask; 计算出的索引值即为该 key 和 value 在 table 中的存储位置。 哈希碰撞\b使用 hashTable, 那么就必须要解决\b哈希碰撞。1哈希碰撞就是当 key 计算出来的哈希索引的位置上已经存在了一个 key，\b那么就是发生了哈希碰撞。\b就是两个 key \b都哈希到了同一个哈希索引的位置上 redis 解决哈希碰撞的方法是：链地址法 当发生哈希碰撞时，哈希节点通过 next 指针连接起来构成单向链表。 为了速度考虑，程序总是将新节点添加到表头的位置（时间复杂度为 1），排在其他节点的前面。 ReHash \b的原理\b随着操作的不断进行，哈希表中保存的\b key 会增多获或减少，为了让 \bhash 表的负载因子维持在一个合理的范围之内，redis 会进行 rehash 的操作。1\b负载因子 = 哈希表已保存节点数量 / 哈希表的大小当负载因子大于等于 1 会触发哈希表的扩展操作当负载因子小于等于 0.1 会触发哈希表的收缩操作 rehash 的过程： 为字典的 ht[1] 分配空间，空间的大小取决于要执行的操作以及哈希表 ht[0] 包含的键值对的大小 \b将保存在 ht[0] 上的所有的键 rehash 到 ht[1] 上，rehash 需要重新计算得到索引值。 rehash 完成后，ht[0] 为空，释放 ht[0]，将 ht[1] 设置为 ht[0], 并为 ht[1] \b创建一个空白的哈希表，为下次 rehash 准备。 渐进式的 rehashredis 如果只保存了少量的键值对，那么一次 rehash 可以\b很快完成，但是当健值对很多的时候，一次性全部 rehash 肯定会影响 redis 的性能。\b所以，\btrehashidx 的属性派上用场。 当不需要 rehash 的时候，rehashidx \b= -1，当需要 rehash 的时候，rehashidx = 0; 这时候，\b当该 hashTable 中需要操作时，除了操作指定的键以外，同时还会将 ht[0] rehashidx 的索引位置的所有的键值对 rehash 到 ht[1] 的 hastTable 中，完成后对 rehashidx + 1。随着操作的\b不断进行，最终会完成 ht[0] 到 ht[1] 全部 rehash 工作。 渐进式的 rehash 过程中，发生增删改查的操作时的处理： 增加新的键值对\b，只会对 ht[1] 的表新增 查找键值对，先查找 ht[0]，没有的话查找 ht[1] 修改键值对，对 ht[0] 和 ht[1] 都进行修改 删除键值对，对 ht[0] 和 ht[1] 同时删除 字典的使用\b场景字典在 redis 的使用场景比较多。 \bredis 的 key value 的存储结构 \bredis 的 hash 存储结构 redis zaset 中根据 memeber 查找 score。。。 总结hashtable 是最常使用的一种数据结构，因为有 1 的时间复杂度，在设计 hashtable 时，可以借鉴 redis 的哈希碰撞和 rehash 的设计。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://phachon.github.io/tags/redis/"}]},{"title":"Redis系列（八）：Redis 数据结构之 SkipList","slug":"redis/redis-8","date":"2018-12-30T04:22:10.000Z","updated":"2022-07-11T01:59:03.325Z","comments":true,"path":"redis/redis-8.html","link":"","permalink":"http://phachon.github.io/redis/redis-8.html","excerpt":"SkipList 跳跃表是一种有序的数据结构，通过每个节点中维持多个指向其他节点的指针，从而达到快速访问的目的。跳跃表是有序集合数据类型的底层实现之一。","text":"SkipList 跳跃表是一种有序的数据结构，通过每个节点中维持多个指向其他节点的指针，从而达到快速访问的目的。跳跃表是有序集合数据类型的底层实现之一。 跳跃表的演变跳跃表本质上也是来解决查找问题，提高查找效率，通常情况下，我们使用两种数据结构： 树结构（二叉树，平衡树，红黑树） 哈希结构 但是，跳跃表并不属于这两类，从 skipList 名字来看，跳跃表其实是从有序链表演变而来。 链表我们先来看看有序链表的查找方式 \b\b\b很明显，只能\b从表头查到表尾\b，时间复杂度为 O(n) 跳跃表我们试图将链表增加层级来提高查找效率，如下图所示： 如果查找所需要的数据，， 跳跃表与平衡树对比redis 跳跃表的实现有序集合中跳跃表的使用\b有序\b集合 zset 的\b常用命令如下：12345678910// 添加一个成员和分数zadd key score member// 获取成员分数zscore key member// 获取成员排名zrevrank key member// 获取\b排名范围的成员zrevrange key 1 3// 获取分数范围的成员zrevrangebyscore key 60 80 zscore 并没有用到 skiplist 而是通过 dict \b实现，有序集合\b通过 dict 来保存成员到分数的对应关系 zrevrank 先通过 总结参考资料： Redis为什么用跳表而不用平衡树？","categories":[{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://phachon.github.io/tags/redis/"}]},{"title":"Redis系列（六）：Redis 数据结构之 SDS","slug":"redis/redis-6","date":"2018-12-17T04:22:10.000Z","updated":"2022-07-11T01:59:03.325Z","comments":true,"path":"redis/redis-6.html","link":"","permalink":"http://phachon.github.io/redis/redis-6.html","excerpt":"Redis 没有直接使用 C 语言的字符串数组，而是自己构建了一个简单动态字符串用于 Redis 底层的字符串表示，即 SDS (Simple Dynamic String)","text":"Redis 没有直接使用 C 语言的字符串数组，而是自己构建了一个简单动态字符串用于 Redis 底层的字符串表示，即 SDS (Simple Dynamic String) SDS 的数据结构C 语言使用以空格结尾的字符串数组来表示字符串。 123+---+---+---+---+---+----+| R | e | d | i | s | \\0 |+---+---+---+---+---+----+ sds 的数据结构 1234567891011struct sdshdr &#123; // 记录了 buf 中已使用的数量 int len // 记录了 buf 中未使用的数量 int free // 用于存储字符串的数组 char buf[]&#125; 可以看出，在 c 的基础上加了两个属性，len 和 free。 SDS 的优化\bsds \b字符串主要从三方面进行了优化 1.提高获取字符串长度效率传统的 c 语言获取字符串长度的方式是没次都遍历字符串数组，是件复杂度为 nsds 增加了 len 属性，\b所以获取字符串的事件复杂度将为 1 2.防止缓冲区溢出当拼接字符串的时候，字符串长度需要增加时候，如果\b是 c 语言，那么首先我们必须在拼接字符串之前要判断字符串数组是否能够容纳增加后的字符串，否则的话要先对字符串数组进行内存充分配。如果忘记判断，就\b就造成缓冲区的溢出。 sds 字符串在操作字符串的 API 内部都进行了判断，所以不需要使用者再去\b关心内存溢出的问题，所以是从根本上杜绝了内存溢出的可能。 3.减少内存重分配\b在 c 语言中，每次在扩展字符串的时候，我们都需要每次先进行内存重新分配的操作，当字符串缩短时，同样要进行内存释放，否则会造成内存泄漏。操作内存属于系统操作，相对比较耗时。 sds \b字符串使用 free 属性来减少内存重分配，当发生\b字符串扩展时，redis 不只是将 sds 的 buf 数组增加到新数组的长度，二是会额外增加一部分的空闲空间，空闲空间的长度就是 free 属性的值。当下一次再进行字符串扩展时，首先会判断空闲的字符串长度是否够，如果够，则直接进行扩展，而不需要再进行内存充分配的操作。同样，当字符串进行缩短的时候，sds 也并不会马上进行内存释放，而是将多出来的空闲 buf 数组的值保存到 free 属性中，等待下次字符串需要的时候再使用。 所以，正常情况下，redis 的 sds 可能有部分内存浪费的情况，sds 也提供了手动清理空闲的 buf。 SDS 二进制安全c 语言的字符串数组只能存储 ASCII 编码的字符，并且会以空格 \\0 作为字符串的结尾，例如我们存入一个 ‘redis cluster’ 的字符串，当通过 c 语言获取的时候，只会读取到 ‘redis’。 redis 的 sds 字符串 api 不会对输入的数据进行任何的处理，所以可以是压缩的图像，视频，文件的二进制数据，也可以是以空格分割的文本数据。当在读取的时候， sds 不会以空格为结尾读取，而是通过 len 属性来读取字符窜。 SDS 兼容性除了做了上面的一些优化和功能扩展之外，sds 的设计还充分考虑到和 c 字符窜的兼容性，所以，sds 的 buf 数组也是必须以空格结尾。这样做的好处在于，可以复用一部分的 c 字符串的函数。例如，我们存入的是简单的文本数据，那么就可以直接使用 c 语言的一部分函数来直接操作 buf 数组。 总结从 redis 的 sds 的设计中，可以看到作者考虑问题的细致，一个看似简单的扩展，其实大大提高了字符串的使用效率。所以，我们在设计系统或是编写代码的过程中，应该习惯取多去思考一些细节。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://phachon.github.io/tags/redis/"}]},{"title":"Consul系列（一）：Consul 的介绍与使用","slug":"consul/consul-1","date":"2018-11-26T05:51:00.000Z","updated":"2022-07-11T01:59:03.319Z","comments":true,"path":"consul/consul-1.html","link":"","permalink":"http://phachon.github.io/consul/consul-1.html","excerpt":"Consul 用于实现分布式的服务发现和配置，内置了服务注册与发现框架，分布一致性协议实现，健康检查，Key/Value 存储，多数据中心方案，不再依赖其他工具。使用相对比较简单。","text":"Consul 用于实现分布式的服务发现和配置，内置了服务注册与发现框架，分布一致性协议实现，健康检查，Key/Value 存储，多数据中心方案，不再依赖其他工具。使用相对比较简单。 Consul 介绍Consul是一个分布式高可用的系统。相比其他的服务发现方案，Consul 的服务发现方案更”一站式”，内置服务发现与注册、分布式一致性协议实现、健康检查、Key/Value 存储，多数据中心方案。使用 Go 语言编写，因此，可编译成多个平台（Linux，Windows，Mac OS） Consul 特性 服务发现 健康检查 Key/Value存储 多数据中心 支持多个数据中心， 上图有两个数据中心 每个数据中心一般有 N个服务器，服务器数目要在可用性和性能上进行平衡，客户端数量没有限制。分布在不同的物理机上。 一个集群中的所有节点都添加到 gossip protocol（通过这个协议进行成员管理和信息广播）中 数据中心的所有服务端节点组成一个raft集合， 他们会选举出一个leader，leader服务所有的请求和事务， 如果非leader收到请求，把所有的改变同步(复制)给非leader. 所有数据中心的服务器组成了一个 WAN gossip pool，他存在目的就是使数据中心可以相互交流，增加一个数据中心就是加入一个 WAN gossip pool， 当一个服务端节点收到其他数据中心的请求， 会转发给对应数据中心的服务端。 Consul 安装https://www.consul.io/downloads.html 不需要安装，解压后直接运行。 我这里下载的版本是 consul-1.5.2 Consul Agent运行 consul agent12# 开发模式运行，-node 指定节点名consul agent -node consul.node.1 -dev观察日志输出 Web 管理界面浏览器打开：http://127.0.0.1:8500 查看集群成员1consul members 会输出我们自己的节点，运行的地址，健康状态，自己在集群中的角色，版本信息12Node Address Status Type Build Protocol DC Segmentconsul.node.1 127.0.0.1:8301 alive server 1.5.2 2 dc1 &lt;all&gt; HTTP 查询节点1curl 127.0.0.1:8500/v1/catalog/nodes 输出1[&#123;&quot;ID&quot;:&quot;d68bd1c6-65dd-0a7e-97b0-c7dc409f9c91&quot;,&quot;Node&quot;:&quot;consul.node.1&quot;,&quot;Address&quot;:&quot;127.0.0.1&quot;,&quot;Datacenter&quot;:&quot;dc1&quot;,&quot;TaggedAddresses&quot;:&#123;&quot;lan&quot;:&quot;127.0.0.1&quot;,&quot;wan&quot;:&quot;127.0.0.1&quot;&#125;,&quot;Meta&quot;:&#123;&quot;consul-network-segment&quot;:&quot;&quot;&#125;,&quot;CreateIndex&quot;:9,&quot;ModifyIndex&quot;:10&#125;] DNS 查询节点1dig @127.0.0.1 -p 8600 consul.node.1 服务注册假如现在有一个 8088 的服务需要注册到 consul 中，我们先来定义一下服务 服务定义服务定义最好是根据服务的所属业务线，业务模块，项目，以及服务属性来划分，例如，我们定义如下服务：1234567&#123; &quot;service&quot;: &#123; &quot;name&quot;: &quot;video.user.info&quot;, &quot;tags&quot;: [&quot;go&quot;], &quot;port&quot;: 8088 &#125;&#125;新建配置文件 /etc/consul.d/news.user.info.json，将服务信息写入 重启 agent1consul agent -config-dir /etc/consul.d -node consul.node.1 -dev通过读取配置文件的服务定义信息，将服务 video.user.info 注册到了 consul 中 服务发现通过 http 方式来发现服务12# video.user.info 是服务名curl http://127.0.0.1:8500/v1/catalog/service/video.user.info返回服务信息 总结本文简单介绍了 Consul 的安装和使用，总体看 Consul 的安装和使用都比较简单。","categories":[{"name":"Consul","slug":"Consul","permalink":"http://phachon.github.io/categories/Consul/"}],"tags":[{"name":"consul","slug":"consul","permalink":"http://phachon.github.io/tags/consul/"}]},{"title":"Consul系列（五）：Consul 的一致性算法","slug":"consul/consul-5","date":"2018-11-26T05:51:00.000Z","updated":"2022-07-11T01:59:03.319Z","comments":true,"path":"consul/consul-5.html","link":"","permalink":"http://phachon.github.io/consul/consul-5.html","excerpt":"Consul 用于实现分布式的服务发现和配置，内置了服务注册与发现框架，分布一致性协议实现，健康检查，Key/Value 存储，多数据中心方案，不再依赖其他工具。使用相对比较简单。","text":"Consul 用于实现分布式的服务发现和配置，内置了服务注册与发现框架，分布一致性协议实现，健康检查，Key/Value 存储，多数据中心方案，不再依赖其他工具。使用相对比较简单。","categories":[{"name":"Consul","slug":"Consul","permalink":"http://phachon.github.io/categories/Consul/"}],"tags":[{"name":"consul","slug":"consul","permalink":"http://phachon.github.io/tags/consul/"}]},{"title":"Consul系列（六）：Consul 的介绍与使用","slug":"consul/consul-6","date":"2018-11-26T05:51:00.000Z","updated":"2022-07-11T01:59:03.319Z","comments":true,"path":"consul/consul-6.html","link":"","permalink":"http://phachon.github.io/consul/consul-6.html","excerpt":"Consul 用于实现分布式的服务发现和配置，内置了服务注册与发现框架，分布一致性协议实现，健康检查，Key/Value 存储，多数据中心方案，不再依赖其他工具。使用相对比较简单。","text":"Consul 用于实现分布式的服务发现和配置，内置了服务注册与发现框架，分布一致性协议实现，健康检查，Key/Value 存储，多数据中心方案，不再依赖其他工具。使用相对比较简单。","categories":[{"name":"Consul","slug":"Consul","permalink":"http://phachon.github.io/categories/Consul/"}],"tags":[{"name":"consul","slug":"consul","permalink":"http://phachon.github.io/tags/consul/"}]},{"title":"mac 下的 Docker 安装","slug":"docker/mac_install","date":"2018-11-26T05:51:00.000Z","updated":"2022-07-11T01:59:03.319Z","comments":true,"path":"docker/mac_install.html","link":"","permalink":"http://phachon.github.io/docker/mac_install.html","excerpt":"","text":"mac 下的 docker 安装","categories":[{"name":"Docker","slug":"Docker","permalink":"http://phachon.github.io/categories/Docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://phachon.github.io/tags/docker/"},{"name":"mac","slug":"mac","permalink":"http://phachon.github.io/tags/mac/"}]},{"title":"Nginx 系列（一）：工作原理","slug":"nginx/Nginx-1","date":"2018-10-07T10:25:15.000Z","updated":"2022-07-11T01:59:03.324Z","comments":true,"path":"nginx/Nginx-1.html","link":"","permalink":"http://phachon.github.io/nginx/Nginx-1.html","excerpt":"Nginx 作为高性能的 HTTP 和 反向代理服务器，被广泛使用在互联网的业务中。经典的比如 Nginx + PHP-FPM 的组合。本篇文章来简单了解一下 Nginx 的基本原理。","text":"Nginx 作为高性能的 HTTP 和 反向代理服务器，被广泛使用在互联网的业务中。经典的比如 Nginx + PHP-FPM 的组合。本篇文章来简单了解一下 Nginx 的基本原理。 Nginx 体系架构总体来说，Nginx 是由 模块 和 内核 组成，内核的设计非常的简洁。完成的工作也非常的简单。其实内核也是由模块组成的。内核的主要任务是： 通过查找配置，将客户端的请求映射到对应的 location 块，在每个 location 块中所配置的一些指令就会去启动不同的模块去完成对应的工作。例如： 1234567location ~ \\.php$ &#123; root html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; include fastcgi_params;&#125; 内核查找将 .php 结尾的请求全部映射到该 location 块中，在该块中又有相关的指令来启动其他的第三方模块来工作。 Nginx 从结构上分为三部分： 核心模块：HTTP 模块，EVENT 模块，MAIL 模块 基础模块：HTTP Access 模块，HTTP FastCGI 模块，HTTP Proxy 模块和 HTTP Rewrite 模块。 第三方模块：HTTP Upstream Request Hash 模块，Notice 模块，Rtmp 模块等等。 当然，如果用能力的话你也可以开发符合自己需求的模块。总体来说，采用了多模块组合的体系架构，使得 Nginx 才能如此的强大。 总体上 Nginx 对一个请求处理的过程如下： Nginx 接受到请求，通过查找配置信息，将请求映射到一个 location 块 location 块在接收到请求后开始执行指令。会涉及到多个 handle 模块和多个 filter 模块。 handle 模块处理请求，并生产响应的内容 filter 模块对生成的响应内容处理并返回 Nginx 进程模型Nginx 的进程模型总体来说是属于多进程模型。在多进程模型下，会有一个唯一的 Master 进程，至少有一个 Worker 进程。在 Worker 进程中的线程数量的不同又可分为两类： 多线程：多线程即 Worker 进程中有多个线程在工作 单线程：单线程即 Worker 进程中有单个线程工作 Nginx 默认是多进程单线程的模型。启用线程池支持，编译时 configure 时需要显式加入 –with-threads 选项。 Master 进程Master 的进程的工作比较简单，主要工作有一下几点： 接受来自外界的信号，向各个 worker 进程发送信号 监控 worker 进程的运行状态，当 worker 进程异常退出，会启用新的 worker reload 平滑重启实现的原理？首先 reload 或者 -HUP pid 会向 master 进程发送一个重载信号，master 接受到信号后，重新加载配置文件，然后重新启动新的 worker 进程，并向老的 worker 进程发送信号，告诉它们可以退出了。老的 worker 进程在接受到信号好，会停止接受新的请求，并处理完当前的请求，然后退出。 Worker 进程Worker 进程才是真正处理我们的网络请求的地方，一个请求，只可能被一个 worker 进程来处理。每个 worker 进程的竞争机会都是相等的。这就出现了问题，当一个请求过来之后，到底是哪个 worker 来执行？ 每一个 worker 进程采用的是 epoll 异步非阻塞的方式来处理请求，epoll 支持监听多个 socket 网络套接字，这些套接字被注册到 listen_fd 变量里。 惊群问题当 listen_fd 有新的 accept() 请求过来的时候，操作系统会唤醒所有的 epoll_wait 该 listen_fd 变量的进程（Nginx 的每一个 worker 进程)。因为操作系统并不知道谁到底可以执行 accept，所以全部都唤醒。但是，最终只能给一个 worker 来执行 accept，其他的 worker 都执行失败。所以这样的子进程似乎都是被 “吓醒” 的，所以又称为 “惊群问题”。惊群问题的解决： 我们最容易想到的，就是全局锁机制。原理类似于分布式的全局锁。具体的实现办法是：nginx 的每一个 worker 进程在被 “惊醒” 之后，都回首先去抢占一个全局的互斥锁。抢到锁的进程，那么恭喜，该进程就获得执行本次请求的机会，开始读写数据。没有抢占到锁的则继续等待下一次机会。这里还需要注意到一点的是，当某个进程处理的工作量达到总设置的一定的比例时（7/8）,则就会停止申请锁。这样可以来均衡各个进程的任务量该方法也是 Nginx 内核解决惊群问题的实现方法。 Nginx 1.9.1 采用新的机制，socket 分片机制。具体实现的原理是依赖操作系统的 Socket RequestPort 功能。选项允许多个socket监听同一个IP地址和端口的组合。内核负载均衡这些进来的sockets连接,将这些socket有效的分片。当SO_REUSEPORT选项没开启时,连接进来时监听socket默认会通知某个进程，每个进程都有自己独立的监听socket.内核决定哪个是有效的socket(进程)得到这个连接。 在 worker 在 accept 这个连接之后，就开始读取数据，解析请求，处理请求，产生数据后，返回给客户端，最后才断开连接。 总体来说，Nginx 的多任务多请求处理机制，其实是抢占式的机制。多个 worker 去抢占。而不是 master 分配。 Worker 进程的数量最好与 CPU 核数一致，并且可以帮到进程到指定的 CPU 内核 Nginx 网络模型Nginx 之所以能够高并发，主要是采用了异步非阻塞的网络并发模型方式。 异步：针对内核的 I/O 事件，当向内核发出 I/O 请求的命令，不用等待 I/O 事件真正发生就返回，可以做另外的事情。 非阻塞IO：针对网络 I/O 操作，例如 socket ，不同等待 socket 是否可以操作，而是将 socket 注册到监听的变量里，通过不断的循环来监听是否有准备好的读写socket再来操作。 Nginx 异步 I/O 的实现是调用的操作系统的异步 I/O，AIO。Nginx 非阻塞 I/O 的实现是通过 select, epoll 机制实现。 所以，Nginx 的异步非阻塞是 AIO + epoll 的机制共同来实现的。 epoll/select/poll 的网络模型的比较这里不再详细介绍。参考阅读 并发服务器的实现方式 Nginx + PHP-FPMPHP-FPM 其实就是php 实现的 fastcgi 进程管理器。PHP-FPM 的优点就是把动态语言与 HTTP Server 分离开来，Nginx 专门来处理一些静态请求。PHP-FPM 来处理动态的请求。 整体的工作流程如下： fastcgi 进程管理器 php-fpm 自身初始化，启动主进程 php-fpm 并且启动多个 cgi 子进程。 主进程的 php-fpm 主要是用来管理 fastcgi 的子进程，监听端口 9000。 fastcgi 子进程等待来自 web server 的连接。 当客户端的请求到达 nginx 时，nginx 通过 location 指令，将所有的 .php 文件都交给 :9000 来处理，即 Nginx 通过 location 指令，将所有的 php 文件交给 9000 的 php-fpm 处理 php-fpm 进程管理器选择并连接到一个进程 cgi 解释器。Nginx 将 cgi 环境变量和标准输入发送到 fastcgi 子进程。 fastcgi 子进程处理完请求后将标准输出和错误信息从同一连接返回给 nginx。当 fastcgi 子进程关闭时，请求便完成。 fastcgi 子进程等待并处理来自 fastcgi 进程管理器的下一个连接。 php-fpm 进程数的配置：123456789# 对于专用服务器，pm可以设置为static。pm = dynamic # 如何控制子进程，选项有static和dynamic。如果选择static，则由pm.max_children指定固定的子进程数。如果选择dynamic，则由下开参数决定：pm.max_children #，子进程最大数pm.start_servers #，启动时的进程数pm.min_spare_servers #，保证空闲进程数最小值，如果空闲进程小于此值，则创建新的子进程pm.max_spare_servers #，保证空闲进程数最大值，如果空闲进程大于此值，此进行清理# 设置每个子进程重生之前服务的请求数. 对于可能存在内存泄漏的第三方模块来说是非常有用的. 如果设置为 ’0′ 则一直接受请求.pm.max_requests = 1000 一般情况下，一个 php-fpm 子进程开启时占用 3-4M,运行一段时间后，会占用 20-30M，所以 php-fpm 进程数需要合理控制，一般对于 8G 内存，可以设置为 100个，最多占用 3G 内存。 总结本篇文章介绍了 Nginx 的工作体系结构和进程模型，以及 Nginx + PHP-FPM 的工作原理。 参考Nginx 工作原理和优化","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://phachon.github.io/categories/Nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://phachon.github.io/tags/nginx/"}]},{"title":"Nginx 系列（二）：源码分析","slug":"nginx/Nginx-2","date":"2018-10-07T10:25:15.000Z","updated":"2022-07-11T01:59:03.324Z","comments":true,"path":"nginx/Nginx-2.html","link":"","permalink":"http://phachon.github.io/nginx/Nginx-2.html","excerpt":"","text":"【理解 Nginx 源码】https://www.kancloud.cn/digest/understandingnginx/202587","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://phachon.github.io/categories/Nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://phachon.github.io/tags/nginx/"}]},{"title":"Mysql 索引系列（五）：覆盖索引","slug":"mysql/mysql-index-5","date":"2018-09-28T12:25:15.000Z","updated":"2022-07-11T01:59:03.322Z","comments":true,"path":"mysql/mysql-index-5.html","link":"","permalink":"http://phachon.github.io/mysql/mysql-index-5.html","excerpt":"","text":"","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/categories/Mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://phachon.github.io/tags/mysql/"}]},{"title":"Mysql 索引系列（四）：前缀索引","slug":"mysql/mysql-index-4","date":"2018-09-28T11:25:15.000Z","updated":"2022-07-11T01:59:03.322Z","comments":true,"path":"mysql/mysql-index-4.html","link":"","permalink":"http://phachon.github.io/mysql/mysql-index-4.html","excerpt":"","text":"","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/categories/Mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://phachon.github.io/tags/mysql/"}]},{"title":"Mysql 索引系列（三）：索引的策略","slug":"mysql/mysql-index-3","date":"2018-09-28T10:25:15.000Z","updated":"2022-07-11T01:59:03.322Z","comments":true,"path":"mysql/mysql-index-3.html","link":"","permalink":"http://phachon.github.io/mysql/mysql-index-3.html","excerpt":"Mysql 的索引使用的是 B Tree 索引，B Tree 索引适用于全健值、键值范围、键前缀查询。所以在创建索引的时候，我们必须了解存储引擎的索引的策略。这样才能使得查询效率尽量达到最优。 本示例中使用的 Mysql 版本是： 5.7.23","text":"Mysql 的索引使用的是 B Tree 索引，B Tree 索引适用于全健值、键值范围、键前缀查询。所以在创建索引的时候，我们必须了解存储引擎的索引的策略。这样才能使得查询效率尽量达到最优。 本示例中使用的 Mysql 版本是： 5.7.23 索引的类型先来介绍一下 Mysql 包含哪些索引类型，以及这些索引的使用场景 普通索引是最基本的索引，没有任何限制。例如：1KEY index_name (`title`) 唯一索引唯一索引的索引列的值必须是唯一的，但允许有空值。如果是联合索引，则列值的组合必须唯一。1UNIQUE index_name (`title`) 主键索引主键索引一种特殊的唯一索引，一个表必须有一个主键，不允许有空值。也就是说主键索引是一种非空的唯一索引。1PRIMARY KEY (`id`) 联合索引除了在单列的字段上设置索引，还可以将多个列上创建索引。使用联合索引必须遵循最左前缀集合，例如：1KEY index_name (`id`, `title`, `age`) 前缀索引有时候需要索引很长的字符列，这会让索引变的大且慢。可以使用前缀索引来来节约索引空间，从而提高索引效率。前缀索引只索引指定的索引开始的部分长度字符。例如：1KEY index_name (title(7))只会索引 title 从开始长度为 7 的字符。 覆盖索引覆盖索引就是就是可以直接通过索引来获取数据，而不需要读取数据行。如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为 覆盖索引。1KEY index_name (`id`, `name`, `age`)如果我们的 sql 查询语句：1select age from user where id=10 and name=&quot;p&quot;;那么使用的就是覆盖索引，因为要查找数据 age 列本身就包含在索引数据中。 全文索引主要用来查找文本中的关键字，而不是直接与索引中的值相比较，跟其他的索引不太一样，更像是搜索引擎。fulltext 索引配合 match against 操作使用。1FULLTEXT (content)MyISAM 引擎支持全文索引，InnoDB 引擎不支持全文索引。 单列索引的索引策略对于单列索引，并不是任何时候查询都会生效，我们通过实例来看一下哪些查询会导致索引失效，这对于我们日常开发是至关重要的。创建表结构如下：123456789101112131415161718DROP TABLE IF EXISTS `index_single_test`;CREATE TABLE `index_single_test` ( `id` int(10) NOT NULL AUTO_INCREMENT COMMENT &#x27;id&#x27;, `name` char(10) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;索引名称&#x27;, `type` char(50) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;类型&#x27;, `size` int(10) NOT NULL DEFAULT 0 COMMENT &#x27;索引长度&#x27;, PRIMARY KEY (`id`), UNIQUE KEY `name` (`name`), KEY `type` (`type`), KEY `size` (`size`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&#x27;单列索引测试表&#x27;;insert into `index_single_test` (index_single_test.name, index_single_test.type, index_single_test.size) values (&#x27;index_1&#x27;,&#x27;key&#x27;, 10);insert into `index_single_test` (index_single_test.name, index_single_test.type, index_single_test.size) values (&#x27;index_2&#x27;,&#x27;join&#x27;, 8);insert into `index_single_test` (index_single_test.name, index_single_test.type, index_single_test.size) values (&#x27;index_3&#x27;,&#x27;primary&#x27;, 8);insert into `index_single_test` (index_single_test.name, index_single_test.type, index_single_test.size) values (&#x27;index_4&#x27;,&#x27;key&#x27;, 9);insert into `index_single_test` (index_single_test.name, index_single_test.type, index_single_test.size) values (&#x27;index_5&#x27;,&#x27;fulltext&#x27;, 4);insert into `index_single_test` (index_single_test.name, index_single_test.type, index_single_test.size) values (&#x27;index_6&#x27;,&#x27;unique&#x27;, 6); 使用索引 name 来查询：123456789101112131415mysql&gt; explain select * from index_single_test where name=&quot;index_1&quot;\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: index_single_test partitions: NULL type: constpossible_keys: name key: name key_len: 30 ref: const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) 我们看到 type = &quot;const&quot;, key = &quot;name&quot; 确实使用索引来查询。 使用 Like 123456789101112131415mysql&gt; explain select * from index_single_test where name like &quot;%index_1&quot;\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: index_single_test partitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 6 filtered: 16.67 Extra: Using where1 row in set, 1 warning (0.00 sec) 很明显，type 变成了 ALL, 全表扫描，没有使用索引 范围查询（between，&lt;&gt;） 123456789101112131415161718192021222324252627282930mysql&gt; explain select * from index_single_test where size between 0 and 5\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: index_single_test partitions: NULL type: rangepossible_keys: size key: size key_len: 4 ref: NULL rows: 1 filtered: 100.00 Extra: Using index condition1 row in set, 1 warning (0.00 sec)mysql&gt; explain select * from index_single_test where size &gt; 0 and size &lt;5\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: index_single_test partitions: NULL type: rangepossible_keys: size key: size key_len: 4 ref: NULL rows: 1 filtered: 100.00 Extra: Using index condition1 row in set, 1 warning (0.00 sec) 可以看到 type=range key=size 是使用索引来查询的。 使用 In 123456789101112131415mysql&gt; explain select * from index_single_test where size in (9,4,6)\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: index_single_test partitions: NULL type: ALLpossible_keys: size key: NULL key_len: NULL ref: NULL rows: 6 filtered: 50.00 Extra: Using where1 row in set, 1 warning (0.01 sec) 可以看到，type = ALL, key = NULL 并没有使用索引。 使用 or 123456789101112131415mysql&gt; explain select * from index_single_test where name=&#x27;index_1&#x27; or id=2\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: index_single_test partitions: NULL type: ALLpossible_keys: PRIMARY,name key: NULL key_len: NULL ref: NULL rows: 6 filtered: 58.33 Extra: Using where1 row in set, 1 warning (0.00 sec) 可以看到，type = ALL, key = NULL 并没有使用索引。即使 id 和 name 字段上都有索引。 单列索引失效的情况总结： 使用 Like 索引失效 使用 In 索引失效 使用 Or 索引失效 联合（多列）索引的索引策略接下来我们来看看联合（多列）索引的索引策略，这里我们创建表结构如下： 123456789101112131415DROP TABLE IF EXISTS `index_double_test`;CREATE TABLE `index_double_test` ( `id` int(10) NOT NULL AUTO_INCREMENT COMMENT &#x27;id&#x27;, `name` char(10) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;索引名称&#x27;, `type` char(50) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;类型&#x27;, `size` int(10) NOT NULL DEFAULT 0 COMMENT &#x27;索引长度&#x27;, PRIMARY KEY (`id`), KEY `name_type_size` (`name`, `type`, `size`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&#x27;多列索引测试表&#x27;;insert into `index_double_test` (index_double_test.name, index_double_test.type, index_double_test.size) values (&#x27;index_1&#x27;,&#x27;key&#x27;, 10);insert into `index_double_test` (index_double_test.name, index_double_test.type, index_double_test.size) values (&#x27;index_2&#x27;,&#x27;join&#x27;, 8);insert into `index_double_test` (index_double_test.name, index_double_test.type, index_double_test.size) values (&#x27;index_3&#x27;,&#x27;primary&#x27;, 8);insert into `index_double_test` (index_double_test.name, index_double_test.type, index_double_test.size) values (&#x27;index_4&#x27;,&#x27;key&#x27;, 9);insert into `index_double_test` (index_double_test.name, index_double_test.type, index_double_test.size) values (&#x27;index_5&#x27;,&#x27;fulltext&#x27;, 4);insert into `index_double_test` (index_double_test.name, index_double_test.type, index_double_test.size) values (&#x27;index_6&#x27;,&#x27;unique&#x27;, 6); 根据最左前缀策略，联合索引对以下的查找有效。 1.全值匹配全值匹配指的是和索引中的所有列都进行匹配。例如：123456789101112131415mysql&gt; explain select * from index_double_test where name=&#x27;index_1&#x27; and type=&#x27;type&#x27; and size=9\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: index_double_test partitions: NULL type: refpossible_keys: name_type_size key: name_type_size key_len: 184 ref: const,const,const rows: 1 filtered: 100.00 Extra: Using index1 row in set, 1 warning (0.00 sec)从索引的使用来看，type = ref key = name_type_size , 并且 key_len 的长度是 184 字节等于 name(3 10) + type(3 50) + 4，能看出来索引三列都匹配。 注意：查询优化器会自动调整 where 子句的条件顺序以使用适合的索引，所以 where 条件顺序颠倒也可以全值匹配。 2.匹配最左前缀即只使用索引的第一列，例如：123456789101112131415mysql&gt; explain select * from index_double_test where name=&#x27;index_1&#x27;\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: index_double_test partitions: NULL type: refpossible_keys: name_type_size key: name_type_size key_len: 30 ref: const rows: 1 filtered: 100.00 Extra: Using index1 row in set, 1 warning (0.01 sec)从索引的使用来看，type = ref key = name_type_size , key_len 是 30 说明只使用了第一列 name(3*10) 来匹配。 3.匹配列前缀也可以只匹配某一列的前缀123456789101112131415mysql&gt; explain select * from index_double_test where name like &quot;ix%&quot;\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: index_double_test partitions: NULL type: rangepossible_keys: name_type_size key: name_type_size key_len: 30 ref: NULL rows: 1 filtered: 100.00 Extra: Using where; Using index1 row in set, 1 warning (0.00 sec)这里看到 key_len 也是 30，说明使用的也是第一列索引来匹配。 4.匹配范围值用于匹配范围查找，示例如下：123456789101112131415mysql&gt; explain select * from index_double_test where name between &#x27;a&#x27; and &#x27;m&#x27;\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: index_double_test partitions: NULL type: rangepossible_keys: name_type_size key: name_type_size key_len: 30 ref: NULL rows: 2 filtered: 100.00 Extra: Using where; Using index1 row in set, 1 warning (0.00 sec)可以看到 key_len 也是 30，说明只使用了索引的第一列来匹配。 5.精确匹配某一列且范围匹配另一列直接上案例12345678910111213141516171819202122232425262728293031mysql&gt; explain select * from index_double_test where name=&#x27;yu&#x27; and type like &#x27;a%&#x27;\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: index_double_test partitions: NULL type: rangepossible_keys: name_type_size key: name_type_size key_len: 180 ref: NULL rows: 1 filtered: 100.00 Extra: Using where; Using index1 row in set, 1 warning (0.00 sec)mysql&gt; explain select * from index_double_test where name=&#x27;yu&#x27; and type like &#x27;%a&#x27;\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: index_double_test partitions: NULL type: refpossible_keys: name_type_size key: name_type_size key_len: 30 ref: const rows: 1 filtered: 16.67 Extra: Using where; Using index1 row in set, 1 warning (0.00 sec)这里第二列我们有两种情况： 第二列使用前缀匹配(like type “a%”)，key_len = 180 则说明使用的是第一列和第二列的索引 第二列使用后缀匹配(like type “%a”)，key_len = 30 则说明只使用了第一列索引，第二列索引无法使用 如果第一列是范围查找第二列是精确查找会一样吗？ 12345678910111213141516171819202122232425262728293031mysql&gt; explain select * from index_double_test where name like &#x27;y%&#x27; and type=&#x27;key&#x27;\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: index_double_test partitions: NULL type: rangepossible_keys: name_type_size key: name_type_size key_len: 180 ref: NULL rows: 1 filtered: 16.67 Extra: Using where; Using index1 row in set, 1 warning (0.00 sec)mysql&gt; explain select * from index_double_test where name like &#x27;%y&#x27; and type=&#x27;key&#x27;\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: index_double_test partitions: NULL type: indexpossible_keys: NULL key: name_type_size key_len: 184 ref: NULL rows: 6 filtered: 16.67 Extra: Using where; Using index1 row in set, 1 warning (0.00 sec) 第一列也有两种情况： 第一列使用前缀匹配(like type “a%”)，key_len = 180 则说明使用的是第一列和第二列的索引 第一列使用后缀匹配(like type “%a”)，type = index 则说明使用的是全索引扫描，效率是比较低的 6.只访问索引的查询这里用到覆盖索引，后面专门的章节来讲。 联合索引使索引失效的情况 不是使用的第一部分，则索引使用全索引扫描 123456789101112131415mysql&gt; explain select * from index_double_test where type=&#x27;key&#x27; and size=9\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: index_double_test partitions: NULL type: indexpossible_keys: NULL key: name_type_size key_len: 184 ref: NULL rows: 6 filtered: 16.67 Extra: Using where; Using index1 row in set, 1 warning (0.00 sec) 查询条件中有 or 123456789101112131415mysql&gt; explain select * from index_double_test where name =&#x27;yu&#x27; or type=&#x27;key&#x27; or size = 8\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: index_double_test partitions: NULL type: indexpossible_keys: name_type_size key: name_type_size key_len: 184 ref: NULL rows: 6 filtered: 42.13 Extra: Using where; Using index1 row in set, 1 warning (0.00 sec) like 查询是以 % 开头上面有演示，这里不再演示 查询条件中有函数或表达式 注意：这里索引失效，并不是不使用索引，可以看到 key = name_type_size, 只是 type = index，即全索引扫描，效率比较差而已 参考《高性能 Mysql 第三版》","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/categories/Mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://phachon.github.io/tags/mysql/"}]},{"title":"Mysql 索引系列（二）：了解并使用 EXPLAIN 命令","slug":"mysql/mysql-index-2","date":"2018-09-28T02:25:15.000Z","updated":"2022-07-11T01:59:03.322Z","comments":true,"path":"mysql/mysql-index-2.html","link":"","permalink":"http://phachon.github.io/mysql/mysql-index-2.html","excerpt":"上一篇文章讲解了 Mysql 在不同的存储引擎下索引的实现，在开始讲解索引的策略以及如何优化索引之前，我觉得有必要先来了解以下如何去使用 EXPLAIN 命令来查看sql 语句的查询方式，因为在后续的文章中，我们会经常使用该命令来调试和分析。除此之外，我们在工作中，也应该习惯去使用 EXPLAIN命令来分析和优化索引。 本示例中使用的 Mysql 版本是： 5.7.23","text":"上一篇文章讲解了 Mysql 在不同的存储引擎下索引的实现，在开始讲解索引的策略以及如何优化索引之前，我觉得有必要先来了解以下如何去使用 EXPLAIN 命令来查看sql 语句的查询方式，因为在后续的文章中，我们会经常使用该命令来调试和分析。除此之外，我们在工作中，也应该习惯去使用 EXPLAIN命令来分析和优化索引。 本示例中使用的 Mysql 版本是： 5.7.23 EXPLAIN 命令简介EXPLAIN 命令用来查看 SQL 语句的执行计划。简单来说，就是通过和这个命令就可以查看该查询执行的详细信息，通过查看并分析这些信息，我们可以优化我们的 SQL 语句和索引，最终来提高我们的查询效率。 使用方法1mysql&gt; explain select * from user id=1\\G 使用比较简单，直接在要查询的 select 语句前加上 explain 准备数据为了演示，这里新建数据库和表并插入一些数据。 12345678910111213141516171819202122232425262728293031323334353637383940414243CREATE TABLE `user` ( `id` int(10) NOT NULL AUTO_INCREMENT COMMENT &#x27;id&#x27;, `first_name` char(10) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;姓&#x27;, `last_name` varchar(10) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;名&#x27;, `age` int(3) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;年龄&#x27;, PRIMARY KEY (`id`), KEY `firstName_lastName_age_index` (`first_name`, `last_name`, `age`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&#x27;用户表&#x27;;CREATE TABLE `video` ( `id` int(10) NOT NULL AUTO_INCREMENT COMMENT &#x27;role id&#x27;, `user_id` int(10) NOT NULL COMMENT &#x27;user id&#x27;, `title` char(100) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;视频标题&#x27;, PRIMARY KEY (`id`), KEY (`user_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&#x27;视频表&#x27;;insert into `user` (first_name, last_name, age) values (&#x27;zhang&#x27;,&#x27;san&#x27;, 1);insert into `user` (first_name, last_name, age) values (&#x27;li&#x27;,&#x27;si&#x27;, 18);insert into `user` (first_name, last_name, age) values (&#x27;wang&#x27;,&#x27;wu&#x27;, 21);insert into `user` (first_name, last_name, age) values (&#x27;pan&#x27;,&#x27;liu&#x27;, 41);insert into `user` (first_name, last_name, age) values (&#x27;jin&#x27;,&#x27;qi&#x27;, 16);insert into `user` (first_name, last_name, age) values (&#x27;yang&#x27;,&#x27;ba&#x27;, 8);insert into `user` (first_name, last_name, age) values (&#x27;yu&#x27;,&#x27;jiu&#x27;, 9);insert into `user` (first_name, last_name, age) values (&#x27;ding&#x27;,&#x27;q&#x27;, 10);insert into `user` (first_name, last_name, age) values (&#x27;wu&#x27;,&#x27;w&#x27;, 13);insert into `user` (first_name, last_name, age) values (&#x27;zhao&#x27;,&#x27;u&#x27;, 51);insert into `user` (first_name, last_name, age) values (&#x27;qian&#x27;,&#x27;k&#x27;, 61);insert into `user` (first_name, last_name, age) values (&#x27;zheng&#x27;,&#x27;o&#x27;, 31);insert into `user` (first_name, last_name, age) values (&#x27;zhou&#x27;,&#x27;z&#x27;, 10);insert into `video` (user_id, title) values (1, &#x27;v1&#x27;);insert into `video` (user_id, title) values (1, &#x27;v2&#x27;);insert into `video` (user_id, title) values (2, &#x27;v3&#x27;);insert into `video` (user_id, title) values (2, &#x27;v3&#x27;);insert into `video` (user_id, title) values (7, &#x27;v9&#x27;);insert into `video` (user_id, title) values (1, &#x27;v0&#x27;);insert into `video` (user_id, title) values (3, &#x27;v1&#x27;);insert into `video` (user_id, title) values (4, &#x27;v8&#x27;);insert into `video` (user_id, title) values (6, &#x27;v9&#x27;);insert into `video` (user_id, title) values (8, &#x27;v14&#x27;);insert into `video` (user_id, title) values (5, &#x27;v3&#x27;);insert into `video` (user_id, title) values (4, &#x27;v11&#x27;); 123456789101112131415mysql&gt; explain select * from user where id=1\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user partitions: NULL type: constpossible_keys: PRIMARY key: PRIMARY key_len: 4 ref: const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) 列字段解释idselect 查询的标识符，每个 select 都会自动分配一个唯一的标示符 select_typeselect_type 表示查询的类型，通常有如下值： SIMPLE 表示此查询是简单查询，即不包含 UNION 或子查询 PRIMARY 表示此查询是最外层的查询 UNION 表示此查询是 UNION 的第二个或者随后的查询 DEPENDENT UNION 表示 UNION 的第二个或后面的查询，取决于外面的查询 UNION RESULT 表示 UNION 的结果 SUBQUERY 子查询中的第一个 SELECT DEPENDENT SUBQUERY 子查询中的第一个 SELECT ,取决于外面的查询，即子查询依赖于外层的查询结果 最常见的就是 SIMPLE 查询，查询没有子查询，也没有 UNION 查询时，通常就是 SIMPLE123456789101112131415mysql&gt; explain select * from user where id=1\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user partitions: NULL type: constpossible_keys: PRIMARY key: PRIMARY key_len: 4 ref: const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) 使用了 UNION 查询，输出结果如下：123456789mysql&gt; explain (select * from user where id=1) union (select * from user where id=2);+----+--------------+------------+------------+-------+---------------+---------+---------+-------+------+----------+-----------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+--------------+------------+------------+-------+---------------+---------+---------+-------+------+----------+-----------------+| 1 | PRIMARY | user | NULL | const | PRIMARY | PRIMARY | 4 | const | 1 | 100.00 | NULL || 2 | UNION | user | NULL | const | PRIMARY | PRIMARY | 4 | const | 1 | 100.00 | NULL || NULL | UNION RESULT | &lt;union1,2&gt; | NULL | ALL | NULL | NULL | NULL | NULL | NULL | NULL | Using temporary |+----+--------------+------------+------------+-------+---------------+---------+---------+-------+------+----------+-----------------+3 rows in set, 1 warning (0.00 sec) table查询涉及的表或者衍生表 partitions匹配的分区 typetype 字段比较重要，表示数据的查询类型，根据 type 字段判断是全表扫描还是索引扫描 system：表中只有一条数据，是特殊的 const const：针对主键或唯一索引的等值查询扫描，最多只返回一条数据。const 查询速度非常快，因为仅仅读取一次即可。例如： 123456789101112131415mysql&gt; explain select * from user where id=1\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user partitions: NULL type: constpossible_keys: PRIMARY key: PRIMARY key_len: 4 ref: const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.04 sec) eq_ref：此类型通常出现在多表的 join 查询，表示前表的每一个结果，都只能匹配到后表的一行结果，查询的操作符通常是 =，查询效率比较高： 12345678910111213141516171819202122232425262728mysql&gt; explain select * from user,video where user.id=video.user_id\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: video partitions: NULL type: indexpossible_keys: user_id,user_id_2 key: user_id_2 key_len: 304 ref: NULL rows: 12 filtered: 100.00 Extra: Using index*************************** 2. row *************************** id: 1 select_type: SIMPLE table: user partitions: NULL type: eq_refpossible_keys: PRIMARY key: PRIMARY key_len: 4 ref: test.video.user_id rows: 1 filtered: 100.00 Extra: NULL2 rows in set, 1 warning (0.00 sec) ref：此类型通常出现在多表的 join 查询，针对于非唯一索引或主键索引，或者是使用了 最左前缀 规则索引的查询。 range：表示使用的是范围查询，通过索引字段范围获取表中部分数据记录，这个类型通常出现在 =，&lt;&gt;,&gt;,&lt;=,&gt;=, IS NULL, &lt;=&gt;, between, in() 操作中。type 是 range，explain 输出的 ref 字段为 NULL，并且 key_len 字段是此次查询中使用到的最长的那个索引。 123456789101112131415161718192021222324252627282930mysql&gt; explain select * from user where user.id &gt; 0 and user.id &lt;40\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user partitions: NULL type: rangepossible_keys: PRIMARY key: PRIMARY key_len: 4 ref: NULL rows: 13 filtered: 100.00 Extra: Using where1 row in set, 1 warning (0.00 sec)mysql&gt; explain select age from user where age between 0 and 40\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user partitions: NULL type: rangepossible_keys: age key: age key_len: 4 ref: NULL rows: 10 filtered: 100.00 Extra: Using where; Using index1 row in set, 1 warning (0.00 sec) index：表示全索引扫描，和 all 类型类似，只不过 all 类型是全表扫描，而 index 类型只扫描所有的索引，而不是扫描数据。通常情况下，index 出现在所要查询的数据直接出现在索引树中就可以直接获取到，而不需要扫描数据。一般 Extra 字段会显示 Using index。 123456789101112131415mysql&gt; explain select * from user where age between 0 and 40\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user partitions: NULL type: indexpossible_keys: age key: first_name_2 key_len: 64 ref: NULL rows: 13 filtered: 76.92 Extra: Using where; Using index1 row in set, 1 warning (0.00 sec) 从 range 里面的示例和上面的示例我们可以看到两条相似的语句使用的查询类型不一样，原因是：因为 age 是索引，当使用 select age，直接可以通过二级索引树查到范围数据，所以是 range当使用 select * , 因为二级索引只能查到 age 和主键，想要查到所有数据集，需要再次回到主索引树查找，因此退化成了 index, 也就是需要全索引扫描 all：表示全表扫描，这个是最差的扫描。如果出现了 all，那么我们应该优化掉。对于大数据量的情况下，这将是灾难。123456789101112131415mysql&gt; explain select * from video where video.title=&quot;v1&quot;\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: video partitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 12 filtered: 10.00 Extra: Using where1 row in set, 1 warning (0.00 sec) title 不是索引，所以只能全表扫描。 type 的性能比较： all &lt; index &lt; range &lt; ref &lt; eq_ref &lt; const &lt; system possible_keys表示在 Mysql 查询时可能使用到的索引，注意，即使有些索引在 possible_key 出现，但是并不表示此索引会被真正的被 Mysql 用到。具体使用的是哪些索引，由字段 key 表示 key表示 Mysql 在查询中真正使用到的索引。 key_len表示查询优化器在使用了索引的字节数，这个字段可以评估组合索引是否完全被使用，或者是只使用了最左部分，key_len 的计算规则如下： 字符串类型 char(n): 如果是 uft8 编码，则是 3n 字节; utf8mb4 编码，则是 4n 字节 varchar(n): 如果是 uft8 编码，则是 3n+2 字节; utf8mb4 编码，则是 4n+2 字节注意：如果属性不是 NOT NULL, 则需要多加 1 个字节。 数值类型 TINYINT: 1 字节 SMALLINT: 2 字节 MEDIUMINT: 3 字节 INT: 4 字节 BIGINT: 8 字节 时间类型 DATE: 3 字节 TIMESTAMP: 4 字节 DATETIME: 8 字节 在 user 表中我们有联合索引 KEY (first_name, last_name, age) 举例说明:123456789101112131415mysql&gt; explain select * from user where first_name=&#x27;yu&#x27;\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user partitions: NULL type: refpossible_keys: firstName_lastName_age_index key: firstName_lastName_age_index key_len: 30 ref: const rows: 1 filtered: 100.00 Extra: Using index1 row in set, 1 warning (0.00 sec)我们的查询语句使用的是 first_name=&#39;yu&#39;，根据最左匹配原则，只匹配了第一列 first_name, first_name 的字段类型是 char, 且是 NOT NULL, 所以 key_len 是 30, 表示只使用了 30 字节的索引长度。再来看一个例子： 123456789101112131415mysql&gt; explain select * from user where first_name=&#x27;yu&#x27; and last_name=&quot;jiu&quot;\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user partitions: NULL type: refpossible_keys: firstName_lastName_age_index key: firstName_lastName_age_index key_len: 62 ref: const,const rows: 1 filtered: 100.00 Extra: Using index1 row in set, 1 warning (0.00 sec) 这个例子中匹配了前两列，所以是 key_len(first_name) + key_len(last_name) 等于 3 10 + 3 10 + 2 = 62 字节 ref哪个字段或常数与 key 一起被使用 rowsrows 也是一个重要的字段. MySQL 查询优化器根据统计信息, 估算 SQL 要查找到结果集需要扫描读取的数据行数。 filtered表示此查询条件所过滤的数据的百分比 ExtraExtra 的信息表示额外的信息。常见的有以下几种内容： Using filesort当出现 Using filesort 时，表示需要额外的排序操作，不能通过索引顺序达到排序的效果，这种情况下一般都建议优化掉。例如： 123456789101112131415mysql&gt; explain select * from user order by age desc\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user partitions: NULL type: indexpossible_keys: NULL key: firstName_lastName_age_index key_len: 66 ref: NULL rows: 13 filtered: 100.00 Extra: Using index; Using filesort1 row in set, 1 warning (0.00 sec) Using index“覆盖索引扫描”, 表示查询在索引树中就可查找所需数据, 不用扫描表数据文件, 一般性能不错 Using temporary查询有使用临时表, 一般出现于排序, 分组和多表 join 的情况, 查询效率不高, 建议优化. 总结简单的介绍了以下 explain 的使用方法以及各种参数的意义。通常，我们应该经常来使用 explain 语句来分析我们的查询语句是否可以优化。尤其是判断索引的创建是否合理。 参考MySQL 性能优化神器 Explain 使用分析","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/categories/Mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://phachon.github.io/tags/mysql/"}]},{"title":"Mysql 部署系列 - 主从同步","slug":"mysql/mysql-deploy-1","date":"2018-09-28T01:15:45.000Z","updated":"2022-07-11T01:59:03.322Z","comments":true,"path":"mysql/mysql-deploy-1.html","link":"","permalink":"http://phachon.github.io/mysql/mysql-deploy-1.html","excerpt":"","text":"参考资料：","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/categories/Mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://phachon.github.io/tags/mysql/"}]},{"title":"Mysql 索引系列（一）：索引的实现","slug":"mysql/mysql-index-1","date":"2018-09-28T01:15:45.000Z","updated":"2022-07-11T01:59:03.322Z","comments":true,"path":"mysql/mysql-index-1.html","link":"","permalink":"http://phachon.github.io/mysql/mysql-index-1.html","excerpt":"Mysql 数据库是目前最流行使用最广泛的关系型数据库，通过本系列来复习一下 Mysql 索引相关的知识。本篇文章来讲解一下索引的具体实现。","text":"Mysql 数据库是目前最流行使用最广泛的关系型数据库，通过本系列来复习一下 Mysql 索引相关的知识。本篇文章来讲解一下索引的具体实现。 为什么要使用索引1什么是索引？为什么要使用索引？ 索引就是存储引擎用于快速找到记录的一种数据结构。把数据库比做一本书，如果查找内容就需要每一页每一页的找，那岂不是效率很低。那么我们设计了一套规则： 将书分按照一章一章的分类，每一章又分为不同的小章节 将分好的章节信息保存在目录页里 每次查询的时候我们先查找目录，找到目标的章节，最后一直找到想要找到的内容。 通俗来说，索引的设计就是用来加快数据库的访问速度。 索引的实现方式通常为了加快数据的速度，一般两种数据结构来实现： Hash 哈希 Tree 树 Hash 结构通过 Hash 函数将数据映射到哈希桶里，哈希桶是顺序存储的数据结构，所以插入/更新/删除数据时，可以直接找到数据的位置，时间复杂度是 O(1)。可以说是非常快速 Mysql 的 memory 存储引擎使用的就是哈希索引。 Tree 结构二叉搜索树二叉搜索树是我们最熟悉页最常见的树结构，如下图所示： 我们看到，由于二叉搜索树是二叉的，所以当数据量很大的时候，存在以下问题： 树的高度比较高 每个节点只能存储一条记录，每次查询到该节点都要进行磁盘 I/O 二叉搜索树的查找时间复杂度是 O(logn) B 树为了适用数据库的查找，发明了 B 树的数据结构，实际上是一种多路搜索树，如下图所示： B 树的特点是： 不再是二叉，而是多叉 叶子节点和非叶子节点都存储数据 每个非根节点可以存储多条记录，个数满足 (m/2 - 1) &lt;= j &lt;= m-1 中序遍历可以获取所有节点 可以发现，B 树相对于二叉搜索树，高度大大降低，并且每个非叶子节点可以存储多条记录，这样做有什么好处？这是因为这样做，可以利用局部性原理来降低磁盘 I/O，提高读取效率。 这里简单解释一下局部性原理。 局部性原理 磁盘的读取相对内存来说要慢很多，所以应尽量减少磁盘的读取操作。 磁盘预读，磁盘一次读取，并不会按需读取，而是按页读取，一次读一页，如果以后要读的数据就在这一页中，就可以避免再次读取磁盘，提高效率。 软件或程序设计过程中应该尽量遵循这样的原则，例如，对于 B 树的非叶子节点来说，每个节点可以设置为一页的数据，只需读取一次即可。 通常，磁盘读取一页的数据是 4k B 树一般被用来设计做数据库的索引的优势： 多叉搜索树，高度降低。 每个节点存储多个记录，利用局部性原理，降低了磁盘读取次数，提高了读取效率 1哈希索引更快更简单，数据库为什么不使用哈希索引？ 哈希索引是更快，但是哈希索引对于 分组（group by）排序（order by）以及范围查找（&gt; &lt;）需要全表扫描才行，时间复杂读退化为 O(n) Mysql Innodb 索引的实现Mysql Innodb 存储引擎的索引使用的是在 B 树上优化的一种数据结构，B+ 树。B+ 树也是多路搜索树，是在 B 树的基础上优化而来，如下图所示： B+ 树具备 B 树的优点，同时又做了以下优化： 非叶子节点上不再存储数据，只记录记录的key，只有叶子节点上才存储数据记录 所有的叶子节点，都通过链表连接起来，方便了范围查找 优化的好处： 非叶子节点不存数据，只记录 key，相同内存下，B+树存储更多的索引 增加的链表，方便了范围查找。 聚集索引和非聚集索引这里简单介绍下聚集索引和非聚集索引的区别。 聚集索引聚集索引就是索引和数据记录存储在一起的索引，例如在上面说的 B+树的数据结构中，叶子节点最终保存的不仅是索引的 key ，还包括索引的数据。InnoDB 就是使用的聚集索引，如下图就是 InnoDB 的主键索引的存储结构： 可以看到叶子节点上本身就存在数据，所以通过索引查找可以直接查找到数据。 聚集索引的好处： 可以把数据保存在一起。只需要从磁盘读取少数的数据也就能获取数据。 数据访问更快。 使用覆盖索引扫描的查询可以直接使用节点的主键值 非聚集索引和聚集索引相反，非聚集索引就是数据和索引分开存储的索引。MyISAM 使用的就是非聚集索引 可以看到，叶子节点存储的的是索引的 key 和 行号, 行号即索引数据在数据文件的位置。 二级索引对于 InnoDB 来说，主键索引是聚集索引，但是二级索引（辅助索引）和聚集索引很不相同。InnoDB 二级索引的叶子节点存储的是主键值，所以，二级索引查找可能需要查找两次首先根据索引查找到数据的主键值，然后再根据主键从主键索引查到数据。 所以，从这一点来看，我们就明白了 InnoDB 必须存在主键，如果没有显示的主键，InnoDB 会先查找非空的唯一索引当主键，否则会自己生成一个隐藏的主键。 对于 MyISAM 来说，二级索引和主键索引的实现方式一样。 总结只有了解了索引的底层实现，才能更好的使用索引和优化索引。","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/categories/Mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://phachon.github.io/tags/mysql/"}]},{"title":"Mysql 内核系列 - 事务","slug":"mysql/mysql-kernel-begin","date":"2018-09-28T01:15:45.000Z","updated":"2022-07-11T01:59:03.323Z","comments":true,"path":"mysql/mysql-kernel-begin.html","link":"","permalink":"http://phachon.github.io/mysql/mysql-kernel-begin.html","excerpt":"","text":"参考资料： 4种事务的隔离级别，InnoDB如何巧妙实现？","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/categories/Mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://phachon.github.io/tags/mysql/"}]},{"title":"Mysql 内核系列 - 锁机制","slug":"mysql/mysql-kernel-lock","date":"2018-09-28T01:15:45.000Z","updated":"2022-07-11T01:59:03.323Z","comments":true,"path":"mysql/mysql-kernel-lock.html","link":"","permalink":"http://phachon.github.io/mysql/mysql-kernel-lock.html","excerpt":"","text":"参考资料： 关于MySQL内核，一定要知道的！ MYSQL优化有理有据全分析","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/categories/Mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://phachon.github.io/tags/mysql/"}]},{"title":"Mysql 内核系列 - 查询流程","slug":"mysql/mysql-kernel-select","date":"2018-09-28T01:15:45.000Z","updated":"2022-07-11T01:59:03.323Z","comments":true,"path":"mysql/mysql-kernel-select.html","link":"","permalink":"http://phachon.github.io/mysql/mysql-kernel-select.html","excerpt":"","text":"参考资料：","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/categories/Mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://phachon.github.io/tags/mysql/"}]},{"title":"Redis系列（五）：Redis 缓存机制与淘汰策略","slug":"redis/redis-5","date":"2018-09-26T09:41:47.000Z","updated":"2022-07-11T01:59:03.325Z","comments":true,"path":"redis/redis-5.html","link":"","permalink":"http://phachon.github.io/redis/redis-5.html","excerpt":"Redis 是基于内存的 Key Value 的 NoSql 数据库，由于其高性能，高可用，支持分布式集群的优点被广泛应用于缓存的业务场景。本篇文章就来详细了解下 Redis 缓存机制及内存淘汰策略。","text":"Redis 是基于内存的 Key Value 的 NoSql 数据库，由于其高性能，高可用，支持分布式集群的优点被广泛应用于缓存的业务场景。本篇文章就来详细了解下 Redis 缓存机制及内存淘汰策略。 如何使用缓存？我们先来插入一个最简单的 key 123127.0.0.1:6379&gt; set name phachonOK127.0.0.1:6379&gt; OK, 插入成功。我们再来设置一下 key 的过期时间, redis 有 4 个命令来设置过期时间： EXPIRE ：key 的生存时间设置为 ttl 秒 PEXPIRE ：key 的生存时间设置为 ttl 毫秒 EXPIREAT ：将 key 的过期时间设置为 timestamp 指定的秒数时间戳 PEXPIREAT ：将 key 的过期时间设置为 timestamp 指定的毫秒数时间戳 12345678127.0.0.1:6379&gt; EXPIRE name 1000(integer) 1127.0.0.1:6379&gt; PEXPIRE name 30000(integer) 1127.0.0.1:6379&gt; EXPIREAT name 1539331476(integer) 1127.0.0.1:6379&gt; PEXPIREAT name 1539337307000(integer) 1 OK, 该 key 在 1000s 之后将过期。过期之前我们可以通过命令查看剩余的时间 123127.0.0.1:6379&gt; ttl name(integer) 936127.0.0.1:6379&gt; 可以看到，剩余 936s 该 key 才会过期，ttl 返回的是秒，如果想要看剩余多少毫秒，可以使用 pttl 命令 有的时候，我们可以将 set 和 expire 命令合并一个命令使用 123127.0.0.1:6379&gt; setex name 1000 phachonOK127.0.0.1:6379&gt; 注意：setex 命令只能对字符串类型的数据进行 set 和 expire 操作。 看来使用缓存的方法是非常的简单。这里只演示了字符串类型的数据，其他的数据类型也是用的 expire 命令来设置过期时间。 如何判断过期？RedisDb 结构的 expires 字典保存了所有 key 的过期时间。1那么 Redis 是使用什么方法来判断时间是否过期并删除呢？在了解 Redis 的删除过期键的策略之前我们来看看有哪些方式可以实现： 定时删除定时删除恐怕是我们最容易想到的方法了，原理就是在一个 key 被设置了过期时间之后，启动一个定时器，当定时器到了过期时间，则删除掉这个 key。该种方法肯定能保证键的过期删除，并且不会有遗漏的键，但是要为每一个key实现一个定时器，会耗费较多的资源，无疑会对 CPU 和当前任务造成影响。 定期删除定期删除策略的原理就是规定一定时间内定期的扫描一遍 expires 字典，将已过期的键删除掉。这种方法解决了定时删除的耗费资源的问题，但是该种方法不能保证所有的 key 过期删除。例如：key1 生存时间是 3s, 而定期删除的时间间隔是 5s, 那这个 key 在 3 秒后还存在内存中，并没有被删除。 惰性删除惰性删除的原理是，在获取每一个 key 的时候，判断一下该 key 是否已经过了过期时间，如果已经失效，则删除掉这个 key。惰性删除的缺点也很明显，如果一个 key 一直不使用，则即使到了过期时间也会一直占有内存，大量的不使用的 key 会使得内存暴增。 综合三种过期键删除的策略我们发现似乎都不能很好的完成过期键的精确删除。Redis 采用了两种删除策略来协同工作： 定期删除 + 惰性删除 使用定期删除策略：Redis 会每隔一段时间（默认是 100 ms）会从所有的 key 中随机获取一些 key ，判断时间是否过期，是，则删除。1为什么不直接获取整个数据，而只随机找到一些 key 来判断，这样不是还有可能会造成某些 key 一直未被判断？ 如果每隔 100ms 检查所有的 key, 如果数据库有 1000 万缓存key，那 redis 岂不是卡死。 采用定期删除之后，还是会导致很多的已过期的缓存 key 没有被删除。 使用惰性删除策略：Redis 会在每次 get key 的时候先判断该 key 的过期时间，已经过期，则删除。 1采用了 定期删除 + 惰性删除 的策略，假如有一个 key , 即没有被定期删除随机获取到，也没有被使用，那么这个 key 岂不是永远还占用着内存？ 没错，即使采用了 定期删除+惰性删除 的策略，还是不能保证所有的过期 key 都被删除。这种情况下，还是会导致内存占用率增高。 有解决办法吗，有！那就是启用 内存淘汰策略！ 内存淘汰策略内存淘汰策略：Redis 每执行一个命令，就会判断当前占用的内存是否大于设置的最大内存，大于，则开始内存淘汰机制。 12# 设置最大的内存，如果不设置该值的话，会导致 redis 一直运行最终以内存不足而终止# maxmemory &lt;bytes&gt; Redis 内存淘汰的机制有以下几种方案可供选择： volatile-lru：从设置过期的数据集中淘汰最少使用的 key volatile-ttl：从设置过期的数据集中淘汰即将过期的 key volatile-random：从设置过期的数据集中随机选取 key 淘汰 allkeys-lru：从所有的数据集中选取最少使用的数据 allkyes-random：从所有的数据集中任意选取数据淘汰 no-envicition：不进行淘汰 注意这 6 主机制。volatile 和 allkeys 规定了是对已设置过期的数据集还是从全部的数据集淘汰数据。具体的使用应根据不同的业务场景来配置不同的策略。一般来说，使用 volatile-lru 或者 allkeys-lru 是比较合理的。删除最少使用的 key。如果使用 redis 作为缓存，就使用 volatile-lru 。如果除了缓存还使用存储，就使用 allkeys-lru。 注意：ttl 和 random 的实现方法比较简单，lru 的实现方法是 redis 会随机挑选几个键值对，然后取出lru 最大的键值对淘汰。所以并不是严格的就会淘汰整个数据集中最少使用的 key，而是随机数据集中的最少使用的 key。 AOF、RDB 和复制功能对过期键的处理1那么 AOF、RDB持久化和复制功能对过期策略会有什么影响呢？ AOF、RDB持久化和主从复制的实现原理这里不再详细介绍，可参考之前写的文章。 RDB 文件的生成和载入当执行 SAVE 或者是 BGSAVE 命令的时候，程序会对数据库中所有的键进行检查，已过期的键不会被保存到新创建的 RDB 文件中。 所以数据库保存过期键不会对 RDB 文件的创建产生影响。 当服务启动的时候，如果开启了 快照持久化 则会载入 rdb 文件，如果是主从同步模式的集群模式，不同的节点的处理不一样： 如果启动的服务节点是 Master 节点，则程序会对 rdb 文件中的键检查，只会将未过期的键载入到内存中。过期的键会忽略。 如果启动的服务节点是 Slave 节点：则程序不会对 rdb 文件中键检查，不论是否过期都会载入到数据库中。因为主从同步模式，当从节点重启之后，会再次和主节点同步，所以，最后数据会和主节点保持一致。过期的 key 依然会被删除。 AOF 文件的写入当服务时开启了 AOF 的持久化机制时，如果某个 key 已过期，但是还是没有被 定期删除 和 惰性删除 清理掉，程序不会对 aof 文件做任何操作。当过期的 key 被 定期删除 和 惰性删除 删除之后，程序会向 aof 文件写一条 DEL 命令来记录该键被删除。举例说明：客户端使用 GET message 命令，试图访问过期的 key，那么程序执行以下步骤： 从数据库中删除 message 键 在 aof 文件追加一条 DEL 命令 向客户端返回空 AOF 重写日志如果开启了 AOF 重写机制，再重写的子进程开始时，程序会对数据库中的 key 检查，并且只会将未过期的 key 写入到 aof 临时文件中。 主从复制在处于主从复制的模式中，如果主服务器的过期键要删除： 主服务器在删除了自己的数据之后，会发送一个 DEL 的命令给从服务器，告知从服务器这个键要删除 从服务器只有在接受到这个 DEL 命令才会真正的将数据删除，即使从服务器在执行自己的 定期删除 和 惰性删除时，也不会删除该数据。 从服务只会在接受到主服务器的 DEL 命令才会删除过期键 主从复制规定数据的过期删除完全由主节点服务器来控制，正是通过这种机制，才能保证主从服务器的数据一致性。 总结通过上面过期机制的了解，我们发现 Redis 并不能保证所有的 key 都能准时过期并删除。所以通过多种机制来协作保证。主要是采用：定期删除 + 惰性删除 + 内存淘汰策略 参考《Redis 设计与实现》Redis的缓存策略和主键失效机制","categories":[{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://phachon.github.io/tags/redis/"}]},{"title":"Redis系列（四）：Redis 持久化机制","slug":"redis/redis-4","date":"2018-09-25T09:41:47.000Z","updated":"2022-07-11T01:59:03.325Z","comments":true,"path":"redis/redis-4.html","link":"","permalink":"http://phachon.github.io/redis/redis-4.html","excerpt":"Redis 作为最流行的非关系型数据库之一，既然是数据库就应该具备数据持久化的机制，本篇文章将针对 Redis 的数据持久化与数据恢复来进行讨论。","text":"Redis 作为最流行的非关系型数据库之一，既然是数据库就应该具备数据持久化的机制，本篇文章将针对 Redis 的数据持久化与数据恢复来进行讨论。 什么是持久化？简单来说，持久化就是将数据放到即使断电后数据也不会丢失的设备中，一般是物理设备，通常理解为硬盘 Redis 持久化机制Redis 提供了两种持久化机制，分别是 Snapshotting（快照&amp;RDB）和 AOF（Append Only File）持久化机制。 快照持久化快照是 Redis 默认的持久化方式，这种方式就是将内存中的数据以快照的方式写入到二进制文件中，默认的文件名为 dump.rdb，默认文件在 Redis 启动的当前目录下，rdb 文件的路径可通过配置文件更改。我们也可以配置 Redis 在 n 秒内如果超过 m 个 key 被修改就自动做快照，默认的快照持久化的配置如下： 1234567# 快照持久化的配置save 900 1 // 900 秒内超过 1 个 key 被修改就执行快照save 300 10 // 300 秒内超过 10 个 key 被修改就执行快照save 60 10000 // 60 秒内超过 10000 个 key 被修改就执行快照# 快照 rdb 文件的位置dbfilename dump.rdb 快照的执行过程： 客户端手动执行 save 或 bgsave 命令发起执行快照的请求或者 redis 触发了执行快照的条件发起快照请求 redis 调用 fork 函数，创建新的子进程 为了不影响 redis 的本身的工作，父进程继续处理 Client 的请求，子进程负责将内存中的内容写到临时文件中。 这里需要注意的是，由于操作系统的写时复制机制，也就是说发生 fork 的时候，父进程和子进程是共享相同的内存空间，当父进程接受到写处理请求时，操作系统会为主进程创建要修改的数据的副本，而不影响子进程的数据。所以子进程快照的数据是 fork 那一刻整个数据库的数据 当子进程写完临时文件之后，用临时文件替换掉原来的快照文件，然后子进程退出。 注意点： 快照持久化方式是每次都将内存中的数据持久化数据完整的写入到磁盘，并不是只同步增量的数据，如果数据量很大的话，写操作比较多，会引起大量的磁盘 I/O, 可能会严重影响性能。 关于 save 和 bgsave 命令，都是用来快照镜像的操作.save 命令是在 redis 主线程中操作的，会阻塞所有的 Client 的请求。不推荐使用 bgsave 命令是非阻塞的方式来对数据快照。是推荐的使用快照的方式。 AOF 持久化既然已经有了快照的持久化方式，还需要 AOF 持久化吗？我们来分析一种情况：由于 Redis 快照的方式并不是实时的，是在一定的时间间隔内才执行快照操作，事实上也不能实时快照，数据量比较大的情况下，磁盘 I/O 会严重影响性能。如果在 Redis 上一次持久化之后到下一次持久化之间，Redis 突然 down 掉了。那岂不是有部分数据没有持久化到磁盘，操作数据丢失。如此一来，就需要依靠 AOF 的持久化机制来保证数据的完整性。 Append Only File，读取字面意思，就是将数据追加到文件中。其工作原理是Redis 在执行完一个写命令之后，会以协议的格式将被执行的写命令追加到服务器的 aof_buf 缓冲区的末尾 AOF 文件的写入与同步Redis 的服务器进程是一个事件轮训（loop），这个循环中的 文件事件 负责接受客户端的命令请求，以及向客户端发送命令回复，时间事件则负责执行定时运行的一些函数。在处理文件事件时，会执行一些写命令，这些写命令被追加到 aof_buf 缓冲区中。服务器在事件执行完毕后都会调用 flushAppendOnlyFile() 函数来判断是否将 aof 缓冲区的数据写入和保存到 AOF 文件中，默写入的文件是 appendonly.aof。1234567891011def eventLoop(): # 开始事件轮询 while True: # 文件事件 fileEvents() # 定时事件 cronEvents() # 其他事件 otherEvents() # 判断是否将 aof 缓冲区的数据写入和同步到 aof文件中 flushAppendOnlyFile()flushAppendOnlyFile() 函数的写入和同步行为由 Redis 服务端的配置来决定的： 关于写入和同步：为了提高文件的写入效率，现在的操作系统中，当用户调用 write 函数，将一些数据写入到文件中，操作系统通常会将写入数据暂时保存在一个内存缓冲区里，等到缓冲区填满或者超过里指定的时限之后，才真正的将缓冲区的数据同步到磁盘里。这种做法虽然提高里效率，但是同样带来了数据丢失的风险，所以，系统提供了 fasync 和 fdatasync 的两个同步函数，可以将缓冲区里的数据写入（同步到）到磁盘里，从而确保数据的安全性。 12345678910111213# 启用 aof 的持久化机制appendonly yes# aof 文件的位置appendfilename &quot;appendonly.aof&quot;# 持久化的时机：always、everysec、noappendfsync everysecno-appendfsync-on-rewrite noauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb# redis在恢复时，会忽略最后一条可能存在问题的指令。默认值yes。# aof 写入时，可能存在指令写错的问题(突然断电，写了一半)，# 这种情况下，yes会log并继续，而no会直接恢复失败.aof-load-truncated yes always 将 aof_buf 缓冲区的所有内容写入 aof 文件，并完成磁盘的同步，速度最慢，但是最安全，不会丢失数据 everysec 将 aof_bug 缓冲区所有内容写入 aof 文件，如果上次同步 aof 文件的时间距离现在超过1秒，那么再次执行同步。默认的配置，最多会有 1 秒的数据丢失 no 将 aof_buf 缓冲区的所有内容写入 aof 文件，但是并不对 aof 文件进行同步，何时同步由操作系统同步。速度最快，可能会丢失计较多的数据 注意： del 命令如果删除一个不存在的 key 并不会被记录在 aof 日志中因为 redis 判断出该操作并没有对数据集做出修改。 AOF 持久化的问题持久化的 aof 文件越来越大，所有的写操作都会追加到 aof 日志文件里，但其实恢复数据只往往需要最后的几条写命令。所以为了解决这个问题，redis 提供了 BGREWRITEAOF 命令压缩持久化文件。 AOF 文件重写压缩原理收到此命令之后，redis 会使用和快照类似的方式将内存中的数据以命令的方式保存到临时文件中，最后替换原来的 aof 文件。具体的过程如下： redis 收到 BGREWRITEAOF命令 redis 调用 fork 函数，创建新的子进程 父进程继续处理 client 请求，除了把命令继续写入到 aof 文件中，同时把写命令写入到缓存中，保证子进程重写失败的话不会出问题。 子进程把快照的内容以命令的方式写到临时文件后，子进程发信号通知父进程，父进程把缓存的写命令也写入到临时文件中 父进程用临时文件替换掉旧的 aof 文件，并重新命名，后面收到的命令也重新往新的 aof 文件中追加 aof 文件压缩相关配置：123456# 是否不使用 fsync 的方式重写no-appendfsync-on-rewrite no# aof 文件增长的比例auto-aof-rewrite-percentage 100# aof 文件重写的最小大小auto-aof-rewrite-min-size 64mb 深挖 BGREWRITEAOF 配置 no-appendfsync-on-rewrite 参数当进行 bgrewriteof 命令操作的时候，主进程也会继续写 aof 文件，子进程会写临时的 aof 文件，只要是写文件就会进行磁盘的 I/O 操作，如此一来，就会两个进程就会竞争磁盘。为了解决不竞争磁盘，bgrewriteof 同时也可以配置是否是采用 fsync 方式来强制写入磁盘，具体的配置字段是 no-appendfsync-on-rewrite:no-appendfsync-on-rewrite no：意思是 appendfsync 是 yes, 也就是说会采用 fsync 每次都强制写磁盘，该种方式比较安全，不会造成数据丢失，但是磁盘的写入操作会和主进程的磁盘写入造成竞争，会阻塞主进程的磁盘写入no-appendfsync-on-rewrite yes：意思是 appendfsync 是 no, 也就是说不会采用 fsync 不是每次强制写入磁盘，而是先写入到缓冲区，这样就不会和主进程的写入造成竞争，但是，如果这个时候 Redis 挂掉来，那就会造成数据丢失，默认在 Linux 操作系统写会丢失 30s 的数据。所以，如果无法忍受延迟，而可以容忍少量的数据丢失，则设置为 yes；如果无法忍受数据丢失，则设置为 no auto-aof-rewrite-percentage 参数aof 文件增长的比例，即当前的 aof 文件的大小相比上一次重写时候的 aof 文件的比例大小。默认是 100%，也就是 1 倍。当增长到 1 倍的时候。Redis 就会启动 aof 重写来压缩文件大小 auto-aof-rewrite-min-size 参数aof 文件重写的最小的文件大小。即最开始的 aof 重写当文件必须要到达配置的大小时才会触发。后面每次的重写就不会根据这个变量来，会根据上面的重写文件增长比例 auto-aof-rewrite-percentage来触发 数据恢复机制我们首先要明白为什么要持久化，持久化的核心就是当 服务崩溃之后数据不至于不丢失。那么如何来对数据进行恢复呢？ 从流程图可以看出，Redis 在启动服务的时候是自动的进程数据恢复。不需要手动操作。 两种数据文件的恢复过程，相对来说RDB的启动恢复可能会更短一些，原因有两个: RDB 的文件中每一条数据只有一条记录，不会像 AOF 日志那样可能存在一条数据有多此操作记录的情况。 RDB 的文件存储格式与 Redis 数据在内存中的编码格式一致，不需要再进行数据编码工作，CPU 消耗较小。 下面是 AOF 文件的载入与还原过程： 两种持久化方式的对比Snapshotting 快照优点： 性能最大化，采用 fork 子进程的方式快照，主进程继续处理命令 文件的数据格式和内存的编码一直，恢复数据快速方便 缺点： 由于是不定时的进行快照，会造成数据丢失，数据安全性低 AOF优点： 数据安全性高，aof 持久化可以配置 appendfsync ，每次强制写入磁盘。 采用 append 模式写文件，即使中途宕机，可以通过 redis-check-aof 工具解决一致性问题 aof 机制提供 rewrite 重写模式来压缩 aof 文件。 缺点： 可能文件会比 rdb 文件要大 数据集大的时候，服务启动数据恢复时间比rdb时间长 如何选择？那么到底该如何选择使用那种持久化机制？通常来说，如果想要提供很高的数据保障性，那么同时使用两种方式持久化机制。如果可以接受带来的几分钟的数据丢失，那么可以直接使用默认的持久化机制 快照。 个人建议，生产环境使用持久化机制，最好两种方式都开启。 总结可以看到，Redis 的持久化机制是可以保证数据可靠性。在使用 Redis 的时候可以根据实际的业务场景来合理的选择不同的持久化方案。 参考redis的持久化和缓存机制Redis的2种持久化方式对比redis的no-appendfsync-on-rewrite参数Redis提供的持久化机制（RDB和AOF）","categories":[{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://phachon.github.io/tags/redis/"}]},{"title":"Redis系列（三）：Redis Cluster集群模式","slug":"redis/redis-3","date":"2018-09-24T10:09:10.000Z","updated":"2022-07-11T01:59:03.325Z","comments":true,"path":"redis/redis-3.html","link":"","permalink":"http://phachon.github.io/redis/redis-3.html","excerpt":"本篇文章来介绍 Redis 的第三种集群模式 Cluster 集群模式，该模式也是 Redis3.x 之后才引入的，在该模式下解决了主从同步和 哨兵模式 的不能水平扩容的问题，使得 Redis 集群的性能得到提高，也由此成为了Redis 官方推荐使用的集群方案。本篇文章来介绍如何搭建使用 Redis Cluster 集群并试图去探究 Redis Cluster 集群的实现原理。","text":"本篇文章来介绍 Redis 的第三种集群模式 Cluster 集群模式，该模式也是 Redis3.x 之后才引入的，在该模式下解决了主从同步和 哨兵模式 的不能水平扩容的问题，使得 Redis 集群的性能得到提高，也由此成为了Redis 官方推荐使用的集群方案。本篇文章来介绍如何搭建使用 Redis Cluster 集群并试图去探究 Redis Cluster 集群的实现原理。 Redis Cluster 介绍首先我们需要了解 Redis Cluster 的设计目标： 高性能：高性能是 Redis 赖以生存的看家本领，增加集群之后不能对性能产生太大影响，否则会得不尝失。 水平扩展：之前 Redis 集群不能水平扩展的缺点时常被人诟病，所以必须具备水平扩展。 高可用：在之前，高可用主要是通过 Redis Sentinel 来保障，Cluster 集群也应该具备 Sentinel 的监控、提醒、自动故障转移等功能。 有了 Cluster 的集群方案，使得 Redis 变成了真正的分布式 NoSql 数据库。 数据分区方案为了使得集群能够水平扩展，首要解决的问题就是如何将整个数据集按照一定的规则分配到多个节点上，常用的数据分区的方法有： 普通哈希分区普通的哈希分区比较简单，就是根据规定的哈希函数将数据哈希到指定的节点上，例如：现在有 3 个 Redis 结点 node1、node2、node3。我们的哈希函数采用取余法哈希 123function hash(key) &#123; return key % 3&#125; 当写数据的时候，根据哈希函数写到对应的节点中，读数据的时候先计算出数据在哪个节点，然后再去对应的节点去取。我们发现当节点数固定的时候，该种数据分区的方案没有问题，当增加一个节点或删除一个节点的时候。取余哈希函数的分母会改变，导致之前已分配的数据分区大量改变，并且造成大量的数据获取不到。所以该种方案很少使用。 一致性哈希分区为了解决普通的哈希分区的缺点，提出了一致性哈希的概念。一致性哈希的核心原理是：1将数据 key 和节点都通过哈希函数映射到 2^32 次方的环上关于一致性哈希的原理，超出了本文探讨的范围，后续再写专门的文章来详解。一致性哈希尽最大限度的解决了节点数改变带来的数据不一致的问题。 虚拟槽分区Cluster 采用的正是这种分区的方式。虚拟槽分区巧妙的使用了哈希空间，使用分散度良好的哈希函数把所有的数据映射到一个固定范围内的整数集合，整数定义为槽（slot）,Redis Cluster 的槽范围是 0~ 16383，槽是集群内的数据管理和迁移的基本单位。每个节点负责一定数量的槽。计算公式： 1CRC16(key)&amp;16383 每一个节点负责维护一部分槽及槽所映射的键值数据，如下图所示（图片来源于网络）： 采用 哈希虚拟槽分区 的特性： 解耦了数据和节点之间的关系，简化了节点的扩容和收缩的难度 节点自身来维护槽的映射关系，不需要客户端或者代理来维护槽分区的元数据 至此节点、槽、键之间的映射查询。 节点增加和删除采用 Cluster 的集群方案，当节点增加和删除时，集群又是如何工作来保证服务的高可用？ 下图展现一个 5 个节点构成的集群，每个节点平均大约负责 3276 个槽，以及通过计算公式映射到对应节点的对应槽的过程。 增加节点当增加一个节点 Node-6 时，只需要把其他节点的某些哈希槽挪到新的节点就可以了。 移除节点移除一个节点 Node-5 时，只需要把该节点上的哈希槽挪到其他的节点上就可以了。 在增加和删除节点，redis 的其他节点都不需要停机。 数据迁移1那么如何将槽的数据挪到其他的结点呢？ 为了实现节点之间的数据迁移，节点之间必须相互连接。数据迁移分为两部分： 槽的迁移现在要将 Master A 节点中的编号为 1,2,3 的槽迁移到 Master B 中 在迁移的中间状态下，槽 1,2,3 在 MasterA 节点的状态为 MIGRATING（迁移），在 MasterB 节点的状态为 IMPORTING（入口）。IMPORTING(入口) 状态是被迁移的槽在目标节点中出现的一种状态，准备迁移从A到B的时候，被迁移的槽的状态首先变为 IMPORTING(入口)注意：此时并不刷新 node 的映射关系 键空间的迁移在满足了槽迁移的条件下，通过相关命令将 slot1, slot2, slot3 中的键空间从 A 迁移到B。迁移过程大概如下： Master A 节点执行 DUMP 命令，序列化要迁移的 key，并将数据发送给 Master B Master B 节点接受到要迁移的序列化的 key 之后执行 RESTORE 命令反序列化为 key, 并保存 Master A 节点执行 DEL 命令删除掉已迁移的 key 迁移完成之后，刷新 node 的映射关系 需要注意的是： MIGRATE（迁移） 并不是原子的，如果在 MIGRATE 出现错误的情况可能会导致下面问题： 键空间在两个节点都存在； 键空间只存在第一个节点； 深挖细节 为什么不用一致性哈希，而用槽哈希分区，原因是什么？Redis 使用的是 crc16 的简单算法，Redis 的作者认为 crc16(key) mod 16384 的效果已经不错了，虽然可能没有一致性哈希灵活，但实现比较简单，节点的增加和删除都比较方便 节点增加和删除的过程中，数据会不会丢失？节点在数据迁移的时候数据会有备份，不会丢失 主从同步我们已经了解了 Cluster 的集群的工作方式，那使用 Cluster 模式如何来实现主从同步？ 其实主从同步还是使用的 Redis 本身的主从复制模式，将主从同步和 Cluster 模式结合起来的架构如下： 从图中可以看出，将多个 Master 节点作为 Cluster 的节点，每个 Master 的节点又增加多个 Slave 节点。并且数据读写分离。如果想水平扩展读的并发能力，可以增加多个 Slave, 想水平扩展写的并发能力，可以增加多个 Master, 并且任何一个 Master 和 Slave 宕掉都不会影响服务稳定性。 搭建Redis Cluster 搭建这里篇幅有限，暂不介绍，需要请自行查找相关资料 参考三张图秒懂Redis集群设计原理Redis的Cluster集群搭建","categories":[{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://phachon.github.io/tags/redis/"}]},{"title":"Redis系列（二）：Redis 哨兵集群模式","slug":"redis/redis-2","date":"2018-09-24T04:09:10.000Z","updated":"2022-07-11T01:59:03.325Z","comments":true,"path":"redis/redis-2.html","link":"","permalink":"http://phachon.github.io/redis/redis-2.html","excerpt":"上一篇文章介绍了 Redis 集群的主从同步模式，虽然配置简单，但是缺点也十分突出：Master 内存受限，Master 宕机之后不能自动切换，不能水平扩容等等。本篇文章来介绍 Redis 的第二种集群模式 哨兵模式","text":"上一篇文章介绍了 Redis 集群的主从同步模式，虽然配置简单，但是缺点也十分突出：Master 内存受限，Master 宕机之后不能自动切换，不能水平扩容等等。本篇文章来介绍 Redis 的第二种集群模式 哨兵模式 什么是哨兵模式(Redis Sentinel)哨兵（Sentinel）模式下会启动多个哨兵进程，哨兵进程的作用如下： 监控：能持续的监控 Redis 集群中主从节点的工作状态 通知：当被监控的节点出现问题之后，能通过 API 来通知系统管理员或其他程序 自动故障处理：如果发现主节点无法正常工作，哨兵进程将启动故障恢复机制把一个从节点提升为主节点，其他的从节点将会重新配置到新的主节点，并且应用程序会得到一个更换新地址的通知 哨兵模式的应用场景当采用 Master-Slave 的高可用方案时候，如果 Master 宕机之后，想自动切换，可以考虑使用哨兵模式。哨兵模式其实是在主从模式的基础上工作的。 哨兵模式搭建版本Redis-3.2 环境 windows: Master 192.168.238.1:6379 linux: Slave1 192.168.238.129:6380 linux: Slave2 192.168.238.129:6381 配置主从配置这里不再多说，参考上一篇文章 Redis系列（一）：Redis 主从同步集群模式 哨兵配置三个节点配置一样的哨兵文件 sentinel.conf12345678910#当前Sentinel服务运行的端口port 26379# 哨兵监听的主服务器sentinel monitor mymaster 192.168.238.1 6379 2# 3s 内mymaster无响应，则认为mymaster宕机了sentinel down-after-milliseconds mymaster 3000#如果 10 秒后, mysater仍没启动过来，则启动 failoversentinel failover-timeout mymaster 10000# 执行故障转移时， 最多有1个从服务器同时对新的主服务器进行同步sentinel parallel-syncs mymaster 1 Slave1 和 Slave2 由于在同一台机器上，所以需要修改一下 sentinel.conf 哨兵进程的端口,其他配置不变 Slave1 1port 26380 Slave2 1port 26381 启动哨兵 Master: 192.168.238.1:6379 123&gt; redis-server.exe sentinel.conf --sentinel[9080] 11 Oct 10:36:57.649 # Sentinel runid is 0ccfa091a43d8c8d11cec3aa606395f0400d5499[9080] 11 Oct 10:36:57.650 # +monitor master mymaster 192.168.238.1 6379 quorum 2 Slave1: 192.168.238.129:6380 12345&gt; /usr/local/redis/bin/redis-sentinel /usr/local/redis/etc/sentinel_6380.conf8128:X 11 Oct 10:35:42.843 # Sentinel ID is 9e3c5ef3ec6f595ae273d52ff5ee8f5badf9729a8128:X 11 Oct 10:35:42.844 # +monitor master mymaster 192.168.238.1 6379 quorum 28128:X 11 Oct 10:35:42.854 * +slave slave 192.168.238.129:6380 192.168.238.129 6380 @ mymaster 192.168.238.1 63798128:X 11 Oct 10:35:42.861 * +slave slave 192.168.238.129:6381 192.168.238.129 6381 @ mymaster 192.168.238.1 6379 Slave2: 192.168.238.129:6381 1234567&gt; /usr/local/redis/bin/redis-sentinel /usr/local/redis/etc/sentinel_6381.conf8135:X 11 Oct 10:36:03.296 # Sentinel ID is c2c03e1548ca7ecd53ff8191dcf681fea8f95ba58135:X 11 Oct 10:36:03.296 # +monitor master mymaster 192.168.238.1 6379 quorum 28135:X 11 Oct 10:36:03.303 * +slave slave 192.168.238.129:6380 192.168.238.129 6380 @ mymaster 192.168.238.1 63798135:X 11 Oct 10:36:03.311 * +slave slave 192.168.238.129:6381 192.168.238.129 6381 @ mymaster 192.168.238.1 63798135:X 11 Oct 10:36:03.353 * +sentinel sentinel 9e3c5ef3ec6f595ae273d52ff5ee8f5badf9729a 192.168.238.129 26380 @ mymaster 192.168.238.1 63798135:X 11 Oct 10:36:57.782 * +sentinel sentinel 0ccfa091a43d8c8d11cec3aa606395f0400d5499 192.168.238.1 26379 @ mymaster 192.168.238.1 6379 查看一下主节点的主从配置 123456127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:2slave0:ip=192.168.238.129,port=6380,state=online,offset=70740,lag=1slave1:ip=192.168.238.129,port=6381,state=online,offset=70740,lag=0 至此 一主两从三哨兵 的集群模式已搭建成功 测试主从同步测试 Master123&gt; redis-cli.exe127.0.0.1:6379&gt; set &quot;foo&quot; bar1OK Slave1 123&gt; ./redis-cli -p 6380127.0.0.1:6380&gt; get foo&quot;bar1&quot; Slave2 123&gt; ./redis-cli -p 6381127.0.0.1:6381&gt; get foo&quot;bar1&quot; 主从切换测试 Master 节点宕机 观察 Slave1 节点的 sentinel 进程的输出日志：123458128:X 11 Oct 10:38:11.306 # +config-update-from sentinel 0ccfa091a43d8c8d11cec3aa606395f0400d5499 192.168.238.1 26379 @ mymaster 192.168.238.1 63798128:X 11 Oct 10:38:11.306 # +switch-master mymaster 192.168.238.1 6379 192.168.238.129 63808128:X 11 Oct 10:38:11.306 * +slave slave 192.168.238.129:6381 192.168.238.129 6381 @ mymaster 192.168.238.129 63808128:X 11 Oct 10:38:11.306 * +slave slave 192.168.238.1:6379 192.168.238.1 6379 @ mymaster 192.168.238.129 63808128:X 11 Oct 10:38:14.381 # +sdown slave 192.168.238.1:6379 192.168.238.1 6379 @ mymaster 192.168.238.129 6380Slave 的哨兵进程发现 Master 出现问题，然后选举 Slave2 为 Master 节点( @ mymaster 192.168.238.129 6380), 原 Master 节点 192.168.238.1:6379 降为 Slave 节点这时我们查看一下 Slave2 的主从配置 12345678910127.0.0.1:6380&gt; info replication# Replicationrole:masterconnected_slaves:1slave0:ip=192.168.238.129,port=6381,state=online,offset=6128,lag=1master_repl_offset:6128repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:6127 很明显，6380 的 redis 实例称为了 master 节点。主从自动切换成功 Master 节点到宕机之后恢复 当 6379 的 Redis 实例重新恢复运行时，原来的 Master 自动切换成 Slave，不会自动恢复成 Master。 Slave 节点宕机使 Slave1(6380) 节点 shutdown, 模拟宕机，观察 master 节点 6379 的 info replication 信息12345127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:1slave1:ip=192.168.238.129,port=6381,state=online,offset=70740,lag=0 我们发现 6389 的 slave 结点不见了。 重新启动 slave1 节点。master 节点的同步从节点又会变成两个。 哨兵进程的工作方式 每个哨兵进程会以每秒钟一次的频率向整个集群中的 Master 结点、Slave 节点、Sentinel 进程发送一个 PING 命令 如果一个实例距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值，则这个实例就会被哨兵进程标记为主观下线 如果一个 Master 节点被标记为 主观下线，则所有监视这个 Master 节点的哨兵进程都需要以每秒一次的频率确认 Master 主服务器的确进入了主观下线状态 当有足够数量的哨兵进程在指定时间范围内确认了 Master 主节点进入了主观下线状态，则 Master 节点就会被标记为客观下线 每个哨兵进程会以每 10 秒一次的频率向集群中的所有 Master/Slave 机器发送 INFO 命令，并从回复信息中提取从节点ID、从节点角色、从节点所属的主节点的ip及端口、主从节点的连接状态、从节点的优先级、从节点的复制偏移量等信息； 若没有足够数量的哨兵进程同意 Master 主节点下线，Master 主节点的客观下线状态就会被移除。若 Master 主节点重新向哨兵进程发送 PING 返回有效的回复, Master 主节点的主观下线状态就会被移除 主观下线所谓主观下线就是单个的哨兵进程认为某个服务下线，带有主观意识。 标记为主观下线，是根据发送的 PING 命令是否有效回复来判断，当然主观下线的时间长度可以设置，down-after-milliseconds 毫秒内返回的都是无效回复，则标记为主观下线。 客观下线所谓的客观下线，就是当一个哨兵进程标记某个服务为主观下线时，哨兵需要询问其他的哨兵进程是否也认为该服务为主观下线，接受到足够数量的主观下线的时候，那么该服务就被认为是客观下线。然后开始对服务进行故障转移工作。 领头哨兵的选举如果一个 Redis 节点被标记为客观下线，那么所有监控改服务的哨兵进程会进行协商，选举出一个领头的哨兵，对 Redis 服务进行转移故障操作。领头哨兵的选举大概遵循以下原则： 所有的哨兵都有公平的机会被选举为领头哨兵 在一轮选举中，所有的哨兵都有且仅有一次机会被选举称领头哨兵，一旦选举，不可更改 如果某个哨兵被半数以上的哨兵设置为领头，那么该哨兵称为领头哨兵 如果在限定时间内没选举出来，那么暂停一段时间，再次选举 故障转移哨兵模式最大的优点即可以进行故障转移，提高了服务的高可用。故障转移分为三个步骤： 从下线的主节点所有的从节点中挑选一个从节点，将其转成主节点选举出来的领头哨兵从列表中选择优先级最高的，如果优先级都一样，则选择偏移量大的（偏移量大说明数据比较新），如果偏移量一样，则选择运行ID比较小的 将已下线的主节点的所有从节点改为向新的主节点进行复制挑选出来了新的主节点服务之后，领头哨兵会向原主节点的所有从节点发送 slaveof 新主节点的命令，复制新的 Master 当已下线的原主节点恢复服务时，复制新的主节点，变成新主节点的从节点当已下线的服务重新上线时，sentinel会向其发送 slaveof 命令，让其成为新主节点的从节点 哨兵模式优缺点优点 哨兵模式本身就是基于主从模式，所以具有主从同步模式的优点 主从可以切换，故障转移，提高系统的可用性 系统更加健壮稳定 缺点当 Redis 集群容量达到一定程度时，不能很好的支持在线扩容，所以在使用前必须确保有足够的空间。 总结可以说，哨兵模式是对主从同步模式的一个补充，使得 Redis 集群更加的稳健，可用性更高。但是该种模式下的 Redis 不能水平扩容，不能随时增加或删除结点，这也限制了哨兵模式的广泛使用。在 Redis3.0之后的版本提供了更加强大的集群模式，Cluster 集群模式，下一篇文章我们再详细讨论。 参考Redis哨兵集群模式redis哨兵（sentinel）原理","categories":[{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://phachon.github.io/tags/redis/"}]},{"title":"Redis系列（一）：Redis 主从同步集群模式","slug":"redis/redis-1","date":"2018-09-23T00:10:19.000Z","updated":"2022-07-11T01:59:03.325Z","comments":true,"path":"redis/redis-1.html","link":"","permalink":"http://phachon.github.io/redis/redis-1.html","excerpt":"在生产环境中，为了保证 Redis 服务的高可用，我们往往要使用 Redis 的集群模式，Redis 的集群模式有三种：主从同步集群模式、哨兵集群模式、Cluster 集群模式，本篇文章先介绍 Redis 主从同步集群模式的原理及实现。","text":"在生产环境中，为了保证 Redis 服务的高可用，我们往往要使用 Redis 的集群模式，Redis 的集群模式有三种：主从同步集群模式、哨兵集群模式、Cluster 集群模式，本篇文章先介绍 Redis 主从同步集群模式的原理及实现。 什么是主从同步简单来说，主从同步 就是指以一个主节点作为基准节点，将数据同步给从节点，使得主从节点的数据保持一致。这里的主节点一般也称为 Master 节点，从节点一般也叫做 Slave 节点。一个 Master 节点可以拥有多个 Slave 节点。这种架构就叫做 一主多从 的主从架构。如果每一个 Slave 节点也作为基准节点，同时也拥有多个 Slave 节点，那么这中架构就叫做 级联结构的主从架构。本篇文章仅研究 一主多从主从架构。 Redis 主从同步集群模式的应用场景1那么什么时候需要使用主从同步的集群模式？ 个人认为 Redis 主从同步有一下几种应用场景 场景一：Slave 作为 Master 节点的数据备份主从服务器架构的设计，可以大大加强 Redis 服务的健壮性。当主服务器出现故障时，可以人工或自动切换到从服务器继续提供服务，同时当主服务器的数据因为某种原因不能恢复时，可以使用从服务器备份的数据。除了这些之外，还经常使用从服务器来处理一些操作比较耗时的命令，以防止阻塞主服务器的工作，导致主服务的请求不能及时处理。例如: Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？我们知道使用 keys 命令可以扫出指定模式的 key 列表。 1如果 Redis 正在线上提供服务，会有什么问题吗？ 因为 Redis 是单线程的，keys 指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候如果我们可以将 Redis 配置一个从服务器，将比较耗时或者阻塞的操作都在从服务器来操作，以防止主服务器停顿。当然除了这种解决办法，还可以使用 scan 命令（scan 命令是无阻塞的）来扫描出需要的 key , 但是有一定的重复率。可以在客户端进行去重。 场景二：数据读写分离读写分离的场景往往是我们最多使用的场景，类似于 Mysql 读写分离，一般是主服务器来提供写操作，从服务器提供读操作。主服务器的写操作会同步给从服务器。数据读写分离将读操作和写操作隔离开，使得读写相互不影响效率，提高了服务的读写速度。 场景三：多个从服务器根据业务拆分此种场景其实是基于场景二的基础上增加的，当读多写少的情况下，我们还可以根据读的不同业务将多个从服务器拆分，例如，从服务器 A 专门用来提供视频业务的数据访问，从服务 B 专门用来新闻业务的数据访问，从服务器 C 专门用来提供用户的数据访问。此种场景不仅减轻了主服务器的压力，同时也使得不同的业务数据访问互不影响。 Redis 主从同步的配置Redis 的安装这里不再介绍，我们以两台机器为例来搭建主从同步的 Redis 集群，一台在 windows 下，一个 Redis 实例为 192.168.238.1:6379; 一台在虚拟机里， 两个 Redis 实例为 192.168.238.129:6379, 192.168.238.129:6380假如我们配置让 windows 机器的 Redis 实例为主节点，另外两个节点为从节点。 配置 运行主节点的 Redis 实例 1234&gt; redis-server.exe[8616] 09 Oct 17:31:00.826 # Server started, Redis version 3.0.502[8616] 09 Oct 17:31:00.826 * DB loaded from disk: 0.000 seconds[8616] 09 Oct 17:31:00.826 * The server is now ready to accept connections on port 6379 运行节点的 Redis 实例从节点有两种方式来指定自己所需要连接的主节点，一种是直接在启动的命令行参数指定，一种是修改 /etc/redis.conf 文件，两个从节点为分别用两种不同的方式来演示： 从节点 192.168.238.129:6379 采用命令行参数的方式指定 Master123456789101112&gt; /usr/local/redis/bin/redis-server --slaveof 192.168.238.1 637913316:S 21 Sep 21:46:05.087 * The server is now ready to accept connections on port 637913316:S 21 Sep 21:46:05.087 * Connecting to MASTER 192.168.238.1:637913316:S 21 Sep 21:46:05.087 * MASTER &lt;-&gt; SLAVE sync started13316:S 21 Sep 21:46:05.088 * Non blocking connect for SYNC fired the event.13316:S 21 Sep 21:46:05.093 * Master replied to PING, replication can continue...13316:S 21 Sep 21:46:05.100 * Partial resynchronization not possible (no cached master)13316:S 21 Sep 21:46:05.118 * Full resync from master: 3c4a283f5c5f503d833bf3cad3ae1adde7af283d:113316:S 21 Sep 21:46:05.337 * MASTER &lt;-&gt; SLAVE sync: receiving 44 bytes from master13316:S 21 Sep 21:46:05.338 * MASTER &lt;-&gt; SLAVE sync: Flushing old data13316:S 21 Sep 21:46:05.339 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory13316:S 21 Sep 21:46:05.339 * MASTER &lt;-&gt; SLAVE sync: Finished with success 从节点 192.168.238.129:6380 采用修改配置文件的方式指定 Master打开 redis 的配置文件，修改 salveof 配置12265 # slaveof &lt;masterip&gt; &lt;masterport&gt;266 slaveof 192.168.238.1 6379 运行从节点 Redis 实例123456789101112&gt; /usr/local/redis/bin/redis-server /usr/local/redis/etc/redis_6380.conf13521:S 21 Sep 21:52:34.853 * The server is now ready to accept connections on port 638013521:S 21 Sep 21:52:34.854 * Connecting to MASTER 192.168.238.1:637913521:S 21 Sep 21:52:34.854 * MASTER &lt;-&gt; SLAVE sync started13521:S 21 Sep 21:52:34.860 * Non blocking connect for SYNC fired the event.13521:S 21 Sep 21:52:34.863 * Master replied to PING, replication can continue...13521:S 21 Sep 21:52:34.866 * Partial resynchronization not possible (no cached master)13521:S 21 Sep 21:52:34.885 * Full resync from master: 3c4a283f5c5f503d833bf3cad3ae1adde7af283d:54713521:S 21 Sep 21:52:35.063 * MASTER &lt;-&gt; SLAVE sync: receiving 44 bytes from master13521:S 21 Sep 21:52:35.063 * MASTER &lt;-&gt; SLAVE sync: Flushing old data13521:S 21 Sep 21:52:35.063 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory13521:S 21 Sep 21:52:35.063 * MASTER &lt;-&gt; SLAVE sync: Finished with success 这时，我们注意观察一下主节点的输出，我们能看出，主节点已经和两个从节点同步成功1234567891011121314[8616] 09 Oct 17:37:39.515 * Slave 192.168.238.129:6379 asks for synchronization[8616] 09 Oct 17:37:39.517 * Full resync requested by slave 192.168.238.129:6379[8616] 09 Oct 17:37:39.517 * Starting BGSAVE for SYNC with target: disk[8616] 09 Oct 17:37:39.523 * Background saving started by pid 5384[8616] 09 Oct 17:37:39.657 # fork operation complete[8616] 09 Oct 17:37:39.657 * Background saving terminated with success[8616] 09 Oct 17:37:39.658 * Synchronization with slave 192.168.238.129:6379 succeeded[8616] 09 Oct 17:43:09.583 * Slave 192.168.238.129:6380 asks for synchronization[8616] 09 Oct 17:43:09.592 * Full resync requested by slave 192.168.238.129:6380[8616] 09 Oct 17:43:09.599 * Starting BGSAVE for SYNC with target: disk[8616] 09 Oct 17:43:09.601 * Background saving started by pid 8996[8616] 09 Oct 17:43:09.778 # fork operation complete[8616] 09 Oct 17:43:09.778 * Background saving terminated with success[8616] 09 Oct 17:43:09.779 * Synchronization with slave 192.168.238.129:6380 succeeded 注意：如果主节点启用了密码认证，需要将从节点的配置文件的配置 masterauth xxxxxx 修改 验证不要轻易相信别人说的，要始终相信眼睛看到；接下来我们来验证一下主服务器是否能将数据同步到两个从服务器 主节点 123456&gt; redis-cli.exe127.0.0.1:6379&gt; set &quot;foo&quot; barOK127.0.0.1:6379&gt; get &quot;foo&quot;&quot;bar&quot;127.0.0.1:6379&gt; 从节点1 1234&gt; ./redis-cli -p 6379127.0.0.1:6379&gt; get foo&quot;bar&quot;127.0.0.1:6379&gt; 从节点2 1234&gt; ./redis-cli -p 6380127.0.0.1:6380&gt; get foo&quot;bar&quot;127.0.0.1:6380&gt; 至此，一主两从 的 Redis 主从同步集群已经搭建成功。 Redis 主从同步的原理虽然我们已经能够配置并使用主从同步的 Redis 集群，但是我们还是有必要了解一下主从同步的实现原理，这样才能在遇到问题的时候迅速判断问题的发生的原因。Redis 主从同步分为两个过程：全量同步和增量同步 全量同步全量同步一般发生在 Slave 的初始化阶段，也就是 Slave 节点的启动阶段。具体的步骤如下（最好对照着刚刚启动的日志来看）： 从服务器连接主服务器（Log: Connecting to MASTER 192.168.238.1:6379） 从服务器发送 SYNC 命令到主服务器（Log: MASTER SLAVE sync started） 主服务器接收到 SYNC 命名后，开始执行 BGSAVE 命令生成 RDB 文件并使用缓冲区记录此后执行的所有写命令（Log: Starting BGSAVE for SYNC with target: disk） 主服务器 BGSAVE 执行完后，递增地将文件发送到从服务器，并在发送期间继续记录被执行的写命令（Log: Synchronization with slave 192.168.238.129:6379 succeeded） 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照（Log: MASTER SLAVE sync: Flushing old data） 从服务器将快照载入内存（Log: MASTER SLAVE sync: Loading DB in memory） 主服务器快照发送完毕后开始向从服务器发送缓冲区的写命令 从服务器完成对快照的载入，开始接收主服务器发送的写命令请求，并执行写命令。 至此，一次全量同步完成 增量同步增量同步是指 Redis 在主从模式已经正常工作的情况下，主服务器将写操作同步到从服务器的过程增量复制的原理当主服务器每执行一个写命令，就会将该命令发送给所有的从服务器，从服务器接收到命令之后立即执行。 深挖细节 主节点执行 BGSAVE 生成全量镜像的 RDB 文件，是如何来工作的？首先 BGSAVE 指令是用来在后台异步保存当前数据库的数据到磁盘，不会阻塞主节点的进程，当执行 BGSAVE 后，会立即返回 OK, 然后 Redis fork 出一个新子进程 来专门生成全量镜像文件的工作，将数据保存到磁盘后，子进程退出。 当主节点在 BGSAVE 的过程中，又有新的写请求到来，主节点怎么工作？这些写数据怎么保存？根据 1 的细节，我们知道主节点会有一个新的子进程来单独处理全量镜像的生成工作，那么主节点父进程可以继续来接收新的请求。这里需要注意的是，当发生 fork 的时候，操作系统会采用写时复制（copy-on-write）策略即 fork 函数发生的那一刻，父子进程共享同一块内存数据，当父进程接收到写操作时，操作系统会复制一份数据以保证子进程的数据不受影响。所以新生产的 RDB 文件存储的是执行 fork 那一刻的数据。 主服务执行 BGSAVE 命令如果磁盘不够生成 rdb 文件数据的大小怎么办？不能同步了吗？可以采用 无磁盘复制 技术; 通常来讲，一个完全重同步需要在磁盘上创建一个 RDB 文件，然后加载这个文件以便为从服务器发送数据。如果使用比较低速或者容量较小的磁盘，这种操作会给主服务器带来较大的压力。Redis从2.8.18版本开始尝试支持无磁盘的复制。使用这种设置时，子进程直接将 RDB 文件通过网络发送给从服务器，不使用磁盘作为中间存储。这里需要注意：使用硬盘备份传送是多个从节点排队等待传送，也就是说传送是串行的，而无磁盘复制技术是主节点在传送之前会等待一段时间（可以配置，以秒为单位），希望等待多个从节点都到达后，并行传送。相关配置键如下： 1234# 配置取消硬盘备份repl-diskless-sync no# 延迟时间以秒为单位，默认为5秒。如果设置为 0 秒，传送会立即启动，不会延迟repl-diskless-sync-delay 5 主从同步的过程中，从服务器是阻塞的吗？主从同步的过程中，也不会阻塞从服务器。当从服务器进程初始同步时，会使用旧的数据继续提供查询服务。当然这个也可以在配置文件修改。但是，需要注意的是，并不是整个过程都是不阻塞的，当从服务器接受到快照文件，需要删除旧的快照并加装新的数据集到内存，在这个短暂的时间内，从服务器会阻塞连接进来的请求。 当主从节点断开复制之后，从节点的数据会删除吗？如果需要断开复制，从节点执行命令： 1slaveof no one 从节点不会删除已有的数据，只是不再接受主节点新的数据变化 Redis 重同步机制 如果节点宕掉了或者主从重新连接是如何重新恢复同步机制的？ 在 Redis 2.8 之前同步机制和 Redis2.8 之后的同步机制不太一样。下面分开来介绍 旧版同步机制的缺陷复制的情况分为两种情况： 初次同步初次同步即从节点在复制当前主节点之前，没有复制过任何的主节点，或者是从节点要复制的和上一次要复制的主节点不同。对于初次复制来说，旧版的复制功能没有任何问题，能够完成同步功能。 断线后重同步当处于增量复制阶段的时候，主从节点的连接因为网络原因中断了复制，但从节点又重新连接上了主节点，并继续复制主服务器。重同步的机制如下： 从节点重新连接上了主节点 从节点向主节点发送 SYNC 的命令 主节点接受到 SYNC 的命令，执行 BGSAVE 命令开始生成 rdb 文件, 并使用缓冲区来记录所有的写命令。注意这里生成的并不是全量的文件，是从未同步成功的key开始到当前的key的数据文件。 主节点向从节点发送 rdb 文件 从节点接受到 rdb 文件，将数据载入 主从节点数据恢复一致 从上面可以看出，基本上和初次同步没什么不同。都要进行 SYNC 的操作， 而 SYNC 是一个非常耗费资源的操作： 每次都要进行 BGSAVE 操作，会耗费服务器大量的 CPU、内存和磁盘 将生成的 rdb 文件通过网络发送给从服务器，这个操作会耗费主从服务器大量的网络带宽和流量，会对主节点响应命令请求的时间产生影响 从节点接受到 rdb 文件之后会将数据载入内存，这个时候从服务器是阻塞的，没有办法处理请求 新版同步机制的核心原理为了解决旧版的断线后重同步的缺陷，新版的 Redis 使用 PSYNC 命令来代替 SYNC 来执行复制时的同步操作。PSYNC 的工作模式有两种：完整重同步 和 初次重同步。 完整重同步完整重同步和旧版的初次同步一样，这里不再详细说明 部分重同步部分重同步则主要用于处理断线后重连的情况：当从节点连接到主节点之后，如果 条件允许，则主节点可以将主从节点连接断开期间执行的写命令发送给从节点，从节点接受到这些命令后执行，就可以将数据更新至一致部分重同步主要由三部分组成： 主节点的 复制偏移量 和从节点的 复制偏移量 主节点的 复制积压缓冲区 节点的运行 ID 复制偏移量主从节点都会维护一个复制偏移量： 主节点每次向从节点发送 N 个字节的数据时，就将自己的复制偏移量加 N 从节点接受到 N 个字节数据时，也将自己的复制偏移量加 N 当发生断线重连的时候，从节点发送 PSYN 命令给主节点，主节点会将当前的复制偏移量发送给从节点，通过对比主从节点的复制偏移量就很容易知道主从节点的数据是否处于一致。 复制积压缓冲区复制积压缓冲区是由主节点维护的一个固定长度的队列，默认大小是 1 M。当主节点在增量同步的时候，不仅会将命令发送给从节点，同时也会将命令写入到复制积压缓冲区的队列里。当队列满时，会自动弹出队首的数据，所以复制积压缓冲区会保存一部分最近发送的写命令。 那么当从节点连上主节点之后，从节点也会将自己的 复制偏移量发送给主节点，主节点会根据偏移量的不同来决定采取何种的重同步机制： 当从节点的复制偏移量还在复制积压缓冲区里，那么主节点将对从节点执行部分重同步，即只发送丢失的写命令 相反，如果从节点的复制偏移量已经不在复制积压缓冲区里，那么主节点必须执行完整的重同步 注意：可以根据需要来调整复制积压缓冲区的大小。如果主服务器平均每秒产生 1 MB的写数据，而从节点断线之后平均要 5 秒才能重新连接上主节点，那么复制积压缓冲区的大小就不能低于5MB 节点运行ID无论是主从节点都会在服务启动时自动生成生成一个运行ID，由40个随机字符串组成，例如：9di9b28df834rf09iab5e345fbbab667ydoopp2b3 当初次同步时，主节点会将自己的运行ID发送给从节点，而从节点会将这个运行ID保存下来。即从节点保存了主节点的的运行ID 当从节点重新连接上主节点时，从节点会向主节点发送保存的主节点运行ID: 主节点判断从节点发送过来的保存的运行ID和自己的运行ID相同，则证明节点断线之前就是连接的这个主节点，主节点就可以继续尝试去部分重同步。 相反，如果运行ID不相同，则说明从节点断线之前复制的主节点不是当前的主节点，主节点将直接进行完整重同步操作。 心跳机制主从节点连接断掉之后，主节点是如何知道的？心跳监测机制，在增量同步的过程中，从节点默认会以每秒一次的频率向主节点发送命令：REPLCONF ACK &lt;replication_offset&gt;，命令的作用在于： 检测主从服务器的网络连接状态 检测命令是否丢失如果主服务器超过 1 秒钟没有收到从节点发来的 REPLCONF ACK 命令，那么主节点就知道与从节点之间的连接出现问题了。 主节点不持久化的安全性如果使用主从同步的集群模式，强烈建议开启主节点的持久化机制，但这并不是必须的，如果不开启持久化机制，也应当关闭主节点实例自动重启，原因如下：当主节点不持久化，从节点正常复制主节点的数据，当主出现了一个崩溃，这时候如果 Redis 自动重启服务，因为没有持久化，节点重启后就只有一个空的数据集。其他的从节点依旧从主节点复制数据，所以最终从节点的数据也会为空。 Redis 主从同步的优缺点优点 同一个 Master 可以部署多个 Slave Slave 还可以接受其他的 Slave 的连接和同步，即所谓的 级联结构。有效的减轻 Master 的压力 主从同步期间，主从节点均是非阻塞。不影响服务的查询和写入 可以很好的实现读写分离的架构，系统的伸缩性得到提高 缺点 主机的宕机会非常严重，导致整个数据不一致的问题。 全量的复制的过程中，必须保证主节点必须有足够的内存。若快照的文件过大，还会对集群的服务能力产生影响。 总结Redis 主从集群模式的介绍就到这里。下一篇文章介绍 Redis 集群的哨兵模式。 参考Redis主从复制原理总结主从同步（复制）","categories":[{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://phachon.github.io/tags/redis/"}]},{"title":"TCP/IP 协议栈系列（十三）：IP协议简单介绍","slug":"network/TCP-IP-13","date":"2018-09-21T16:00:00.000Z","updated":"2022-07-11T01:59:03.323Z","comments":true,"path":"network/TCP-IP-13.html","link":"","permalink":"http://phachon.github.io/network/TCP-IP-13.html","excerpt":"","text":"","categories":[{"name":"Network","slug":"Network","permalink":"http://phachon.github.io/categories/Network/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（十二）：DNS原理分析","slug":"network/TCP-IP-12","date":"2018-09-20T16:00:00.000Z","updated":"2022-07-11T01:59:03.323Z","comments":true,"path":"network/TCP-IP-12.html","link":"","permalink":"http://phachon.github.io/network/TCP-IP-12.html","excerpt":"","text":"","categories":[{"name":"Network","slug":"Network","permalink":"http://phachon.github.io/categories/Network/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（十一）：UDP协议详解","slug":"network/TCP-IP-11","date":"2018-09-19T16:00:00.000Z","updated":"2022-07-11T01:59:03.323Z","comments":true,"path":"network/TCP-IP-11.html","link":"","permalink":"http://phachon.github.io/network/TCP-IP-11.html","excerpt":"","text":"","categories":[{"name":"Network","slug":"Network","permalink":"http://phachon.github.io/categories/Network/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（十）：TLS/SSL握手过程","slug":"network/TCP-IP-10","date":"2018-09-18T16:00:00.000Z","updated":"2022-07-11T01:59:03.323Z","comments":true,"path":"network/TCP-IP-10.html","link":"","permalink":"http://phachon.github.io/network/TCP-IP-10.html","excerpt":"","text":"","categories":[{"name":"Network","slug":"Network","permalink":"http://phachon.github.io/categories/Network/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（九）：TLS/SSL握手过程","slug":"network/TCP-IP-9","date":"2018-09-17T16:00:00.000Z","updated":"2022-07-11T01:59:03.324Z","comments":true,"path":"network/TCP-IP-9.html","link":"","permalink":"http://phachon.github.io/network/TCP-IP-9.html","excerpt":"","text":"","categories":[{"name":"Network","slug":"Network","permalink":"http://phachon.github.io/categories/Network/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（八）：HTTPS证书原理","slug":"network/TCP-IP-8","date":"2018-09-16T16:00:00.000Z","updated":"2022-07-11T01:59:03.323Z","comments":true,"path":"network/TCP-IP-8.html","link":"","permalink":"http://phachon.github.io/network/TCP-IP-8.html","excerpt":"","text":"","categories":[{"name":"Network","slug":"Network","permalink":"http://phachon.github.io/categories/Network/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（七）：HTTPS基础知识","slug":"network/TCP-IP-7","date":"2018-09-15T16:00:00.000Z","updated":"2022-07-11T01:59:03.323Z","comments":true,"path":"network/TCP-IP-7.html","link":"","permalink":"http://phachon.github.io/network/TCP-IP-7.html","excerpt":"","text":"","categories":[{"name":"Network","slug":"Network","permalink":"http://phachon.github.io/categories/Network/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（六）：HTTP2.0协议详解","slug":"network/TCP-IP-6","date":"2018-09-14T16:00:00.000Z","updated":"2022-07-11T01:59:03.323Z","comments":true,"path":"network/TCP-IP-6.html","link":"","permalink":"http://phachon.github.io/network/TCP-IP-6.html","excerpt":"","text":"","categories":[{"name":"Network","slug":"Network","permalink":"http://phachon.github.io/categories/Network/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（五）：HTTP1.0与HTTP1.1协议详解","slug":"network/TCP-IP-5","date":"2018-09-13T16:00:00.000Z","updated":"2022-07-11T01:59:03.323Z","comments":true,"path":"network/TCP-IP-5.html","link":"","permalink":"http://phachon.github.io/network/TCP-IP-5.html","excerpt":"","text":"","categories":[{"name":"Network","slug":"Network","permalink":"http://phachon.github.io/categories/Network/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（四）：HTTP协议概述","slug":"network/TCP-IP-4","date":"2018-09-12T16:00:00.000Z","updated":"2022-08-06T07:26:20.444Z","comments":true,"path":"network/TCP-IP-4.html","link":"","permalink":"http://phachon.github.io/network/TCP-IP-4.html","excerpt":"","text":"HTTP 简介HTTP协议是 Hyper Text Transfer Protocol（超文本传输协议）的缩写, 是用于从万维网（WWW:World Wide Web ）服务器传输超文本到本地浏览器的传送协议。 HTTP 是一个基于 TCP/IP 协议来传递数据（网页、文件等）的应用层协议。 HTTP 特点1、简单：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有 GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP 协议简单，使得 HTTP 服务器的程序规模小，因而通信速度很快。 2、灵活：HTTP 允许传输任意类型的数据对象。正在传输的类型由 Content-Type 加以标记。 3、无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 4、无状态：HTTP 协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 5、支持B/S及C/S模式。 请求过程在浏览器输入：https://www.qq.com/ 浏览器向网站所在的服务器发送了一个 Request 请求，服务器接收到这个 Request 之后进行处理和解析，然后返回一个 Response 响应，然后传回给浏览器，Response 里面就包含了页面的 html 源代码等内容，浏览器再对其进行解析便将网页呈现了出来。 HTTP 头部HTTP 头部是一个传递额外重要信息的 键值对。主要分为：通用头部，请求头部，响应头部和实体头部。 通用头部： Connection：客户端和服务端使用的 tcp 连接类型 Date：报文的时间 Cache-Control：缓存的控制 Transfer-Encoding：报文的传输方式；chunked 分块传输 请求头部： Accept：告诉服务器允许的媒体类型 Accept: text/plain Accept-Encoding：客户端支持的接收的编码方法 Accept-Encoding: gzip, deflate User-Agent：浏览器的身份标识字符串 User-Agent: Mozilla/…… Referer：浏览器所访问的前一个页面 响应头部： Server：告知客户端服务器信息 Server: Apache/1.3.27 (Unix) (Red-Hat/Linux) Location：表示重定向后的 URL 实体头部： Allow：对某网络资源的有效的请求行为，不允许则返回405 Content-encoding：返回内容的编码方式 Content-Length：返回内容的字节长度 Content-Language：响应体的语言 Keep-Alive 机制这里的 keep-alive 是指 http 协议里 header 头里设置的 Connection: keep-alive，请求头设置了 keep-alive 之后就会告诉对方这个请求响应完成后不要关闭，下一次咱们还用这个请求继续交流，我们用一个示意图来更加生动的表示两者的区别： 为啥需要 keep-alive？在 HTTP/1.0 中，浏览器每次发起 HTTP 请求都要与服务器创建一个新的 TCP 连接，服务器完成请求处理后立即断开 TCP 连接，服务器不跟踪每个客户也不记录过去的请求。创建和关闭 TCP 连接的过程需要消耗资源和时间，为了减少对 TCP 资源消耗，缩短响应时间，就需要重用 TCP 连接。 特别注意：所以我们需要清楚概念，有些地方也叫 keep-alive 为 http 长连接，这个说法并不是准确；因为 http 压根连连接都没有，真正连接是传输层的 tcp 才回建立连接，所以 http 不存在长连接一说，只有底层的 tcp 才存在长连接。这里 keep-alive 说的是当前的 tcp 连接是可复用的也叫 tcp 长连接或者叫 tcp 保活。 什么时候应该使用 keep-alive？应该说当前大部分的场景已经使用 http1.1 都默认使用的 keep-alive tcp 长连接的方式；对于 http1.0，如果 http 客户端比较多，请求比较频繁，是需要手动设置 keep-alive keep-alive 缺点长时间的保持 TCP 连接时容易导致系统资源被无效占用，若对 Keep-Alive 模式配置不当，将有可能比非 Keep-Alive 模式带来的损失更大。因此，我们需要正确地设置 keep-alive timeout 参数，当 TCP 连接在传送完最后一个 HTTP 响应，该连接会保持 keepalive_timeout 秒，之后就开始关闭这个链接。 HTTP 报文长度如果服务器预先知道报文大小，会直接返回的 header 头中的 Content-Length 标示报文的长度如果服务器采用分块传输机制，就会采用 Transfer-Encoding: chunked 的方式来代替 Content-Length 分块传输编码（Chunked transfer encoding）是 HTTP/1.1 中引入的一种数据传输机制，其允许 HTTP 由服务器发送给客户端的数据可以分成多个部分，当数据分解成一系列数据块发送时，服务器就可以发送数据而不需要预先知道发送内容的总大小，每一个分块包含十六进制的长度值和数据，最后一个分块长度值为0，表示实体结束，客户机可以以此为标志确认数据已经接收完毕。 GET 长度限制HTTP 中的 GET 方法是通过 URL 传递数据的，而 URL 本身并没有对数据的长度进行限制，真正限制 GET 长度的是浏览器，例如 IE 浏览器对 URL 的最大限制为 2000多个字符，大概 2KB左右，像 Chrome, FireFox 等浏览器能支持的 URL 字符数更多，其中 FireFox 中 URL 最大长度限制为 65536 个字符，Chrome 浏览器中 URL 最大长度限制为 8182 个字符 状态码1XX 指示信息–表示请求正在处理2XX 成功–表示请求已被成功处理完毕3XX 重定向–要完成的请求需要进行附加操作4XX 客户端错误–请求有语法错误或者请求无法实现，服务器无法处理请求5XX 服务器端错误–服务器处理请求出现错误 参考资料http的长连接和短连接关于HTTP协议，一篇就够了HTTP协议详解","categories":[{"name":"Network","slug":"Network","permalink":"http://phachon.github.io/categories/Network/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（三）：TCP协议详解","slug":"network/TCP-IP-3","date":"2018-09-11T16:00:00.000Z","updated":"2022-07-11T01:59:03.323Z","comments":true,"path":"network/TCP-IP-3.html","link":"","permalink":"http://phachon.github.io/network/TCP-IP-3.html","excerpt":"","text":"","categories":[{"name":"Network","slug":"Network","permalink":"http://phachon.github.io/categories/Network/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（二）：TCP/IP协议概述","slug":"network/TCP-IP-2","date":"2018-09-10T16:00:00.000Z","updated":"2022-08-06T04:05:34.689Z","comments":true,"path":"network/TCP-IP-2.html","link":"","permalink":"http://phachon.github.io/network/TCP-IP-2.html","excerpt":"","text":"本章将自底向上来说明 TCP/IP协议栈各层的具体工作流程 传输介质首先，我们应该都知道计算机之间必须通过一定的传输媒介才能将数据相互传递，例如，光缆，光纤，或者无线电波，不同的传输媒介决定了电信号（0 1）的传输方式，同时也影响了电信号的传输速率、传输带宽。 链路层我们自然的会去思考： 如何才能将 0 1 的电信号通过传输媒介传输到对方的主机？ 很好解决：我们将每个计算机都安装一个能接收数据和发送数据的设备，然后将 0 1 的电信号分组，也就是组成字节的形式发送出去。 为什么要组成字节发送，因为单纯的 0 1 是没有意义的，计算机用 8 个 0 或 1 的二进制位来表示一个字节，字节才是我们发送数据的最小单位 那么这里我们提到的接收数据和发送数据的设备，就是网卡。我们规定，数据包必须是从一块网卡到另一块网卡，而网卡的地址（即我们常说的 MAC 地址）就是数据包要发送的地址和接收的地址。MAC 地址就像网卡的身份证一样，必须具有全球唯一性。MAC 地址采用 16 进制表示，共 6 个字节，前 3 个字节是厂商的编号，后三个字节是网卡流水号。例如：5C-0F-6E-13-D1-18 解决了数据传输设备，接下来解决如何发送，所以就有人设计出来了一套发送数据的规范，也就是以太网协议。 以太网协议规定，一组电信号就是一个数据包，一个数据包也被称为一帧。一个以太网数据包的格式如下： 123+--------------+----------------------+--------------+| head(14 byte)| data(46 ~ 1500 byte) | end (4 byte) |+--------------+----------------------+--------------+ 整个数据包由三部分组成，头部，数据，和尾部，头部占14个字节，包含原MAC地址，目标MAC地址和类型；数据区最短 46个字节，最大 1500 个字节，如果发送的数据大于 1500 个字节，则必须拆开多个数据包来发送。尾部为 4 个字节，用来存数据帧的校验序列，用来验证整个数据包是否完整。 以太网数据包发送过程：以太网协议会通过广播的形式将以太网数据包发送给在同一个子网的所有主机，这些主机接受到数据包之后，会取出数据包的头部里的 MAC 地址和自己的 MAC 地址进行比较，如果相等，就会接着处理数据，如果不相等，则会丢弃这个数据包。 总结：链路层的工作就是将 0，1的电信号分组并组装成以太网数据包，然后网卡通过传输媒介以广播的形式将数据包发送给在同一个子网的接收方 注意：以太网协议始终是以广播的形式将数据包发给在同一个子网的主机 网络层首先再回过头来看一下链路层，为了能让链路层工作，我们必须知道对方主机的 MAC 地址，而且还要知道对方的 MAC 地址是否和自己处于同一网络。 如果我们使用 MAC 地址来传输数据，那就必须记住每个 MAC 地址，但是去记一串这样长（ 5C-0F-6E-13-D1-18 ）的地址显然是不友好的 即使我们能记住 MAC 地址，MAC 地址也只于厂商有关，和网络无关，怎么能知道是不是在一个子网？ 如果不是一个子网，那怎么办，以太网的协议难道不能发生以太网数据包了？ 别急，能提出问题，那自然有解决方案，当没有解决办法的时候，那就设计一套新的协议来弥补这些问题。 为了解决以上的问题，我们的前辈们设计了三个协议：IP 协议，ARP 协议，路由协议。同时呢将这三个协议放在了网路层。 IP 协议为了解决 1 和 2，必须指定了一套新的地址。使得我们能够区分两个主机是否在同一个网络。IP 地址分为 IPV4 和 IPV6 两种，现在普遍还在使用的是 IPV4 地址，IPV4 地址由 4 个字节 32 位组成，每个字节可以用一个十进制的数表示，通常，我们使用 . 隔开每个十进制数来表示 ip 地址，例如：192.168.12.11 。同时，IPV4 对 IP 地址进行了分类，主要是 A B C D 四类，以 C 类地址 192.168.12.11 为例，其中前 24 位就是网络地址，后 8 位就是主机地址。那么网络地址相同的就是在一个局域网子网内为了判断 IP 地址中的网络地址，IP 协议还引入了子网掩码，通过子网掩码和 IP 地址按位与运算，就能得到网络地址。 因为在上层的传输层中，开发者会将 IP 地址传入，所以我们只用通过子网掩码进行运算后就能判断两个 IP 是否在一个子网内。 这里简单介绍一下 IP 数据包： 123+-----------------+--------------------+| head(20 byte) | data (65515 byte) |+----------------=+--------------------+ ARP 协议我们解决了问题1和问题2，但是随之问题又来 现在设计的 IP 协议解决了在不在一个子网内的问题，但是如果用 IP 协议，以太网协议必须知道目标主机的 MAC 地址才能传输，怎么获取到目前主机的 MAC 地址？ 为了解决这个问题，ARP 协议被设计出来，即 IP 地址解析协议，主要作用就是通过 IP 来获取到对应的 MAC 地址。 ARP 协议的具体工作过程：ARP 会首先发起一个数据包，数据包里面包含了目标主机的 IP 地址，然后发送到链路层再次包装成以太网数据包，最终由以太网广播给自己当前子网的所有主机，主机接受到这个数据包之后，取出数据包的 IP 地址，和自己的 IP 地址进行对比如果相同就返回自己的 MAC 地址，如果不同就丢弃这个数据包。ARP 接受消息来确定目标主机的 MAC 地址。如果查询到了 MAC 地址，ARP 还会将该 IP 的 MAC 地址缓存到本机保留一段时间等下次再有请求查询，直接先从缓存里取出。这样可以节约资源，提高查询效率。 相反的 RARP 协议是用来解析 MAC 地址为 IP 地址的协议 路由协议我们发现 ARP 协议通过 IP 获取 MAC 地址依然是局限在子网内，那不在子网的 IP 地址，ARP 不就拿不到 MAC 地址了？这也就是我们开始提出的第三个问题还没有解决。 为了解决这个问题，前辈们又设计出了另一种协议-路由协议，路由协议必须借助路由设备来完成，即路由器或交换机，路由器扮演着交通枢纽的角色，会根据信道的情况，选择合适的路径来转发数据包因此，刚刚我们的那个问题得到解决，首先是通过 IP 协议来判断两个 IP 是否在同一个子网内，如果在一个子网，那就通过 ARP 协议去获取 MAC 地址，然后再通过以太网协议将数据包广播到子网内；如果不在一个子网内，以太网会将数据包先转发到本子网的网关进行路由，网关会进行多次转发，并最终将数据包转发到目标 IP 的子网内，然后再通过 ARP 协议获取目标主机的 MAC 地址，最终再通过以太网协议将数据包发送到目标 MAC 地址。 总结一下：网络层的工作主要是定义网络地址、划分网段、查询 MAC 地址、对不是同一网段的数据包进行路由转发 传输层依靠传输层和链路层的工作，数据已经能够正常的从一台主机发送到另一台主机，但是，我们在一台主机中往往不可能只有一个网络程序，所以当有多个网络程序同时工作的时候，我们依然会发现有如下问题 如何在多个网络程序运行的主机间进行数据传输，更简单的来说，就是如何实现一个主机的某个应用程序发出，然后由对方主机的应用程序接收？ 为了解决这个问题，聪明的前辈们又想到了解决办法，为每一个网络程序分配一个不同的数字来表示，发送数据的时候指定发送到某台主机的某个数字的网络程序不就可以了。这个数字就是端口。端口用 2 个字节来表示，范围是 0 ～ 65535，也就是最大 65535 个端口。一般情况下是足够用了。有了端口，我们来简单介绍下传输层的两种协议。 TCP我们知道网络层的数据包 IP 数据包都是不保证可靠性的，也就是说将数据发送出去，并不保证数据可达，并且数据发送也不保证有序。所以，为了满足一些对数据可靠性和有序性的应用。前辈们设计了新的协议 TCP 协议。TCP 协议保证了数据的可靠性，有序性，是面向连接的传输协议。如果发现有一个数据包收不到确认，就会重新发送数据包。 有了 TCP 协议，我们的应该程序可以将数据有序的，可靠的发送到对方指定端口的网络程序中。TCP 数据包格式 123+-----------------+--------------------+| head(20 byte) | data |+----------------=+--------------------+ TCP 建立连接需要经过 3 次握手，断开连接需要经过 4 次挥手。后面章节会详细来讲解整个过程，在此不详细介绍 UDP 不一定是所有的场景都必须要求数据的可靠性和有序性，有些应用程序只要求数据能快速高效的发送出去，至于可靠性并不十分关系，那这个时候 TCP 协议似乎不能满足这种需求。 其实 IP 协议的数据包就可以满足我们的新的需求，但是 IP 协议是网络层，不存在端口。而我们在传输层规定了端口，所以干脆就在传输层新设计一个协议 UDP 协议，UDP 协议其实就是在 IP 协议的基础上指定了端口（简单理解）。 UDP 是面向用户的（非连接的）传输层协议，这是因为 UDP 不像 TCP 需要 3 次握手建立连接的机制。UDP 协议相较于 TCP 来说实现比较简单，没有确认机制，数据包一旦发出，不保证数据可达和有序。不过一般情况下 UDP的数据包也不会有那么差的可靠性，还是能保证一定的可靠性。但是相较于 TCP ，UDP 的发送效率是比较快的。UDP 数据包的格式如下 123+-----------------+--------------------+| head(8 byte) | data (65527 byte) |+----------------=+--------------------+ 应用层有了上面介绍的三层协议的支持，我们可以满足各种情况下，将我们的数据包发送到指定的端口的网络程序中，但是，传输的数据都是字节流，程序并不能很好的识别，操作性相对比较差。因此，在应用层规范了各种各样的协议来规范我们的数据格式，同时也使得我们程序开发更为便利。常见的应用层协议有：HTTP、FTP、SMTP 等。针对不同类型的应用程序开发，可以使用不同的协议来开发。 每天在浏览器浏览网页，我们最熟悉的莫过于 HTTP 协议了。后面我会有专门的章节来详细讲解 HTTP 协议，这里不做过多介绍。 总结有了分层的模型，每一层基于协议又有非常明确的分工，使得计算机之间的数据传输有条不紊的进行。我们来自顶向下回顾一下每一层的数据传输过程： 应用层：应用层将用户输入的数据规范化，并根据应用层协议（如 HTTP 协议）封装成数据消息，传输给传输层 传输层：传输层拿到应用层消息，根据传输层协议，将数据再次包装，并加上传输层协议头，发给网络层 网络层：拿到传输层数据包，根据 IP 协议，将数据再次包装，加上 IP 协议头，发送给链路层 链路层：链路层拿到网络层数据包，再次包装层以太网数据包，加上以太网协议头。通过网卡发送给对方主机 再来自顶向下回顾一下每一层的职责： 应用层：按照应用层协议解析和规范用户数据 传输层：定义端口，确定要发送的目标主机上的应用程序，根据协议的不同，控制数据的传输 网络层：定义 IP 地址；分配网络地址和主机地址；解析 MAC 地址；将不在同一子网的数据包路由转发 链路层：对 0 1进行分组，定义数据帧，确认对方主机 MAC 地址。通过物理媒介传输到对方主机的网卡 本文只是对 TCP/IP 协议栈各个层工作的一个概述，具体每一层的协议，后面会有专门的章节来介绍。 参考文献 深入浅出 TCP/IP 协议栈","categories":[{"name":"Network","slug":"Network","permalink":"http://phachon.github.io/categories/Network/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"TCP/IP 协议栈系列（一）：模型简介","slug":"network/TCP-IP-1","date":"2018-09-09T16:00:00.000Z","updated":"2022-08-06T04:25:02.803Z","comments":true,"path":"network/TCP-IP-1.html","link":"","permalink":"http://phachon.github.io/network/TCP-IP-1.html","excerpt":"本系列将由浅入深通俗的讲解 TCP/IP 协议栈的基本知识，希望能对读者有用。 OSI 七层模型TCP/IP 协议栈是在借鉴了 OSI 七层模型的基础上提出来的模型，所以我们有必要先来了解一下 OSI 七层模型。 OSI 模型是计算机网路体系结构发展的产物。它的基本内容是开放系统通信功能的分层结构。通俗来讲，就是为了计算机系统的通信功能设计的一套标准的框架，大家都遵循这套标准来进行网络通信的开发，OSI 七层模型如下：","text":"本系列将由浅入深通俗的讲解 TCP/IP 协议栈的基本知识，希望能对读者有用。 OSI 七层模型TCP/IP 协议栈是在借鉴了 OSI 七层模型的基础上提出来的模型，所以我们有必要先来了解一下 OSI 七层模型。 OSI 模型是计算机网路体系结构发展的产物。它的基本内容是开放系统通信功能的分层结构。通俗来讲，就是为了计算机系统的通信功能设计的一套标准的框架，大家都遵循这套标准来进行网络通信的开发，OSI 七层模型如下： 应用层：通过不同的应用层协议来提供特定的应用层服务或者应用；http / smtp / ftp 表示层：数据压缩、数据加密、数据描述 会话层：负责建立、管理和终止表示层实体之间的通信会话 传输层：为两台的主机间的进程提供传输协议；tcp / udp 网络层：为两台主机网络查找、寻址、路由提供协议；ip 数据链路层：物理机之间传输数据的协议；以太网协议 物理层：硬件定义的接口 具体每一层的作用，这里不再详细说明； TCP/IP 四层模型TCP/IP 协议栈基于 OSI 七层模型提出来 TCP/IP 四层模型，也就是简化了的 OSI 模型： 应用层 传输层 网络层 链路层 OSI 七层模型和 TCP/IP 4 层模型之间的关系如下： 对比总结OSI 七层模型 主要概念：服务，接口，协议 协议有很好的隐蔽性 产生在协发明之前 7层 TCP/IP 模型 没有明确的区分服务，接口，协议 产生在协议发明之后 4层","categories":[{"name":"Network","slug":"Network","permalink":"http://phachon.github.io/categories/Network/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"Go runtime 系列之 - 启动过程","slug":"go/go-runtime-bootstrap","date":"2018-09-08T16:00:00.000Z","updated":"2022-07-11T01:59:03.320Z","comments":true,"path":"go/go-runtime-bootstrap.html","link":"","permalink":"http://phachon.github.io/go/go-runtime-bootstrap.html","excerpt":"通过查阅资料，了解 Go 语言的启动过程。 启动总体顺序 命令行参数解析 操作系统相关初始化 调度器初始化 创建 main.goroutine 运行 main 函数 命令行参数初始化主要是解析命令行参数并保存 操作系统相关初始化主要是确定操作系统的 CPU 核数，CPU 核数决定默认的了 P 的数量","text":"通过查阅资料，了解 Go 语言的启动过程。 启动总体顺序 命令行参数解析 操作系统相关初始化 调度器初始化 创建 main.goroutine 运行 main 函数 命令行参数初始化主要是解析命令行参数并保存 操作系统相关初始化主要是确定操作系统的 CPU 核数，CPU 核数决定默认的了 P 的数量 调度器初始化调度器的初始化时启动程序的核心 设置 M 的最大数量（10000） 内存相关初始化 M 的初始化 存储命令行参数和环境变量 解析 Debug 调试参数 初始化垃圾回收器 初始化 poll 时间 社会最大的 P 的数量，默认是 CPU 核数 main.goroutine 初始化 设置栈的最大值 启动后台监控 初始化 runtime.init 及 runtime 包 启动垃圾回收器 初始化 main.init 及用户或第三方引入的包 执行 main.main 函数执行入口函数，开始运行 参考资料： Go 程序是怎样跑起来的","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"Go runtime 系列之 - defer 机制","slug":"go/go-runtime-defer","date":"2018-09-08T16:00:00.000Z","updated":"2022-07-11T01:59:03.320Z","comments":true,"path":"go/go-runtime-defer.html","link":"","permalink":"http://phachon.github.io/go/go-runtime-defer.html","excerpt":"","text":"参考资料： 探究 Go 语言 defer 语句的三种机制","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"Go runtime 系列之 - 垃圾回收","slug":"go/go-runtime-gc","date":"2018-09-08T16:00:00.000Z","updated":"2022-07-11T01:59:03.320Z","comments":true,"path":"go/go-runtime-gc.html","link":"","permalink":"http://phachon.github.io/go/go-runtime-gc.html","excerpt":"","text":"参考文档： Golang 垃圾回收剖析 Golang GC核心要点和度量方法 屌炸天的新版GoGC之twitch的GC优化之路","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"Go runtime 系列之 - goroutine 过程","slug":"go/go-runtime-goroutine","date":"2018-09-08T16:00:00.000Z","updated":"2022-07-11T01:59:03.320Z","comments":true,"path":"go/go-runtime-goroutine.html","link":"","permalink":"http://phachon.github.io/go/go-runtime-goroutine.html","excerpt":"","text":"","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"Go runtime 系列之 - 内存分配","slug":"go/go-runtime-mem","date":"2018-09-08T16:00:00.000Z","updated":"2022-07-11T01:59:03.320Z","comments":true,"path":"go/go-runtime-mem.html","link":"","permalink":"http://phachon.github.io/go/go-runtime-mem.html","excerpt":"","text":"参考文档： Go 语言内存管理（一）：系统内存管理 在 Go 中恰到好处的内存对齐 图解Go语言内存分配 Go 内存分配器可视化指南 tcmalloc 介绍 图解 TCMalloc","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"Go runtime 系列之 - 信号处理","slug":"go/go-runtime-signal","date":"2018-09-08T16:00:00.000Z","updated":"2022-07-11T01:59:03.320Z","comments":true,"path":"go/go-runtime-signal.html","link":"","permalink":"http://phachon.github.io/go/go-runtime-signal.html","excerpt":"","text":"参考文档：","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"Go runtime 系列之 - Timer 机制","slug":"go/go-runtime-timer","date":"2018-09-08T16:00:00.000Z","updated":"2022-07-11T01:59:03.321Z","comments":true,"path":"go/go-runtime-timer.html","link":"","permalink":"http://phachon.github.io/go/go-runtime-timer.html","excerpt":"","text":"参考资料： Golang 定时器底层实现深度剖析 CPU功耗优化300倍的过程","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"并发服务器的实现方式","slug":"linux/concurrrent-server","date":"2018-09-08T16:00:00.000Z","updated":"2022-07-11T01:59:03.322Z","comments":true,"path":"linux/concurrrent-server.html","link":"","permalink":"http://phachon.github.io/linux/concurrrent-server.html","excerpt":"","text":"并发服务器的实现方式一般有三种：多进程服务器，多线程服务器，多路复用服务器 多进程服务器实现原理：当父进程 accept 一个请求之后，立即 Fork 出一个子进程去处理请求。而父进程则继续循环等待 accept 接受到新的请求。没有请求的情况下，父进程处于阻塞状态。 创建套接字 绑定（bind）服务器端口 监听（listen）端口 受理（accept）连接请求 给获取到新的请求创建网络套接字传递(fork)给子进程 子进程处理连接 继续（accept）等待新的连接 子进程会复制父进程的所有资源，多个子进程之间相互独立，互不影响。 多进程服务器的优点 由操作系统进行调度，运行相对稳定健壮 通过操作系统可以方便的进行监控和管理 比较好的隔离性，每个进程相互独立，不影响主程序的稳定性。 充分利用多核 CPU , 实现并行处理 多进程服务器的缺点 进程的创建和销毁比较消耗资源，每个进程都独立加载完整的应用环境，内存消耗比较大。 CPU 消耗高，高并发下，进程之间频繁的进行调度切换，需要大量的内存操作 进程数量限制了并发处理数，使得 I/O 的并发处理能力比较低 多线程服务器通常在一个进程中可以包含若干个线程，当然一个进程中至少有一个线程，不然没有存在的意义。线程可以利用进程所拥有的资源，在引入线程的操作系统中，通常都是把进程作为分配资源的基本单位，而把线程作为独立运行和独立调度的基本单位，由于线程比进程更小，基本上不拥有系统资源，故对它的调度所付出的开销就会小得多，能更高效的提高系统多个程序间并发执行的程度。 多线程服务器的实现： 创建套接字 绑定（bind）服务器端口 监听（listen）端口 受理（accept）连接请求 服务器通过 accept 受理连接请求 每当有新连接时，创建新的线程来处理用户请求 处理完成后，销毁线程 继续（accept）接收新的连接请求 多线程服务器的优点 对内存消耗小，线程之间共享进程的堆内存和数据，每个线程的栈都比较小，不超过 1M CPU 上下文切换比较快 线程的切换开销远低于进程，I/O 的并发能力强 多线程服务器的缺点 不方便操作系统的管理 由于线程存在对资源的共享操作，一旦出现死锁和线程阻塞，使得影响整个应用的稳定性 多路复用服务器多路复用即 I/O 多路复用，是指内核一旦发现进程指定的一个或者多个 I/O 条件准备读取，它就通知该进程。I/O复用原理：让应用程序可以同时对多个I/O端口进行监控以判断其上的操作是否可以进行，达到时间复用的目的。 select 模型使用 select 函数时，可以将多个文件描述符集中到一起进行监视： 是否存在套接字接受数据 无需阻塞传输数据的套接字有哪些 哪些套接字发生了异常 利用 select 函数实现 I/O 复用服务器实现过程描述： 创建套接字 绑定（bind）服务器端口 监听（listen）端口 注册服务端套接字到 fd_set 变量 while 循环 调用 select 函数监听 fd_set 里的套接字 监听发生状态变化的（有接受数据的）网络套接字 首先发生变化的是否是验证服务端套接字，如果是，则说明有新的连接请求，accept 新的请求，并将客户端连接的套接字注册到 fd_set 变量中 如果发生变化不是服务端套接字，则说明是客户端连接套接字，则读取客户端数据 读取的数据是 EOF，则证明套接需要关闭套接字，并从 select 注册的套接字中删除该套接字 select 的几大缺点： 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大 同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大 select支持的文件描述符数量太小了，默认是1024 利用 poll 实现 I/O 复用服务器实现过程和 select 函数大致相同，区别在于 select 使用的结构是集合 fd_set 结构，poll 使用的结构是 pollsd 结构。 利用 epoll 实现 I/O 复用服务器基于 select 的 I/O 复用服务器，有比较明显的不合理： 每次调用 select 函数后针对所有文件描述符分循环 每次调用 select 函数都需要向该函数传递监视对象的信息（fd_set） 每次调用 select 函数时是向操作系统传递监视对象信息，那必然会发生系统调用，需要把 fd 集合从用户态拷贝到内核态。开销太大 Linux 下的 epoll 具有如下优点： 无需编写以监视状态变化为目的针对所有文件描述符的循环语句 调用对应于 select 函数的 epoll_wait 函数无需每次都传递监视对象信息 epoll 提供了三个函数： epoll_create：是创建一个 epoll 句柄 epoll_ctl：是注册要监听的事件类型 epoll_wait：则是等待事件的产生 实现过程描述： 创建套接字 绑定（bind）服务器端口 监听（listen）端口 epoll_create 创建 epoll 例程 epoll_ctl(add) 注册事件到 epoll 句柄 while 循环 调用 epoll_wait 函数监听套接字 监听发生状态变化的（有接受数据的）网络套接字 首先发生变化的是否是验证服务端套接字，如果是，则说明有新的连接请求，accept 新的请求，并调用 epoll_ctl 将客户端连接的套接字注册到 epoll 句柄 如果发生变化不是服务端套接字，则说明是客户端连接套接字，则读取客户端数据 读取的数据是 EOF，则证明套接需要关闭套接字，调用 epoll_ctl(del) 注册事件到 epoll 句柄 epoll 和 selectp/poll 最大的区别： epoll_ctl 函数，每次注册新的事件到 epoll 句柄时，会把所有的 fd 拷贝进内核，而不是在 epoll_wait 的时候重复拷贝。epoll 保证了每一个 fd 在整个过程中只会拷贝一次 epoll 的解决方案不像 select 或 poll 一样每次都把需要监听的套接字加入 fd 对应的设备等待队列中，而只在 epoll_ctl 时挂载一遍，并为每个 fd 设置一个回调函数，当设备就绪，唤醒等待队列的等待者时，就会调用这个函数，而这个毁掉函数就会把 fd 加入一个有序链表。 epoll_wait 的工作实际上就是在这个就绪的链表中查看有没有就绪的 fd。 总结","categories":[{"name":"Linux","slug":"Linux","permalink":"http://phachon.github.io/categories/Linux/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"http://phachon.github.io/tags/tcp/"}]},{"title":"Go runtime 系列之 - 并发机制","slug":"go/go-runtime-concurrent","date":"2018-09-02T16:00:00.000Z","updated":"2022-07-11T01:59:03.320Z","comments":true,"path":"go/go-runtime-concurrent.html","link":"","permalink":"http://phachon.github.io/go/go-runtime-concurrent.html","excerpt":"在操作系统的搭建的内核线程之上，go 语言搭建了一个特有的两极线程模型。首先来了解一下线程实现模型，然后再详细了解 go 语言实现的 线程实现模型线程的实现模型主要有三种：用户级线程模型、内核级线程模型、两极线程模型。它们之间的区别主要是线程与内核调度对象之间的的对应关系。内核调度象也就是内核线程。 用户级线程模型用户级线程模型是由用户级别的线程库来全权管理的。也就是说，用户级线程模型下的线程是往往是通过应用程序的线程库来创建、切换、销毁的。与操作系统内核的线程没有关系。操作系统内核的线程调度器也无法调度用户级线程模型创建的线程。内核线程调度器只能调度创建此线程的的应用程序的进程。一个进程对应多个用户级线程，所以这种线程模型又称为多对一（M:1）的线程模型, 如下图所示：","text":"在操作系统的搭建的内核线程之上，go 语言搭建了一个特有的两极线程模型。首先来了解一下线程实现模型，然后再详细了解 go 语言实现的 线程实现模型线程的实现模型主要有三种：用户级线程模型、内核级线程模型、两极线程模型。它们之间的区别主要是线程与内核调度对象之间的的对应关系。内核调度象也就是内核线程。 用户级线程模型用户级线程模型是由用户级别的线程库来全权管理的。也就是说，用户级线程模型下的线程是往往是通过应用程序的线程库来创建、切换、销毁的。与操作系统内核的线程没有关系。操作系统内核的线程调度器也无法调度用户级线程模型创建的线程。内核线程调度器只能调度创建此线程的的应用程序的进程。一个进程对应多个用户级线程，所以这种线程模型又称为多对一（M:1）的线程模型, 如下图所示： 优势 对线程的各种管理调度与内核无关。应用程序对线程的创建、终止、切换等操作不需要让CPU从用户态切换到内核态。速度方面比较有优势 由于不依赖内核，所以程序的一致性比较强 劣势 由于此模型下内核调度的最小单位是进程。如果线程阻塞，则整个进程被阻塞。 不能真正利用多核 CPU 来实现并发。进程中的多个线程无法被分配到多个 CPU 中去执行。 综上所述，由于缺陷明显，所以现在的操作系统一般不使用此种模型来实现线程 内核级线程模型和用户级线程相反，内核级线程是由内核来管理的，属于内核的一部分。应用程序对线程的创建、终止、切换等操作必须通过内核提供的系统调用来完成。进程中的每一个线程都与内核线程一一对应由此，也称为一对一（1：1）的线程模型。如下图所示： 优势 一对一的线程模型消除了多对一的线程模型的不能真正并发的弊端，线程的管理由内核管理和调度，内核可以在不同的时间片内让CPU运行不同的线程。 即使某一个线程收到阻塞，其他线程不受影响 劣势 创建线程和管理线程的成本加大，要经常去系统调用来管理线程，线程管理的时间耗费的时间相对比较大。 如果一个进程包含大量的线程，将会给内核的调度器带来非常大的负担，甚至会影响操作系统的整体性能。 消耗更多的内核资源 尽管内核级线程也有劣势，但是相比用户级线程的优势还是比较明显的。很多的现代的操作系统都是以内核级线程模型来实现线程的。包括 Linux 操作系统。需要注意的是，在使用内核级线程模型时，必须了解每个进程允许的线程的最大数目是多少。防止线程数过大造成操作系统性能下降甚至崩溃。 两极线程模型两极线程模型是根据用户级线程模型和内核级线程模型综合演变而来。可以说是取前两种模型之精华，去前两种模型之糟粕。在此模型下，一个进程可以与多个内核线程相关联。这与内核级线程相似。但与内核线程模型不同的是，进程中的线程并不与内核线程一一对应，这些应用程序线程可以映射到同一个已关联的内核线程上。 首先实现了两极线程模型的线程库会通过操作系统调用创建多个内核线程。然后，它会通过这些内核线程对应用程序线程进行调度。大多数的此类线程库都可以将这些应用程序线程动态的与内核线程相关联。在这种实现中，进程有着自己的内核线程池。可运行的用户线程由运行时库分派并标记为准备好执行的可用线程。操作系统选择用户线程并将它映射到线程池中的可用内核线程。多个用户线程可以分配给相同的内核线程。如下图所示： 优势 内核资源的消耗大大减少 线程管理操作的效率提高 劣势 由于此种模型的线程设计使得管理工作变得更加复杂 因为两极线程的复杂性，往往不会被操作系统所采用，但是，这样的模型却可以很好地在编程语言层面上实现并充分发挥作用。Go 语言的并发模型正是在该模型的基础上实现的。 Go 语言并发模型Go 的线程实现模型。有三个必知的核心元素。他们支撑起了模型的主要框架。 M （machine）一个 M 代表一个内核线程 P （processor）一个 P 代表一个 Go 代码片段所必须的资源。goroutine依赖于 P 进行调度，P 是真正的并行单元； G （goroutine）一个 G 代表一个 Go 代码片段。 简单来说，一个 G 的执行，需要 P 和 M 的支持。一个 M 在一个 P 关联之后就形成了一个有效的 G 的运行环境（内核线程 + 上下文环境）。 对应关系： M 与操作系统内核线程是一对一的关系。即一个 M 只能代表一个内核级线程。并且他们之间的关系一旦关联一般不可改变。 M 与 P 之间的关系也是一对一的关系。但是他们之间的关联是易变的。会根据实际的调度来确定哪个 P 和 M 关联。 P 与 G 之间的关系是一对多的关系。因为每个 P 中都有一个可运行的 G 队列。 M上面已经讲了，一个 M 代表一个内核线程。一般情况下，创建 M 的时机一般是由于没有足够的 M 来管理 P ，并运行 P 中的可执行队列中的 G 。除此之外，在运行时系统执行监控和垃圾回收的过程中也会导致新的 M 的创建。 M 的核心结构字段123456789type M struct &#123; g0 *g // 特殊的 goroutine, 系统启动时创建，执行一些运行时任务 msstartfn func() // M 的其实函数。其实就是编写 go 语句时携带的函数 curg *g // 当前 M 正在执行的 G 指针 p punittr // 当前 M 关联的 P nextp punittr // 当前 M 预关联的 P ，可以理解为提前关联 spinning bool // 当前 M 是否正在寻找可运行的 G lockedg *g // 运行时系统可以把一个 M 和 一个 G 锁定在一起。那么这个 G 只能由这个 M 运行。&#125; M 的生命周期 创建 M，M 在创建后加入全局的 M 列表中。起始函数和预关联的 P 都会被设置好。 运行时系统会为 M 专门创建一个新的内核线程并与之相关联。 初始化 M （栈空间，信号等） 开始执行起始函数（如果存在的话） 起始函数执行完成后，当前 M 会与预关联的 P 完成关联，并准备执行其他任务。M 会依次在多处寻找可运行的 G 。 单个 Go 程序的 M 的最大值是可以设置的，初始化调度器的时候，会对 M 最大数量初始化。最大值为 10000。也就是说最多有 10000 个内核级线程服务于当前的 Go。但是在真正的操作系统运行环境中，基本上很难达到如此的量级的线程共存。所以可以忽略 Go 本身对于线程数量的限制。也可以通过标准库代码包 runtime/debug 中的 SetMaxThreads 函数来限制 M 的最大值。 PP 是 G 能够在 M 中运行的桥梁，Go 的运行时系统会适时的让 P 与不同的 M 建立或断开连接，使得 P 中的那些 G 能够及时获得运行时机，就像是操作系统内核在 CPU 之上的适时切换不同的进程和线程的场景类似改变 P 的最大数量有两种方法： 调用函数 runtime.GOMAXPROCS 传入参数的方式 在 Go 程序运行前设置环境变量 GOMAXPROCS 的值 P 的最大值是 Go 程序并发规模的的限制。P 的数量即可运行的 G 的队列的数量。一个 G 被启动后，首先会被追加到某个 P 中的可运行 G 队列中，等待时机运行。在设置 P 的最大值的时候，会检查该值的有效性，当前，Go 目前还不能保证在数量比 256 更多的 P 同时存在的情形下 Go 仍能保持高效，因此，只要不大于 256，都是被认为是有效的值。一般情况下，P 设置为当前计算机的 CPU 核数。 G每个 G 代表一个 goroutine, 编程时，我们使用 go 语句只是提交了一个并发任务。而 Go 的运行时系统则会安装要求并发执行它。那么当执行 go 关键字的时候发生了什么呢？Go 编译器会把 go 语句变成对内部函数 newproc (runtime.proc.go) 的调用。 1234567func newproc(siz int32, fn *funcval) &#123; argp := add(unsafe.Pointer(&amp;fn), sys.PtrSize) pc := getcallerpc(unsafe.Pointer(&amp;siz)) systemstack(func() &#123; newproc1(fn, (*uint8)(argp), siz, 0, pc) &#125;)&#125; 真正执行的函数在 newproc1(), 有需要请自行看源码，执行顺序如下： 获得当前的 G 所在的 P，然后从空闲的 G 队列中取出一个 G 如果 1 取到则对这个 G 进行参数配置，否则新建一个G 将 G 加入 P 的可运行的 G 队列 调度器在 Go 语言中，调度器的主要调度对象就是 M, P, G 的实例。调度器在调度过程中需要依赖全局的调度对象的容器。简单来说，为了方便调度，调度器会对 M,P,G 的实例存储在容器中。调度器的容器包括： 调度器的空闲 M 列表：存放空闲的 M 的单向链表 调度器的空闲 P 列表：存放空闲的 P 的单向链表 调度器的可运行 G 队列：存放可运行 G 的队列 调度器的自由 G 列表：存放自由的 G 的单向链表 调度器有自己的数据结构，形成此结构的主要目的是更加方便的管理和调度各个核心元素的实例。 基本结构goroutinegoroutine 的核心理念是： 1不要以共享内存的方式来通信。应该以通信作为手段来共享内存","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"Go 应用之 - mysql 建表问题的解决办法","slug":"go/go-app-mysql-table","date":"2018-02-04T16:00:00.000Z","updated":"2022-07-11T01:59:03.320Z","comments":true,"path":"go/go-app-mysql-table.html","link":"","permalink":"http://phachon.github.io/go/go-app-mysql-table.html","excerpt":"问题开发中需要利用 go 读取 sql 文件自动创建表。 table.sql 文件内容如下123456DROP TABLE IF EXISTS `user`;CREATE TABLE `user` ( `user_id` int(11) NOT NULL AUTO_INCREMENT COMMENT &#x27;主键ID&#x27;, `name` varchar(30) NOT NULL COMMENT &#x27;姓名&#x27;, PRIMARY KEY (`user_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&#x27;用户表&#x27;;","text":"问题开发中需要利用 go 读取 sql 文件自动创建表。 table.sql 文件内容如下123456DROP TABLE IF EXISTS `user`;CREATE TABLE `user` ( `user_id` int(11) NOT NULL AUTO_INCREMENT COMMENT &#x27;主键ID&#x27;, `name` varchar(30) NOT NULL COMMENT &#x27;姓名&#x27;, PRIMARY KEY (`user_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&#x27;用户表&#x27;; go 代码如下：1234567891011121314151617181920212223func createTable() (err error) &#123; host := &quot;127.0.0.1&quot; port := &quot;3306&quot; user := &quot;root&quot; pass := &quot;admin&quot; name := &quot;test&quot; sqlBytes, err = ioutil.ReadFile(&quot;docs/databases/table.sql&quot;); if err != nil &#123; return &#125; sqlTable := string(sqlBytes); fmt.Println(sqlTable) db, err := sql.Open(&quot;mysql&quot;, user+&quot;:&quot;+pass+&quot;@tcp(&quot;+host+&quot;:&quot;+port+&quot;)/&quot;+name+&quot;?charset=utf8&quot;) if err != nil &#123; return &#125; defer db.Close() _, err = db.Exec(sqlTable) if err != nil &#123; return &#125; return nil&#125;执行，出错：12Error 1064: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#x27;CREATE TABLE `user` (`user_id` int(11) NOT NULL AUTO_INCREMENT COMMEN&#x27; at line 1刚开始是以为 sql 语句本身有问题，所以将 sql 语句直接粘贴到 mysql 命令行执行，成功。所以不是 sql 语句的问题。 查找资料才知道原因是 mysql 默认是不能在一个语句中同时执行两条 sql 语句，把 drop table 和 create table 拆开。 解决办法 将 多条 sql 语句拆开，每个语句单独执行 db.Exec() 查看 go-sql-driver 的文档，发现可以支持一条语句多条 sql 执行。修改代码如下1db, err := sql.Open(&quot;mysql&quot;, user+&quot;:&quot;+pass+&quot;@tcp(&quot;+host+&quot;:&quot;+port+&quot;)/&quot;+name+&quot;?charset=utf8&amp;multiStatements=true&quot;) 增加了 &amp;multiStatements=true 参数","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/tags/Go/"},{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/tags/Mysql/"}]},{"title":"PHPUnit 学习实例代码","slug":"php/PHPUnit-Lean1","date":"2017-10-19T16:00:00.000Z","updated":"2022-07-11T01:59:03.324Z","comments":true,"path":"php/PHPUnit-Lean1.html","link":"","permalink":"http://phachon.github.io/php/PHPUnit-Lean1.html","excerpt":"PHPUnit 基本用法+实例详解上一篇文章介绍了 PHPUnit 在 windows 的安装和配置。今天我们来介绍一下 PHPUnit 如何编写一些基本的测试用例。我也是在最近才开始慢慢使用的 PHPUnit , 用不足之处，欢迎指正。 编写规范 测试类一般以***Test 命名； 该类必须继承 PHPUnit_Framework_TestCase 类； 类里的测试用例方法一般以test开头，当然也可以通过@test注释来定义一个名字不为test开头的方法为测试方法； 测试方法中需要使用断言方法来断言实际传入的参数与期望的参数是否一致来达到测试的目的；","text":"PHPUnit 基本用法+实例详解上一篇文章介绍了 PHPUnit 在 windows 的安装和配置。今天我们来介绍一下 PHPUnit 如何编写一些基本的测试用例。我也是在最近才开始慢慢使用的 PHPUnit , 用不足之处，欢迎指正。 编写规范 测试类一般以***Test 命名； 该类必须继承 PHPUnit_Framework_TestCase 类； 类里的测试用例方法一般以test开头，当然也可以通过@test注释来定义一个名字不为test开头的方法为测试方法； 测试方法中需要使用断言方法来断言实际传入的参数与期望的参数是否一致来达到测试的目的； 测试用例 基本的demo 定义一个类 DemoTest 并保存到 DemoTest.php 文件中 123456789101112131415161718192021222324252627282930313233343536&lt;?php/** * phpunit test demo * @author phachon@163.com */class DemoTest extends PHPUnit_Framework_TestCase &#123; /** * test */ public function testPushAndPop() &#123; $stack = array (); //断言 $stack 的长度为0 $this-&gt;assertEquals(0, count($stack)); array_push($stack, &#x27;foo&#x27;); //断言 $stack 的长度为 1 $this-&gt;assertEquals(1, count($stack)); //断言 $stack 的最后一个值为foo $this-&gt;assertEquals(&#x27;foo&#x27;, $stack[count($stack)-1]); //断言 $stack 出栈的值为 foo $this-&gt;assertEquals(&#x27;foo&#x27;, array_pop($stack)); //断言 $stack 的长度为 0 $this-&gt;assertEquals(0, count($stack)); &#125; /** * 定义test标签来声明是测试方法 * @test */ public function indexEquals() &#123; $stack = array (0,1,2,3,4); //断言 $stack 索引 0 的值为2 $this-&gt;assertEquals(2, $stack[0]); &#125;&#125; 上面的代码中定义了两种测试用例的方法，一种是开头为test, 一种是定义@test标签；两种都可以。然后运行测试这个类；打开命令窗口，进入该代码保存的文件目录输入:phpunit DemoTest.php运行结果为： 1234567Time:825 ms, Memory: 8.25MbThere was 1 failure:1) DemoTest::indexEqualsFailed asserting that 0 matches expected 2.D:\\server\\apache\\htdocs\\my_php_code\\phpunit\\stack\\DemoTest.php:32FAILURES!Tests: 2, Assertions: 6, Failures: 1. 解释一下：最上面的是一些耗时，内存消耗的多少。往下看测试结果说有一个错误，也就是测试未通过，在文件的32行。32行的意思是断言这个数组中索引为0的值为2，显然不是，这里我故意写错，所以测试失败。如果改为0则会显示OK;最后是显示2个测试用例，6个断言，其中一个失败。 方法依赖关系 在测试类中，测试用例方法可以有依赖关系。通过依赖关系可以传一些参数到方法中；因为默认的测试用例方法是不能有参数的。定义一个FunTest 类保存到文件中 1234567891011121314151617181920212223242526272829303132333435&lt;?php/** * 测试方法依赖关系 * @author phachon@163.com */class FuncTest extends PHPUnit_Framework_TestCase &#123; public function testEmpty() &#123; $stack = array (); $this-&gt;assertEmpty($stack); return $stack; &#125; /** * depends 方法用来表示依赖的方法名 * @depends testEmpty * @param array $stack * @return array */ public function testPush(array $stack) &#123; array_push($stack, &#x27;foo&#x27;); $this-&gt;assertEquals(&#x27;foo&#x27;, $stack[count($stack)-1]); return $stack; &#125; /** * @depends testPush * @param array $stack */ public function testPop(array $stack) &#123; $this-&gt;assertEquals(&#x27;foo&#x27;, array_pop($stack)); $this-&gt;assertEmpty($stack); &#125;&#125; 标签@depends是表示依赖关系，上面的代码中testPop()依赖testPush(),testPush()依赖testEmpty(), 所以当testEmpty()测试通过后返回的变量可以作为testPush(array $stack)的参数。同理，testPop()也是一样。运行结果如下： 12Time: 726 ms, Memory: 8.25MbOK (3 tests, 4 assertions) 测试通过 测试非依赖关系的方法传入参数 如果非依赖关系的方法，默认是不能有参数的，这个时候怎么样才能传参，PHPUnit 提供给了一个标签，@dataProvider定义一个DataTest类保存到文件中 12345678910111213141516171819202122232425262728293031323334&lt;?php/** * 测试非依赖关系的方法传入参数 * 方法提供者 * @author phachon@163.com */class DataTest extends PHPUnit_Framework_TestCase &#123; /** * dataProvider 标签用来提供数据的方法名 * @dataProvider add_provider */ public function testAdd($a, $b, $c) &#123; //断言 a + b = c $this-&gt;assertEquals($c, $a + $b); &#125; /** * 数据提供者的方法 * 格式： * return array( * array(参数1,参数2,参数3,参数4,参数N), * array(参数1,参数2,参数3,参数4,参数N), * ); */ public function add_provider() &#123; return array ( array (0, 0, 0), array (0, 1, 1), array (1, 0, 1), array (1, 1, 2), ); &#125;&#125; 看上面代码应该就能明白。直接运行phpunit DataTest.php运行结果如下： 12Time: 379 ms, Memory: 8.25MbOK (3 tests, 4 assertions) 数据提供者方法和依赖关系的限制 这个听起来有点绕口，意思是如果方法依赖和方法提供者同时使用的话，是有限制的。说半天我估计还是一塌糊涂，不解释，直接看代码定义一个 Data2Test 类保存到文件 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?php/** * 数据提供者方法和依赖关系的限制 * * 当一个测试方法依赖于另外一个使用data providers测试方法时, * 这个测试方法将会在它依赖的方法至少测试成功一次后运行, * 同时使用data providers的测试方法的执行的结果不能传入一个依赖它的测试方法中 * @author phachon@163.com */class Data2Test extends PHPUnit_Framework_TestCase &#123; public function testA() &#123; return 78; &#125; /** * @dataProvider add_provider * @depends testB */ public function testB($a, $b, $c) &#123; $this-&gt;assertEquals($c, $a + $b); return $a; &#125; /** * @depneds testB */ public function testC($a) &#123; var_dump($a); &#125; public function add_provider() &#123; return array ( array (0, 0, 0), array (0, 1, 1), array (1, 0, 1), array (1, 1, 2), ); &#125;&#125; 解释一下：testB 依赖于 testA (testA 使用了dataProvider 提供数据)如果 add_provider 提供的数据至少有一次是成功的，则在成功一次后运行 testC如果 add_provider 提供的数据没有一次是成功的，则 testC 一次也不会执行但是 testC 执行的结果永远是 null, 因为 $a 是通过 dataProvider 提供的。不能传入依赖它的测试方法中好像还是不太明白，反正我是尽力了。慢慢理解吧。 通过构造迭代器来为方法提供数据 通过标签 @dataProvider 来直接返回数据作为数据提供者，PHPUnit 也可以通过返回构造器对象来提供数据。上代码新建 IteratorTest.php 文件 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?php/** * 通过构造迭代器来为方法提供数据 * @author phachon@163.com */class myIterator implements Iterator &#123; private $_position = 0; private $_array = array ( array (0, 0, 0), array (0, 1, 1), array (1, 0, 1), array (1, 1, 2) ); public function current() &#123; echo 0; return $this-&gt;_array[$this-&gt;_position]; &#125; public function key() &#123; echo 1; return $this-&gt;_position; &#125; public function next() &#123; echo 2; ++$this-&gt;_position; &#125; public function valid() &#123; echo 3; return isset($this-&gt;_array[$this-&gt;_position]); &#125; public function rewind() &#123; echo 4; return $this-&gt;_position = 0; &#125;&#125; 123456789101112131415161718/** * 测试类 */class IteratorTest extends PHPUnit_Framework_TestCase &#123; /** * @dataProvider add_provider */ public function testAdd($a, $b, $c) &#123; $this-&gt;assertEquals($c, $a + $b); &#125; public function add_provider() &#123; return new myIterator(); &#125;&#125; 先定义了一个构造器，然后返回这个构造器对象，同样也能提供数据。运行 phpunit IteratorTest.php运行结果如下： 12Time: 408 ms, Memory: 8.25MbOK (4 tests, 4 assertions) 异常测试 有时候我们希望能够抛出我们所期待的异常。这里有三种方法来测试异常，上代码定义 ThrowTest 类保存到文件 123456789101112131415161718192021222324252627282930313233343536&lt;?php/** * 测试异常 * 三种方法 * @author phachon@163.com */class ThrowTest extends PHPUnit_Framework_TestCase &#123; /** * 1.注释法: expectedException 期待的异常 * @expectedExeption My_Exception */ public function testException1() &#123; &#125; /** * 2.设定法：$this-&gt;setExpectedException 期待的异常 */ public function testException2() &#123; $this-&gt;setExpectedException(&#x27;My_Exception&#x27;); &#125; /** * 3.捕获法：try catch */ public function testException3() &#123; try &#123; //代码 &#125; catch (My_Exception $e) &#123; //捕获到异常测试通过，否则失败 return ; &#125; $this-&gt;fail(&#x27;一个期望的异常没有被捕获&#x27;); &#125;&#125; 代码应该很明白了，不用解释了。 错误测试 有时候代码会发生错误，比如某个php文件找不到，文件不可读，php 文件加载失败等。这个时候我们也能进行测试，是否发生错误；PHPUnit 会把错误直接转化为异常PHPUnit_Framework_Error并抛出；我们要做到的是捕获这个异常。上代码。定义 ErrorTest 类保存到文件中 12345678910111213141516&lt;?php/** * 错误测试 * phpunit 会把错误直接转化为异常PHPUnit_Framework_Error并抛出 */class ErrorTest extends PHPUnit_Framework_TestCase &#123; /** * 期待捕获 PHPUnit_Framework_Error 的异常 * @expectedException PHPUnit_Framework_Error */ public function testError() &#123; //如果文件不存在就会抛出异常，我们需要捕获异常 include &#x27;../test.php&#x27;; &#125;&#125; 测试显示OK,则证明已经捕获。 对输出进行测试 有时候我们需要对程序的指定输出进行测试。比如echo 还是 print() 指定的值是否正确。定义类 OutputTest 类保存到文件 1234567891011121314151617&lt;?php/** * 输出测试 * @author phachon@163.com */class OutputTest extends PHPUnit_Framework_TestCase &#123; public function testExpectFooActualFoo() &#123; $this-&gt;expectOutputString(&#x27;foo&#x27;); print &#x27;foo&#x27;; &#125; public function testExpectBarActualBaz() &#123; $this-&gt;expectOutputString(&#x27;bar&#x27;); print &#x27;baz&#x27;; &#125;&#125; 注意: 在严格模式下，本身产生输出的测试将会失败。 基镜（fixture） PHPUnit 支持共享建立基境的代码。在运行某个测试方法前，会调用一个名叫 setUp() 的模板方法。setUp() 是创建测试所用对象的地方。当测试方法运行结束后，不管是成功还是失败，都会调用另外一个名叫 tearDown() 的模板方法。tearDown() 是清理测试所用对象的地方。 12345678910111213141516171819202122232425&lt;?phpclass FixTureTest extends PHPUnit_Framework_TestCase &#123; protected $stack; protected function setUp() &#123; $this-&gt;stack = array(); &#125; public function testEmpty() &#123; $this-&gt;assertTrue(empty($this-&gt;stack)); &#125; public function testPush() &#123; array_push($this-&gt;stack, &#x27;foo&#x27;); $this-&gt;assertEquals(&#x27;foo&#x27;, $this-&gt;stack[count($this-&gt;stack)-1]); $this-&gt;assertFalse(empty($this-&gt;stack)); &#125; public function testPop() &#123; array_push($this-&gt;stack, &#x27;foo&#x27;); $this-&gt;assertEquals(&#x27;foo&#x27;, array_pop($this-&gt;stack)); $this-&gt;assertTrue(empty($this-&gt;stack)); &#125;&#125; 以上是PHPUnit 官方的一个代码示例。测试类的每个测试方法都会运行一次 setUp() 和 tearDown() 模板方法（同时，每个测试方法都是在一个全新的测试类实例上运行的）。另外，setUpBeforeClass() 与 tearDownAfterClass() 模板方法将分别在测试用例类的第一个测试运行之前和测试用例类的最后一个测试运行之后调用。 setUp() 多 tearDown() 少理论上说，setUp() 和 tearDown() 是精确对称的，但是实践中并非如此。实际上，只有在 setUp() 中分配了诸如文件或套接字之类的外部资源时才需要实现 tearDown() 。如果 setUp() 中只创建纯 PHP 对象，通常可以略过 tearDown()。不过，如果在 setUp() 中创建了大量对象，你可能想要在 tearDown() 中 unset() 指向这些对象的变量，这样它们就可以被垃圾回收机制回收掉。对测试用例对象的垃圾回收动作则是不可预知的。 —PHPUnit 官方网站 总结好了，今天大概就先介绍这些，已经可以大概写一些测试用例了。当然还有更高级的测试使用方法。现在为什么不讲呢，因为我也不会。。","categories":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"},{"name":"PHPUnit","slug":"PHPUnit","permalink":"http://phachon.github.io/tags/PHPUnit/"}]},{"title":"PHPUnit windows 下的安装","slug":"php/PHPUnit-install-windows","date":"2017-10-19T16:00:00.000Z","updated":"2022-07-11T01:59:03.324Z","comments":true,"path":"php/PHPUnit-install-windows.html","link":"","permalink":"http://phachon.github.io/php/PHPUnit-install-windows.html","excerpt":"本篇文章介绍一下 PHPUnit 在 windows 下的安装和配置 准备 php 版本 php5.4.45 phpunit 版本 phpunit4.8.24 操作系统：windows 7 (32) php 安装（这里不再详细讲解） phpunit 下载地址：https://phpunit.de/ 下载到文件 phpunit-4.8.24.phar","text":"本篇文章介绍一下 PHPUnit 在 windows 下的安装和配置 准备 php 版本 php5.4.45 phpunit 版本 phpunit4.8.24 操作系统：windows 7 (32) php 安装（这里不再详细讲解） phpunit 下载地址：https://phpunit.de/ 下载到文件 phpunit-4.8.24.phar 安装 将下载的 phpunit-4.8.24.phar 文件保存保存为phar到你自己设定的目录，如我的目录是D：\\server\\phpunit 下。 配置 path 环境变量；计算机右击属性—&gt;高级系统设置—&gt;环境变量–&gt; 在系统变量下找到 path 一栏，选中，编辑。添加 phpunit 路径;D:\\server\\phpunit 到最后。注意 ; 不要忘记。 按快捷键Win + R ，输入cmd并回车。打开 cmd 命令窗口，进入phpunit 的文件目录。D：\\server\\phpunit 输入 echo @php “%~dp0phpunit.phar” %* &gt; phpunit.cmd 接着输入phpunit –version 并回车显示如下 1PHPUnit 4.8.24 by Sebastian Bergmann and contributors 表示安装成功。（如果有误，输入exit 并回车，重新来一遍） 注意：如果失败，请检查你的 php path 变量是否配置 基本命令 –log-tap 生成TAP格式的日志文件 –log-dbus 使用DBUS记录测试的执行情况 –log-json 生成JSON格式的日志文件 –coverage-html 生成html格式的代码覆盖报告请注意这个功能只能在tokenizer和Xdebug安装后才能使用 –coverage-clover 生成xml格式的代码覆盖报告请注意这个功能只能在tokenizer和Xdebug安装后才能使用 –testdox-html and –testdox-text 生成记录已运行测试的html或者纯文本格式的文件文档 –filter 只运行名字符合参数规定的格式的测试，参数可以是一个测试的名字或者一个匹配多个测试名字的正则表达式 –group 只运行规定的测试组，一个测试可以使用@group注释来分组 @author注视是一个和@group关联的注释标签，用来根据作者来过滤测试 –exclude-group 只包含规定的多个测试组，一个测试可以使用@group注释来分组 –list-groups 列出可用的测试组 –loader 定义使用PHPUnit_Runner_TestSuiteLoader的接口 –repeat 根据定义的数字重复运行测试 –tap 使用Test Anything Protocol格式报告测试进程 –testdox 使用agile documentation格式报告测试进程 –colors 在输出结果中使用颜色 –stderr 使用STDERR替代STDOUT输出结果 –stop-on-error 在遇到第一个错误时停止执行 –stop-on-failure 在遇到第一个失败时停止执行 –stop-on-skipped 在遇到第一个跳过的测试时停止执行 –stop-on-incomplete 在遇到第一个未完成的测试时停止执行 –strict 当一个测试没有定义任何断言时将其标记为未完成的测试 –verbose 输出例如未完成的测试的名字，跳过的测试的名字 –wait 在每个测试开始之前等待用户按键，这个在你一个保持打开的窗口中运行很长的测试时很有帮助 –skeleton-class 从一个测试类中生成一个概要测试类 –skeleton-test 在Unit.php内为类Unit生成一个概要测试类UnitTest –process-isolation 在多个php进程中运行所有测试 –no-globals-backup 不备份和还原$GLOBALS变量 –static-backup 备份和还原用户定义的类中的静态变量 –syntax-check 对测试的代码文件开启语法检查 –bootstrap 定义测试前运行的bootstrap的php文件的路径 –configuration, -c 从xml文件中读取配置，增加-c参数看更多的内容如果phpunit.xml或phpunit.xml.dist(根据这个模式)在当前的目录中存在且–configuration参数没有使用的时候，配置信息会被自动读取 –no-configuration 自动跳过当前目录的phpunit.xml和phpunit.xml.dist配置文件 –include-path 在php的include_path增加路径 -d 定义php的配置属性 –debug 输出调试信息如测试的名称及该测试什么时候开始执行 提示当测试代码中含有php语法错误的时候，测试器会退出且不会打印任何错误信息，standard test suite loader可选择性检查测试文件源代码的PHP语法错误，但是不会检查测试文件中引入的其他的代码文件的语法错误","categories":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"},{"name":"Windows","slug":"Windows","permalink":"http://phachon.github.io/tags/Windows/"},{"name":"PHPUnit","slug":"PHPUnit","permalink":"http://phachon.github.io/tags/PHPUnit/"}]},{"title":"Go 应用之 - 获取文件信息方法","slug":"go/go-app-fileinfo","date":"2017-10-09T16:00:00.000Z","updated":"2022-07-11T01:59:03.319Z","comments":true,"path":"go/go-app-fileinfo.html","link":"","permalink":"http://phachon.github.io/go/go-app-fileinfo.html","excerpt":"最近一直在写 go 语言，总结下go获取文件信息的方法 获取文件修改时间1234fileInfo, _ := os.Stat(&quot;test.log&quot;)//修改时间modTime := fileInfo.ModTime()fmt.Println(modTime)","text":"最近一直在写 go 语言，总结下go获取文件信息的方法 获取文件修改时间1234fileInfo, _ := os.Stat(&quot;test.log&quot;)//修改时间modTime := fileInfo.ModTime()fmt.Println(modTime) 判断文件是否存在1234_, err := os.Stat(&quot;test.log&quot;)if(os.IsNotExist(err)) &#123; fmt.Println(&quot;file not exist!&quot;)&#125; 文件是否是目录1234fileInfo, _ := os.Stat(&quot;test.log&quot;)//是否是目录isDir := fileInfo.IsDir()fmt.Println(isDir) 文件权限1234fileInfo, _ := os.Stat(&quot;test.log&quot;)//权限mode := fileInfo.Mode()fmt.Println(mode) 获取文件名1234fileInfo, _ := os.Stat(&quot;test.log&quot;)//文件名filename:= fileInfo.Name()fmt.Println(filename) 获取文件大小1234fileInfo, _ := os.Stat(&quot;test.log&quot;)//文件大小filesize:= fileInfo.Size()fmt.Println(filesize)//返回的是字节 获取文件创建时间文件的创建时间并没有直接的方法返回，翻看源代码才知道如何获取 12345fileInfo, _ := os.Stat(&quot;test.log&quot;)fileSys := fileInfo.Sys().(*syscall.Win32FileAttributeData)nanoseconds := fileSys.CreationTime.Nanoseconds() // 返回的是纳秒createTime := nanoseconds/1e9 //秒fmt.Println(createTime) 文件最后写入时间12345fileInfo, _ := os.Stat(&quot;test.log&quot;)fileSys := fileInfo.Sys().(*syscall.Win32FileAttributeData)nanoseconds := fileSys.LastWriteTime.Nanoseconds() // 返回的是纳秒lastWriteTime := nanoseconds/1e9 //秒fmt.Println(lastWriteTime) 文件最后访问时间12345fileInfo, _ := os.Stat(&quot;test.log&quot;)fileSys := fileInfo.Sys().(*syscall.Win32FileAttributeData)nanoseconds := fileSys.LastAccessTime.Nanoseconds() // 返回的是纳秒lastAccessTime:= nanoseconds/1e9 //秒fmt.Println(lastAccessTime) 文件属性1234fileInfo, _ := os.Stat(&quot;test.log&quot;)fileSys := fileInfo.Sys().(*syscall.Win32FileAttributeData)fileAttributes:= fileSys.FileAttributesfmt.Println(fileAttributes) 介绍一个我用 go 写的日志管理包，地址： https://github.com/phachon/go-logger","categories":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://phachon.github.io/tags/Go/"}]},{"title":"Bootstrap html后台模板总结","slug":"html/bootstrap-html","date":"2017-09-12T16:00:00.000Z","updated":"2022-07-11T01:59:03.321Z","comments":true,"path":"html/bootstrap-html.html","link":"","permalink":"http://phachon.github.io/html/bootstrap-html.html","excerpt":"","text":"总结的一些模板在个人的 github 地址，有需要的欢迎下载或 forkhttps://github.com/phachon/html-templates","categories":[{"name":"Html","slug":"Html","permalink":"http://phachon.github.io/categories/Html/"}],"tags":[{"name":"Bootstrap","slug":"Bootstrap","permalink":"http://phachon.github.io/tags/Bootstrap/"},{"name":"Html","slug":"Html","permalink":"http://phachon.github.io/tags/Html/"}]},{"title":"后端知识点总结","slug":"summary/knowledage","date":"2017-09-04T16:00:00.000Z","updated":"2022-07-11T01:59:03.326Z","comments":true,"path":"summary/knowledage.html","link":"","permalink":"http://phachon.github.io/summary/knowledage.html","excerpt":"","text":"数据结构 顺序表 链表 单向链表 双向链表 循环链表 队列 循环队列 链队列 栈 顺序栈 链栈 集合 树 二叉树 二叉树遍历 二叉查找树 平衡二叉树 红黑树 B 树 B 树的应用 LSM 树 算法 常见面试算法 算法 常被问到的算法题 面试算法题 剑指 OFFER 排序 各种排序算法复杂度分析 排序算法 十大经典的排序算法 查找 二分查找 插值查找 斐波那契查找 二叉查找树查找 哈希查找 过滤 大数据处理-Bitmap 布隆过滤器 基于 Redis 的 Bitmap 数据结构 网络爬虫：URL去重策略之布隆过滤器(BloomFilter)的使用 字符串匹配 KMP 字符串匹配 图遍历 深度优先遍历和广度优先遍历 贪心算法 《算法：贪婪算法基础》 《常见算法及问题场景——贪心算法》 一致性哈希 一致性哈希在Redis集群中的应用 网络知识 七层协议 TCP TCP 协议 TCP 三次握手 TCP中11种状态 TCP/IP/UDP协议详解 TCP/IP网络协议栈 TCP滑动窗口详解 TCP 知识点总结 TCP面试题集 UDP UDP 协议总结 KDP KCP 原理及源码解析 HTTP Http 协议详细讲解 Http1.0 和 Http1.1区别 Http2.0 原理详细分析 Http2.0 二进制帧 Session 和 Cookie 理解 Session 和 Cookie机制 跨域问题 跨域问题2 HTTPS Https 总结 Https 通俗了解 HTTPS协议详解(一)：HTTPS基础知识 HTTPS协议详解(二)：TLS/SSL工作原理 HTTPS协议详解(三)：PKI 体系 HTTPS协议详解(四)：TLS/SSL握手过程 HTTPS协议详解(五)：HTTPS性能与优化 进程线程协程 进程、线程、协程之概念理解 进程 进程的概念 进程间的同步机制 僵尸进程 线程 线程的基本概念 线程的三种实现方式 进程和线程的区别和联系 协程 协程的历史，现在和未来 以goroutine为例看协程的相关概念 PHP中协程的使用 内存分配 TCMalloc介绍 图解TCMalloc 内存优化总结 Linux命令 50个最常用的命令 Tcpdump使用抓包总结 Linux三剑客之awk命令 使用awk,wc,sort,uniq,grep对nginx日志进行分析 中间件MySQL 学习MySQL优化原理，这一篇就够了 数据库优化 MySQL 数据库索引优化项目实战 MySQL索引原理及慢查询优化 mysql面试 mysql面试集锦 索引区别 数据库优化 Redis Redis总结 Redis底层原理 Redis 实现分布式锁 PHP Redis实现分布式锁 为什么 Redis 是单线程的 理解 redis 跳表 redis 底层数据结构 Redis面试”刁难”问题 Redis 防止雪崩或穿透 redis总结篇 RabbitMQ RabbitMQ基础知识详解 RabbitMQ概念总结 深入了解RabbitMQ Nginx Nginx原理和优化 Nginx基础配置详解 Nginx基本学习 Apache 浅析 Apache 工作原理 Apache运行机制剖析 Nginx与Apache的对比及优缺点 Memcache 基本使用 深入理解 memcache 原理 Redis和Memcache区别，优缺点对比 Memcached实现机制 MemCache 基础介绍与工作原理 memcache的介绍与应用场景 Sphinx Sphinx 的介绍和原理探索 Sphinx 在网站架构中的应用 ELK ELK多种架构及优势 Go语言 Golang 新手可能会踩的 50 个坑 基础 常见知识点 笔试网站 make和new区别 golang中的引用类型 高级 Golang适合高并发场景的原因分析 内存分配 内存分配与管理 内存管理 内存管理和垃圾回收 启动过程 go语言启动过程 并发机制 go语言并发机制 go 调度器 golang并发原理分析 理解 goroutine 的并发 Goroutine调度机制 Goroutine并发调度模型深度解析之手撸一个协程池 也谈goroutine调度器 go源码分析博客 channel channel的底层实现 深入理解 interface 其他 fasthhtp 的优化 PHP 基本知识点总结 综合 知识回顾 变量在 PHP7 内部的实现（一） 变量在 PHP7 内部的实现（二） 设计模式 23中设计模式深入理解 项目总结实现短网址项目https://www.jianshu.com/p/43eea66a2235https://www.cnblogs.com/lovekingly/p/5505308.htmlhttps://www.jb51.net/article/136554.htmhttps://www.cnblogs.com/flying1819/articles/8832640.html","categories":[{"name":"Summary","slug":"Summary","permalink":"http://phachon.github.io/categories/Summary/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"PHP 内核知识点总结","slug":"php/php-kernel","date":"2017-07-22T16:00:00.000Z","updated":"2022-07-11T01:59:03.324Z","comments":true,"path":"php/php-kernel.html","link":"","permalink":"http://phachon.github.io/php/php-kernel.html","excerpt":"","text":"PHP 的基本架构 Zend引擎：Zend 整体用纯C实现，是 PHP 的内核部分，它将 PHP 代码翻译（词法、语法解析等一系列编译过程）为可执行 opcode 的处理并实现相应的处理方法、实现了基本的数据结构（如hashtable、oo）、内存分配及管理、提供了相应的 api 方法供外部调用，是一切的核心，所有的外围功能均围绕 Zend 实现。 Extensions：围绕着 Zend 引擎，extensions 通过组件式的方式提供各种基础服务，我们常见的各种内置函数（如 array 系列）、标准库等都是通过 extension 来实现，用户也可以根据需要实现自己的 extension 以达到功能扩展、性能优化等目的（如贴吧正在使用的 PHP 中间层、富文本解析就是 extension 的典型应用）。 Sapi：Sapi 全称是 Server Application Programming Interface，也就是服务端应用编程接口，Sapi 通过一系列钩子函数，使得 PHP 可以和外围交互数据，这是 PHP 非常优雅和成功的一个设计，通过 sapi 成功的将PHP本身和上层应用解耦隔离，PHP 可以不再考虑如何针对不同应用进行兼容，而应用本身也可以针对自己的特点实现不同的处理方式。 apache2handler：这是以apache作为webserver，采用mod_PHP模式运行时候的处理方式，也是现在应用最广泛的一种。 cgi：这是webserver和PHP直接的另一种交互方式，也就是大名鼎鼎的fastcgi协议，在最近今年fastcgi+PHP得到越来越多的应用，也是异步webserver所唯一支持的方式。 cli：命令行调用的应用模式 上层应用：这就是我们平时编写的 PHP 程序，通过不同的 sapi 方式得到各种各样的应用模式，如通过 webserver 实现 web 应用、在命令行下以脚本方式运行等等。 PHP 执行过程 第一步：启动 web 服务器，如果是 apache, apache 通过 mod_php5.so 调用 sapi 接口启动 php 解释器，如果是 nginx, nginx 调用 php-fpm(php fast-cgi进程管理器)启动 php-fpm，php 内核调用各个扩展的初始化方法，使之处于激活状态 第二部：当发生请求时候, SAPI 将控制权交给 php 核心层, php 设置了本次请求的变量 第三部：php 核心层调用 zend 引擎将 php 源代码编译成 opcode 码，并在 zend 虚拟机运行得出结果，将结果返回给 php 核心层 词法分析 语法分析 生成 opcode 码 执行 opcode 码 第四部：php 核心层将返回结果通过 sapi 返回给 web 服务器，web 服务器将结果渲染在浏览器 PHP SAPI 生命周期PHP开始执行以后会经过两个主要的阶段： 处理请求之前的开始阶段 第一个过程是模块初始化阶段（MINIT），在整个SAPI生命周期内 (例如 Apache 启动以后的整个生命周期内或者命令行程序整个执行过程中)， 该过程只进行一次。 第二个过程是模块激活阶段（RINIT），该过程发生在请求阶段，例如通过 url 请求某个页面，则在每次请求之前都会进行模块激活（RINIT请求开始）。 请求处理完后就进入了结束阶段，一般脚本执行到末尾或者通过调用 exit() 或 die() 函数， PHP 都将进入结束阶段。和开始阶段对应，结束阶段也分为两个环节。 请求之后的结束阶段 一个在请求结束后停用模块(RSHUTDOWN，对应RINIT) 一个在 SAPI 生命周期结束（Web服务器退出或者命令行脚本执行完毕退出）时关闭模块(MSHUTDOWN，对应MINIT) 例如执行 test.php 1php -f test.php 调用每个模块的初始化前，初始化过程： 初始化若干全局变量 初始化若干常量 初始化Zend引擎和核心组件 解析 php.ini 全局操作函数的初始化 初始化静态构建的模块和共享模块(MINIT) 多进程SAPI生命周期通常PHP是编译为apache的一个模块来处理PHP请求。Apache一般会采用多进程模式， Apache启动后会fork出多个子进程，每个进程的内存空间独立，每个子进程都会经过开始和结束环节， 不过每个进程的开始阶段只在进程fork出来以来后进行，在整个进程的生命周期内可能会处理多个请求。 只有在Apache关闭或者进程被结束之后才会进行关闭阶段，在这两个阶段之间会随着每个请求重复请求开始-请求关闭的环节。 多线程的SAPI生命周期多线程模式和多进程中的某个进程类似，不同的是在整个进程的生命周期内会并行的重复着 请求开始-请求关闭的环节 Apache 加载 PHP 模块当PHP需要在Apache服务器下运行时，一般来说，它可以mod_php5模块的形式集成， 此时mod_php5模块的作用是接收Apache传递过来的PHP⽂件请求，并处理这些请求， 然后将处理后的结果返回给Apache。如果我们在Apache启动前在其配置⽂件中配置好了PHP模块（mod_php5）， PHP模块通过注册apache2的ap_hook_post_config挂钩，在Apache启动的时候启动此模块以接受PHP文件的请求。 静态加载 1LoadModule php5_module modules/mod_php5.so 动态加载如果需要在服务器运行时加载模块， 可以通过发送信号HUP或者AP_SIG_GRACEFUL给服务器，一旦接受到该信号，Apache将重新装载模块， ⽽不需要重新启动服务器。 Apache 运行过程Apache的运行分为启动阶段和运行阶段。 启动阶段Apache为了获得系统资源最⼤的使用权限，将以特权用户root（*nix系统）或超级管理员Administrator(Windows系统)完成启动， 并且整个过程处于一个单进程单线程的环境中。 这个阶段包括配置⽂件解析(如http.conf⽂件)、模块加载(如mod_php，mod_perl)和系统资源初始化（例如⽇志⽂件、共享内存段、数据库连接等）等⼯作。Apache的启动阶段执行了⼤量的初始化操作，并且将许多⽐较慢或者花费⽐较⾼的操作都集中在这个阶段完成，以减少了后⾯处理请求服务的压⼒。 运行阶段Apache主要⼯作是处理用户的服务请求。 在这个阶段，Apache放弃特权用户级别，使用普通权限，这主要是基于安全性的考虑，防⽌由于代码的缺陷引起的安全漏洞。 Apache对HTTP的请求可以分为连接、处理和断开连接三个⼤的阶段。 PHP 的几种运行方式https://phachon.com/2016/07/29/php-run-type/ PHP 程序的执行过程 如上例中， 传递给php程序需要执行的⽂件， php程序完成基本的准备⼯作后启动PHP及Zend引擎，加载注册的扩展模块。 初始化完成后读取脚本⽂件，Zend引擎对脚本⽂件进行词法分析，语法分析。然后编译成opcode执行。 如过安装了apc之类的opcode缓存， 编译环节可能会被跳过⽽直接从缓存中读取opcode执行。 词法分析PHP的词法分析器是通过 lex 生成的， 词法规则⽂件在$PHP_SRC/Zend/zend_language_scanner.l， 这一阶段lex会会将源代码按照词法规则切分一个一个的标记(token)。PHP中提供了一个函数 token_get_all()， 该函数接收一个字符串参数， 返回一个按照词法规则切分好的数组。 PHP 变量类型及存储结构变量的值存储到以下所⽰ zval 结构体中。变量的 key 和指向 zval 的指针存储在符号表里。 zval 结构体定义在Zend/zend.h⽂件，其结构如下： 123456789typedef struct _zval_struct zval;struct _zval_struct &#123; /* Variable information */ zvalue_value value; /* value */ zend_uint refcount__gc; zend_uchar type; /* active type */ zend_uchar is_ref__gc;&#125;; 变量的值存储在 zvalue_value 联合体中12345678910typedef union _zvalue_value &#123; long lval; /* long value */ double dval; /* double value */ struct &#123; char *val; int len; &#125; str; HashTable *ht; /* hash table value */ zend_object_value obj;&#125; zvalue_value; 使用联合体⽽不是用结构体是出于空间利用率的考虑，因为一个变量同时只能属于一种类型。 如果使用结构体的话将会不必要的浪费空间，⽽PHP中的所有逻辑都围绕变量来进行的，这样的话， 内存浪费将是⼗分⼤的。这种做法成本⼩但收益⾮常⼤。 PHP 哈希表实现PHP内核中的哈希表是⼗分重要的数据结构，PHP的⼤部分的语⾔特性都是基于哈希表实现的，例如：变量的作用域、函数表、类的属性、⽅法等，Zend引擎内部的很多数据都是保存在哈希表中的。 PHP中的哈希表是使用拉链法来解决冲突的，具体点讲就是使用链表来存储哈希到同一个槽位的数据， Zend为了保存数据之间的关系使用了双向列表来链接元素。 PHP 哈希表实现中的数据结构，PHP使用两个数据结构来实现哈希表，HashTable结构体用于保存整个哈希表需要的基本信息，⽽ Bucket 结构体用于保存具体的数据内容 HashTable 结构 1234567891011121314typedef struct _hashtable &#123; uint nTableSize; //表长度，并非元素个数 uint nTableMask;//表的掩码，始终等于nTableSize-1 uint nNumOfElements;//存储的元素个数 ulong nNextFreeElement;//指向下一个空的元素位置 Bucket *pInternalPointer;//foreach循环时，用来记录当前遍历到的元素位置 Bucket *pListHead; Bucket *pListTail; Bucket **arBuckets;//存储的元素数组 dtor_func_t pDestructor;//析构函数 zend_bool persistent;//是否持久保存。从这可以发现，PHP数组是可以实现持久保存在内存中的，而无需每次请求都重新加载。 unsigned char nApplyCount; zend_bool bApplyProtection;&#125; HashTable; Bucket 结构 1234567891011typedef struct bucket &#123; ulong h; //数组索引 uint nKeyLength; //字符串索引的长度 void *pData; //实际数据的存储地址 void *pDataPtr; //引入的数据存储地址 struct bucket *pListNext; struct bucket *pListLast; struct bucket *pNext; //双向链表的下一个元素的地址 struct bucket *pLast;//双向链表的下一个元素地址 char arKey[1]; /* Must be last element */&#125; Bucket; PHP中初始化一个空数组或不足8个元素的数组，都会被创建8个长度的 HashTable。同样创建100个元素的数组，也会被分配128长度的HashTable。依次类推。 PHP 哈希算法PHP内核哈希表的散列函数很简单，直接使用 （HashTable-&gt;nTableSize &amp; HashTable-&gt;nTableMask）的结果作为散列函数的实现。这样做的目的可能也是为了降低Hash算法的复杂度和提高性能。 PHP 对字符串索引处理方式与数字索引相比，只是多了一步将字符串转换为整型。用到的算法是time33，就是对字符串的每个字符转换为ASCII码乘上33并且相加得到的结果。 PHP7 中 HashTable 优化blog PHP7 变量存储的优化内存管理机制PHP的内存管理可以被看作是分层（hierarchical）的。 它分为三层：存储层（storage）、堆层（heap）和接⼝层（emalloc/efree）。 存储层通过 malloc()、mmap() 等函数向系统真正的申请内存，并通过 free() 函数释放所申请的内存。 存储层通常申请的内存块都⽐较⼤，这⾥申请的内存⼤并不是指storage层结构所需要的内存⼤， 只是堆层通过调用存储层的分配⽅法时，其以⼤块⼤块的⽅式申请的内存，存储层的作用是将内存分配的⽅式对堆层透明化。 初始化内存管理顺序： 初始化 storage 层的分配方案 初始化 heap 堆层 PHP中的内存管理主要⼯作就是维护三个列表：⼩块内存列表（free_buckets）、 ⼤块内存列表（large_free_buckets）和剩余内存列表（rest_buckets）从内存分配的过程中可以看出，内存块查找判断顺序依次是⼩块内存列表，⼤块内存列表，剩余内存列表。ZendMM向系统进行的内存申请，并不是有需要时向系统即时申请， ⽽是由ZendMM的最底层（heap层）先向系统申请一⼤块的内存，通过对上⾯三种列表的填充， 建立一个类似于内存池的管理机制。 在程序运行需要使用内存的时候，ZendMM会在内存池中分配相应的内存供使用。 这样做的好处是避免了PHP向系统频繁的内存申请操作 垃圾回收引用计数、引用计数的问题。如何解决。","categories":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/categories/PHP/"}],"tags":[{"name":"php","slug":"php","permalink":"http://phachon.github.io/tags/php/"}]},{"title":"火狐浏览器下刷新不清除表单问题","slug":"html/firefox-input","date":"2016-12-29T16:00:00.000Z","updated":"2022-07-11T01:59:03.321Z","comments":true,"path":"html/firefox-input.html","link":"","permalink":"http://phachon.github.io/html/firefox-input.html","excerpt":"问题js 控制表单重新刷新 12location.href = url;location.reload(); 测试时发现谷歌，360均正常，但是在火狐浏览器，刷新完之后，表单的数据还在，并没有清除，刚开始以为是浏览器的设置问题。查找资料后找到一些解决办法","text":"问题js 控制表单重新刷新 12location.href = url;location.reload(); 测试时发现谷歌，360均正常，但是在火狐浏览器，刷新完之后，表单的数据还在，并没有清除，刚开始以为是浏览器的设置问题。查找资料后找到一些解决办法 解决form 表单加参数 1&lt;form method=&quot;post&quot; autocomplete=&quot;off&quot; action=&quot;&quot;&gt; 1autocomplete=&quot;off&quot; 加了之后火狐刷新不再携带原始数据,清空表单 ok，测试通过，完美解决","categories":[{"name":"Html","slug":"Html","permalink":"http://phachon.github.io/categories/Html/"}],"tags":[{"name":"Html","slug":"Html","permalink":"http://phachon.github.io/tags/Html/"},{"name":"FireFox","slug":"FireFox","permalink":"http://phachon.github.io/tags/FireFox/"},{"name":"javascript","slug":"javascript","permalink":"http://phachon.github.io/tags/javascript/"}]},{"title":"一个基于 node.js 搭建的web聊天系统","slug":"opensource/phaChat","date":"2016-10-10T16:00:00.000Z","updated":"2022-07-11T01:59:03.324Z","comments":true,"path":"opensource/phaChat.html","link":"","permalink":"http://phachon.github.io/opensource/phaChat.html","excerpt":"简介 一个简单的 web 聊天室, 采用 node.js 编写，基于 express + mysql + socket 实现的在线多人web 聊天系统，包括用户的登陆注册，用户的个人信息修改,目的是为了更加深入学习了解 node.js 和 websocket 技术，给初学者一个练习的小项目。有兴趣的同学可以继续完善（用户的头像上传，创建聊天群，消息保存等）","text":"简介 一个简单的 web 聊天室, 采用 node.js 编写，基于 express + mysql + socket 实现的在线多人web 聊天系统，包括用户的登陆注册，用户的个人信息修改,目的是为了更加深入学习了解 node.js 和 websocket 技术，给初学者一个练习的小项目。有兴趣的同学可以继续完善（用户的头像上传，创建聊天群，消息保存等） Install 安装 环境npm 3.node v6.express 4.3.mysql 5.5.redis 2.8.* 使用 进入根目录，phaChat npm install npm start //开启聊天室客户端 node server //开启聊天室服务端 浏览器输入 http://127.0.0.1:3000/chat/index, 界面效果注册 登录 聊天室 继续扩展 创建聊天室 用户修改头像 发送表情 model层优化 项目地址https://github.com/phachon/phaChat","categories":[{"name":"OpenSource","slug":"OpenSource","permalink":"http://phachon.github.io/categories/OpenSource/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/tags/Mysql/"},{"name":"Node","slug":"Node","permalink":"http://phachon.github.io/tags/Node/"},{"name":"Express","slug":"Express","permalink":"http://phachon.github.io/tags/Express/"},{"name":"WebSocket","slug":"WebSocket","permalink":"http://phachon.github.io/tags/WebSocket/"}]},{"title":"ELK 实时日志分析系统平台的学习与使用","slug":"elk/elk-install","date":"2016-09-21T16:00:00.000Z","updated":"2022-07-11T01:59:03.319Z","comments":true,"path":"elk/elk-install.html","link":"","permalink":"http://phachon.github.io/elk/elk-install.html","excerpt":"简介工作工程中，不论是开发还是运维，都会遇到各种各样的日志，主要包括系统日志、应用程序日志和安全日志，对于开发人员来说，查看日志，可以实时查看程序的运行错误，以及性能分析，通常，一个大中型的应用程序会被部署到多台服务器，那日志文件也会分散到不同的机器上，这样查看日志难道要一台一台去查看？显然是太麻烦了，开源的日志分析系统 ELK 完美的解决了这个问题。ELK 并不是一个独立的系统，她是由 ElasticSearch、Logstash、Kibana 三个开源的工具组成。 ElasticSearchElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。 LogstashLogstash 是一个开源的日志分析、收集工具，并将日志存储以供以后使用。 KibanaKibana 是一个为 Logstash 和 ElasticSearch 提供的日志分析的 Web 接口。可使用它对日志进行高效的搜索、可视化、分析等各种操作。","text":"简介工作工程中，不论是开发还是运维，都会遇到各种各样的日志，主要包括系统日志、应用程序日志和安全日志，对于开发人员来说，查看日志，可以实时查看程序的运行错误，以及性能分析，通常，一个大中型的应用程序会被部署到多台服务器，那日志文件也会分散到不同的机器上，这样查看日志难道要一台一台去查看？显然是太麻烦了，开源的日志分析系统 ELK 完美的解决了这个问题。ELK 并不是一个独立的系统，她是由 ElasticSearch、Logstash、Kibana 三个开源的工具组成。 ElasticSearchElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。 LogstashLogstash 是一个开源的日志分析、收集工具，并将日志存储以供以后使用。 KibanaKibana 是一个为 Logstash 和 ElasticSearch 提供的日志分析的 Web 接口。可使用它对日志进行高效的搜索、可视化、分析等各种操作。 搭建方法基于一台主机的搭建，没有使用多台集群，logstah 收集日志后直接写入 elasticseach，可以用 redis 来作为日志队列 jdk 安装jdk 1.8 安装 elasticseach 安装下载地址：https://www.elastic.co/downloads，选择相应的版本 我这里的版本是 elasticsearch-2.4.0 解压目录:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[phachon@localhost elk]$ tar -zxf elasticsearch-2.4.0[phachon@localhost elasticsearch-2.4.0]$# 安装 head 插件[phachon@localhost elasticsearch-2.4.0]$./bin/plugin install mobz/elasticsearch-head[phachon@localhost elasticsearch-2.4.0]$ ls plugins/head编辑 elasticseach 的配置文件[phachon@localhost elasticsearch-2.4.0]$ vim config/elasticseach.yml13 # ---------------------------------- Cluster -----------------------------------14 #15 # Use a descriptive name for your cluster:16 #17 cluster.name: es_cluster #这里是你的el集群的名称18 #19 # ------------------------------------ Node ------------------------------------20 #21 # Use a descriptive name for the node:22 #23 node.name: node0 # elseach 集群中的节点24 #25 # Add custom attributes to the node:26 #27 # node.rack: r128 #29 # ----------------------------------- Paths ------------------------------------30 #31 # Path to directory where to store the data (separate multiple locations by comma):32 #33 path.data: /tmp/elasticseach/data #设置 data 目录34 #35 # Path to log files:36 #37 path.logs: /tmp/elasticseach/logs # 设置 logs 目录#39 # ----------------------------------- Memory -----------------------------------40 #41 # Lock the memory on startup:42 #43 # bootstrap.memory_lock: true44 #45 # Make sure that the `ES_HEAP_SIZE` environment variable is set to about half the memory46 # available on the system and that the owner of the process is allowed to use this limit.47 #48 # Elasticsearch performs poorly when the system is swapping the memory.49 #50 # ---------------------------------- Network -----------------------------------51 #52 # Set the bind address to a specific IP (IPv4 or IPv6):53 #54 # network.host: 192.168.0.155 network.host: 192.168.30.128 # 这里配置本机的 ip 地址,这个是我的虚拟机的 ip 56 #57 # Set a custom port for HTTP:58 #59 http.port: 9200 # 默认的端口 其他配置可先不设置启动 elstaicseach 1[root@localhost elasticsearch-2.4.0]$ ./bin/elasticsearch 注意，这里肯定会报错： 1234567[root@localhost elasticsearch-2.4.0]# ./bin/elasticsearchException in thread &quot;main&quot; java.lang.RuntimeException: don&#x27;t run elasticsearch as root.at org.elasticsearch.bootstrap.Bootstrap.initializeNatives(Bootstrap.java:94)at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:160)at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:286)at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)Refer to the log for complete error details. 之前在网上搜的教程这里都没有详细说明，导致花了很长时间卡在这里安装不成功。提示的原因已经说的很清楚了，不能以 root 权限来安装 elasticseach为 elsearch 添加专门的用户组和用户 123[root@localhost elasticsearch-2.4.0]# groupadd elsearch[root@localhost elasticsearch-2.4.0]# adduser -G elsearch elsearch[root@localhost elasticsearch-2.4.0]# passwd elsearch 123456 将 elasticseach 的安装目录设置为 elsearch 用户组和用户所有 1[root@localhost elk]# chown -R elsearch:elsearch elasticsearch-2.4.0/ 别忘了将 /tmp/elasticseach/data 和 /tmp/elasticseach/logs 目录也设置为 elsearch 用户所有,要不然会没有权限读写 1[root@localhost tmp]# chown -R elsearch:elsearch elasticseach/ 好了。终于设置完毕。切换到 elsearch 重新启动 123456789101112131415161718192021[elsearch@localhost elasticsearch-2.4.0]# ./bin/elasticsearch[2016-09-22 01:51:42,102][WARN ][bootstrap] unable to install syscall filter: seccomp unavailable: requires kernel 3.5+ with CONFIG_SECCOMP andCONFIG_SECCOMP_FILTER compiled in[2016-09-22 01:51:42,496][INFO ][node] [node0] version[2.4.0], pid[4205], build[ce9f0c7/2016-08-29T09:14:17Z][2016-09-22 01:51:42,496][INFO ][node] [node0] initializing ...[2016-09-22 01:51:43,266][INFO ][plugins] [node0] modules [reindex, lang-expression, lang-groovy], plugins [head], sites [head][2016-09-22 01:51:43,290][INFO ][env] [node0] using [1] data paths, mounts [[/ (/dev/sda5)]], net usable_space [8.4gb], net total_space [14.6gb], spins?[possibly], types [ext4][2016-09-22 01:51:43,290][INFO ][env] [node0] heap size [998.4mb], compressed ordinary object pointers [unknown][2016-09-22 01:51:43,290][WARN ][env] [node0] max file descriptors [4096] for elasticsearch process likely too low, consider increasing to at least[65536][2016-09-22 01:51:45,697][INFO ][node] [node0] initialized[2016-09-22 01:51:45,697][INFO ][node] [node0] starting ...[2016-09-22 01:51:45,832][INFO ][transport] [node0] publish_address &#123;192.168.30.128:9300&#125;, bound_addresses &#123;192.168.30.128:9300&#125;[2016-09-22 01:51:45,839][INFO ][discovery] [node0] es_cluster/kJMDfFMwQXGrigfknNs-_g[2016-09-22 01:51:49,039][INFO ][cluster.service] [node0] new_master &#123;node0&#125;&#123;kJMDfFMwQXGrigfknNs-_g&#125;&#123;192.168.30.128&#125;&#123;192.168.30.128:9300&#125;, reason:zen-disco-join(elected_as_master, [0] joins received)[2016-09-22 01:51:49,109][INFO ][http] [node0] publish_address &#123;192.168.30.128:9200&#125;, bound_addresses &#123;192.168.30.128:9200&#125;[2016-09-22 01:51:49,109][INFO ][node] [node0] started[2016-09-22 01:51:49,232][INFO ][gateway] [node0] recovered [2] indices into cluster_state 启动成功在本机浏览器访问 http://192.168.30.128:9200 说明搜索引擎 API 返回正常。注意要在服务器将 9200 端口打开，否则访问失败。 打开我们刚刚安装的 head 插件http://192.168.30.128:9200/_plugin/head/ 如果是第一次搭建好，里面是没有数据的，node0 节点也没有集群信息，这里我搭建完成后已经添加了数据。所以显示的有信息 Logstash安装下载地址：https://www.elastic.co/downloads，选择相应的版本 我这里的版本是 logstash-2.4.0.tar.gz解压目录： 12[root@localhost elk]# tar -zxvf logstash-2.4.0[root@localhost elk]# cd logstash-2.4.0 编辑 logstash 配置文件： 12[root@localhost logstash-2.4.0]# mkdir config[root@localhost logstash-2.4.0]# vim config/logstash.conf 这里因为为了简单来显示一下数据，我这里将 apache 的日志作为数据源，也就是 logstash 的 input，直接输出到 elstaticseach 里，即 ouput 1234567891011121314151617181920input &#123; # For detail config for log4j as input, # See: https://www.elastic.co/guide/en/logstash/ file &#123; type =&gt; &quot;apache-log&quot; # log 名 path =&gt; &quot;/etc/httpd/logs/access_log&quot; # log 路径 &#125;&#125;filter &#123; #Only matched data are send to output. 这里主要是用来过滤数据&#125;output &#123; # For detail config for elasticsearch as output, # See: https://www.elastic.co/guide/en/logstash/current elasticsearch &#123; action =&gt; &quot;index&quot; #The operation on ES hosts =&gt; &quot;192.168.30.128:9200&quot; #ElasticSearch host, can be array. # elasticseach 的 host index =&gt; &quot;apachelog&quot; #The index to write data to. &#125;&#125; 使用命令来检测配置文件是否正确 12[root@localhost logstash-2.4.0]# ./bin/logstash -f config/logstash.conf --configtestConfiguration OK 启动 logstash 来收集日志 123[root@localhost logstash-2.4.0]# ./bin/logstash -f config/logstash.confSettings: Default pipeline workers: 4Pipeline main started 好了，logstash 可以开始收集日志了，当日志文件有变化时，会动态的写入到 elastaticseach 中，先让我们来产生一些日志吧。刷新 http://192.168.30.128/ 一直刷新，apache 产生访问日志。ok，打开我们的 elasticseach 的 web 页面 http://192.168.30.128:9200/_plugin/head/ 这里就出现了我们刚刚配置的 apachelog 的日志，点开数据浏览 这里很详细的列出了我们的日志文件，还有字段，左边可进行相应的搜索，右边点击可查看具体的日志信息。至此我们已经能够收集日志，并进行搜索，接下来我们来将搜索数据可视化成图表 Kibana 的安装下载：https://www.elastic.co/downloads 对应自己的版本, 这里我的版本是：kibana-4.6.1-linux-x86 解压目录： 12[root@localhost elk]# tar -zxvf kibana-4.6.1-linux-x86[root@localhost elk]# cd kibana-4.6.1-linux-x86 编辑配置文件： 12345678910111213141516171819202122232425 [root@localhost kibana-4.6.1-linux-x86]# vim config/kibana.yml # Kibana is served by a back end server. This controls which port to use. server.port: 5601 # kibaba 服务 port # The host to bind the server to. server.host: &quot;192.168.30.128&quot; # 你的kibaba 的服务host # If you are running kibana behind a proxy, and want to mount it at a path, # specify that path here. The basePath can&#x27;t end in a slash. # server.basePath: &quot;&quot; # The maximum payload size in bytes on incoming server requests. # server.maxPayloadBytes: 1048576 # The Elasticsearch instance to use for all your queries. elasticsearch.url: &quot;http://192.168.30.128:9200&quot; # elastaticseach 的host # preserve_elasticsearch_host true will send the hostname specified in `elasticsearch`. If you set it to false, # then the host you use to connect to *this* Kibana instance will be sent. # elasticsearch.preserveHost: true# Kibana uses an index in Elasticsearch to store saved searches, visualizations# and dashboards. It will create a new index if it doesn&#x27;t already exist.kibana.index: &quot;.kibana&quot; # kibana# The default application to load.# kibana.defaultAppId: &quot;discover&quot;# If your Elasticsearch is protected with basic auth, these are the user credentials# used by the Kibana server to perform maintenance on the kibana_index at startup. Your Kibana 配置比较简单配置完成后开始运行 1234567891011[root@localhost kibana-4.6.1-linux-x86]# ./bin/kibanalog [02:48:34.732] [info][status][plugin:kibana@1.0.0] Status changed from uninitialized to green - Readylog [02:48:34.771] [info][status][plugin:elasticsearch@1.0.0] Status changed from uninitialized to yellow - Waiting for Elasticsearchlog [02:48:34.803] [info][status][plugin:kbn_vislib_vis_types@1.0.0] Status changed from uninitialized to green - Readylog [02:48:34.823] [info][status][plugin:markdown_vis@1.0.0] Status changed from uninitialized to green - Readylog [02:48:34.827] [info][status][plugin:metric_vis@1.0.0] Status changed from uninitialized to green - Readylog [02:48:34.835] [info][status][plugin:elasticsearch@1.0.0] Status changed from yellow to green - Kibana index readylog [02:48:34.840] [info][status][plugin:spyModes@1.0.0] Status changed from uninitialized to green - Readylog [02:48:34.847] [info][status][plugin:statusPage@1.0.0] Status changed from uninitialized to green - Readylog [02:48:34.857] [info][status][plugin:table_vis@1.0.0] Status changed from uninitialized to green - Readylog [02:48:34.867] [info][listening] Server running at http://192.168.30.128:5601 在浏览器运行 http://192.168.30.128:5601 这里要先添加 index，在 输入框输入我们刚刚收集的 apachelog 作为 index 名称 点击 create 创建 右上角选择时间来显示我们的数据访问，下面是数据的访问量 中间的搜索框可输入搜索条件搜索，搜索完成后点击右上角的 save seach 保存搜索数据 点击 visualize 可以画出其他的数据分析图，比如饼状图 选择我们刚刚保存的 chrome 的文件来生成饼状图 因为数据没什么变化，所以只能全部是一样的。还是点击右上角的保存按钮，将饼状图保存为 test 添加到 面板中，点击 dashboard点击 + 号添加 选择 test 来显示到面板，效果如下 这样简单的 ELK 系统就搭建起来了，当然，正真的使用环境中，我们会使用集群搭建。利用 redis 来处理日志队列。 marvel 插件Marvel是Elasticsearch的管理和监控工具，在开发环境下免费使用。拥有更好的数据图表界面。 首先在 elastaticsearch 下安装 marvel-agent 插件 12[elsearch@localhost elasticsearch-2.4.0]$ ./bin/plugin install license[elsearch@localhost elasticsearch-2.4.0]$ ./plugin install marvel-agent 这里注意，必须先执行 license 安装，再执行 marvel-agent 安装，安装完成后重启 elastaticseach接下来 kibana 来安装 marvel 插件 12[root@localhost kibana-4.6.1-linux-x86]# cd bin[root@localhost bin]# ./kibana plugin --install elasticsearch/marvel/latest 安装完成后重启 kibana，选择 marvel 插件 是不是感觉有点高大上。。。 好了 ELK 的基本搭建就算是完成了，接下来我们考虑如何集群来使用这个系统。 欢迎指正， Thanks….","categories":[{"name":"ELK","slug":"ELK","permalink":"http://phachon.github.io/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://phachon.github.io/tags/ELK/"},{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://phachon.github.io/tags/ElasticSearch/"},{"name":"LogStash","slug":"LogStash","permalink":"http://phachon.github.io/tags/LogStash/"},{"name":"Kibana","slug":"Kibana","permalink":"http://phachon.github.io/tags/Kibana/"},{"name":"Marvel","slug":"Marvel","permalink":"http://phachon.github.io/tags/Marvel/"},{"name":"Log","slug":"Log","permalink":"http://phachon.github.io/tags/Log/"},{"name":"Linux","slug":"Linux","permalink":"http://phachon.github.io/tags/Linux/"},{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/tags/Redis/"}]},{"title":"点直播流媒体传输协议之 —— HLS（HTTP Live Streaming）","slug":"live/hls","date":"2016-09-12T16:00:00.000Z","updated":"2022-07-11T01:59:03.322Z","comments":true,"path":"live/hls.html","link":"","permalink":"http://phachon.github.io/live/hls.html","excerpt":"简介在最近一年的工作中接触比较多的是视频点播和直播，也了解到了一些点直播的后端技术，这段时间希望将了解到的一些技术总结下来，这篇文章主要介绍流媒体协议 HLS","text":"简介在最近一年的工作中接触比较多的是视频点播和直播，也了解到了一些点直播的后端技术，这段时间希望将了解到的一些技术总结下来，这篇文章主要介绍流媒体协议 HLS 流媒体协议常用的流媒体协议主要有 HTTP 渐进下载和基于 RTSP/RTP 的实时流媒体协议，这两种协议是完全不同的实现方式。主要区别如下： 一种是分段渐近下载，一种是基于实时流来实现播放 协议不同，HTTP 协议的渐近下载意味着你可以在一台普通的 HTTP 的应用服务器上就可以直接提供点播和直播服务 延迟有差异，HTTP 渐近下载的方式的延迟理论上会略高于实时流媒体协议的播放 渐近下载会生成索引文件，所以需要考虑存储，对 I/O 要求较高 HLS简介HLS （HTTP Live Streaming）是苹果公司实现的基于 HTTP 的流媒体协议，可以实现流媒体的点播和直播播放。当然，起初是只支持苹果的设备，目前大多数的移动设备也都实现了该功能。HTML5 直接支持该协议。 实现原理HLS 点播是常见的分段 HTTP 点播，就是将视频流分成不同的片段，客户端不断的去下载该片段，由于片段之间的分段间隔时间非常短，所以看起来是一条完整的播放流，实现的重点是对于媒体文件的分割。同时，HLS 还支持多码率的切换，客户端可以选择从许多不同的备用源中以不同的速率下载同样的资源，允许流媒体会话适应不同的数据速率。多清晰度就是这样实现的。为了播放媒体流，客户端首先需要获得播放列表文件，也就是根据 HLS 生成的片段列表，该列表中包含每个流媒体的文件，客户端以类似轮询的方式不断重复加载播放列表文件并将片段追加实现流媒体的播放。播放列表文件就是通常我们所说的 m3u8 文件，是以后缀 .m3u8 Content-Type是”application/vnd.apple.mpegurl” 的文件。 m3u8 介绍与分析m3u8 文件本质说其实是采用了编码是 UTF-8 的 m3u 文件。它只是一个纯索引文件，一个文件片段的列表，客户单打开它并不是播放它，而是根据它里面的文件片段找到视频文件的网路地址进行播放 这里抓包抓了一个 m3u8 文件打开看一下究竟是什么： 123456#EXTM3U#EXT-X-VIDEO-INF:VIDEO=559ac1317682fa1fcdc67ed2774e4e1a980e0c264cefceb5c.....#EXT-X-STREAM-INF:PROGRAM-ID=1,BANDWIDTH=245760https://*******.com/video/cif/hNAQ0_jbip4j-0o_BhcdqMwyQxwtwbo1k3vVZhtjbcQ.m3u8#EXT-X-STREAM-INF:PROGRAM-ID=1,BANDWIDTH=491520https://******.com/video/sd/hNAQ0_jbip4j-0o_BhcdqMwyQxwtwbo1k3vVZhtjbcQ.m3u8 分析该 m3u8 文件：123456789#EXTM3U：扩展标记 ，意思是我是 m3u 文件#EXT-X-VIDEO-INF:VIDEO ：这个应该是自己定义的一个标签，指名是视频文件，后面可能跟的是视频标题之类的#EXT-X-STREAM-INF指定一个包含多媒体信息的 media URI 作为PlayList，一般做M3U8的嵌套使用，它只对紧跟后面的URI有效，#EXT-X-STREAM-INF:有以下属性：BANDWIDTH：带宽，491520PROGRAM-ID：该值是一个十进制整数，惟一地标识一个在PlayList文件范围内的特定的描述。一个PlayList 文件中可能包含多个有相同ID的此tag。CODECS：不是必须的。RESOLUTION：分辨率。AUDIO：这个值必须和AUDIO类别的“EXT-X-MEDIA”标签中“GROUP-ID”属性值相匹配。 这里 PlayList 的地址我们发现还是个 m3u8 文件 12https://*******.com/video/cif/hNAQ0_jbip4j-0o_BhcdqMwyQxwtwbo1k3vVZhtjbcQ.m3u8https://******.com/video/sd/hNAQ0_jbip4j-0o_BhcdqMwyQxwtwbo1k3vVZhtjbcQ.m3u8 可以观察发现，这其实是 cif 和 sd 两种不同清晰度的 m3u8 文件，客户端根据网络或者选项去选择不同的清晰度的 m3u8 文件。上面的 m3u8 文件为一级 m3u8 文件，这两个 m3u8 就称为二级 m3u8 文件，那么我们就顺着二级 m3u8 文件继续查看，将其中一个下载到本地打开分析： 12345678910111213141516#EXTM3U#EXT-X-VERSION:3#EXT-X-TARGETDURATION:11#EXTINF:12.400,http://*************/**/M00/00/BB/Cn1GQlfWRFaACQaQAAvsEEMIWI42131.ts#EXTINF:10.000,http://*************/**/M00/00/BB/Cn1GQlfWRFaAJO1mAAaTMDz8P4E9292.ts#EXTINF:10.000,http://*************/**/M00/00/BB/Cn1GQlfWRFaAZ2fyAAVQEM22iWA2544.ts#EXTINF:11.120,http://*************/**/M00/00/BB/Cn1GQlfWRFaAIfwHAAirSMgfpx03176.ts#EXTINF:17.240,http://*************/**/M00/00/BB/Cn1GQlfWRFaAaiz6AAn0SHY1csA7539.ts#EXTINF:3.720,http://*************/**/M00/00/BB/Cn1GQlfWRFaARLJ2AAGYUIIpGKA7707.ts#EXT-X-ENDLIST 12345#EXT-X-VERSION:3 : 版本#EXT-X-TARGETDURATION: 11指定最大的媒体段时间长（秒）。所以#EXTINF中指定的时间长度必须小于或是等于这个最大值。这个tag在整个PlayList文件中只能出现一 次（在嵌套的情况下，一般有真正ts url 的m3u8才会出现该tag）#EXTINF: duration 指定每个媒体段(ts)的持续时间（秒），仅对其后面的URI有效，title是下载资源的url#EXT-X-ENDLIST 结束列表 这里我们看到了真正播放的流片段，ts 片，客户端拿到的就是这个 ts 片，然后不断下载请求到该片段并连续播放。 有些人可能要问了，那 ts 文件又到底是个什么东西呢，那就下载来看看，拿着其中的一个 ts 文件浏览器打开保存到本地： 发现保存到本地的文件就可以直接打开，其实就是真正的流媒体文件，但是这个文件只是片段，大概只有 10s 的时间。 HLS播放实现时序图123456title:流媒体播放实现时序图客户端-&gt;服务端play接口:请求服务端play接口-&gt;客户端:返回一级 m3u8地址客户端-&gt;m3u8文件服务器:获取一级m3u8文件客户端-&gt;m3u8文件服务器:获取二级m3u8文件客户端-&gt;ts文件服务器:不断获取 ts 流媒体文件 HLS 直播HLS 直播原理上还是按点播的方式实现的，通过 http 协议传输，生成 ts 索引文件以及 m3u8 索引文件。直播的复杂在于先要采集视频源和音频源的数据，然后再进行 H264 编码和音频 ACC 编码，并封装成 ts 包，其中还要考虑 ts 的分段生成策略。 下一篇我会介绍一篇关于 rtmp 协议的文章。 欢迎指正，Thanks…","categories":[{"name":"Live","slug":"Live","permalink":"http://phachon.github.io/categories/Live/"}],"tags":[{"name":"HLS","slug":"HLS","permalink":"http://phachon.github.io/tags/HLS/"},{"name":"TS","slug":"TS","permalink":"http://phachon.github.io/tags/TS/"},{"name":"M3U8","slug":"M3U8","permalink":"http://phachon.github.io/tags/M3U8/"}]},{"title":"You-get 的安装与使用","slug":"install/you-get-install","date":"2016-09-11T16:00:00.000Z","updated":"2022-07-11T01:59:03.321Z","comments":true,"path":"install/you-get-install.html","link":"","permalink":"http://phachon.github.io/install/you-get-install.html","excerpt":"You-get 介绍You-Get 是一款命令行工具，用来下载网页中的视频、音频、图片，支持众多网站，包含 41 家国内主流视频、音乐网站，如 网易云音乐、AB 站、百度贴吧、斗鱼、熊猫、爱奇艺、凤凰视频、酷狗音乐、乐视、荔枝FM、秒拍、腾讯视频、优酷土豆、央视网、芒果TV 等等，只需一个命令就能直接下载视频、音频以及图片回来，并且可以自动合并视频。而对于有弹幕的网站，比如 B 站，还可以将弹幕下载回来。本篇文章介绍 you-get 的安装","text":"You-get 介绍You-Get 是一款命令行工具，用来下载网页中的视频、音频、图片，支持众多网站，包含 41 家国内主流视频、音乐网站，如 网易云音乐、AB 站、百度贴吧、斗鱼、熊猫、爱奇艺、凤凰视频、酷狗音乐、乐视、荔枝FM、秒拍、腾讯视频、优酷土豆、央视网、芒果TV 等等，只需一个命令就能直接下载视频、音频以及图片回来，并且可以自动合并视频。而对于有弹幕的网站，比如 B 站，还可以将弹幕下载回来。本篇文章介绍 you-get 的安装 Ubuntu安装官网地址：https://you-get.org/github地址：https://github.com/soimort/you-get/中文说明：https://github.com/soimort/you-get/wiki/%E4%B8%AD%E6%96%87%E8%AF%B4%E6%98%8E安装准备： python3安装方法： 安装 pip3 12sudo apt-get install python3-pip #安装 you-getsudo pip3 install you-get 下载安装 1234sudo wget https://github.com/soimort/you-get/releases/download/v0.4.523/you-get-0.4.523.tar.gzsudo tar -zxvf you-get-0.4.523.tar.gzcd you-getmake install 更新方法: pip3 1pip3 install --upgrade you-get 普通更新 1you-get https://github.com/soimort/you-get/archive/master.zip Windows 安装 安装 Python3 安装比较简单，这里不再说明 安装 pip 下载地址:https://pypi.python.org/pypi/pip#downloads选择 pip-8.1.2.tar.gz (md5, pgp) 下载解压到一个目录下，打开 CMD 命令行，进入该目录执行: python3 setup.py install自动安装 安装完成后，注意一下 pip 安装的路径 我这里的路径是 D:\\Program Files(86)\\python3\\Scripts将pip 的安装路径添加到环境变量中 path 安装 you-get 1pip3 install you-get OK ,Windows 下的 you-get 安装成功.","categories":[{"name":"Install","slug":"Install","permalink":"http://phachon.github.io/categories/Install/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"http://phachon.github.io/tags/Windows/"},{"name":"You-get","slug":"You-get","permalink":"http://phachon.github.io/tags/You-get/"},{"name":"Python3","slug":"Python3","permalink":"http://phachon.github.io/tags/Python3/"}]},{"title":"Interview","slug":"summary/interview","date":"2016-09-08T16:00:00.000Z","updated":"2022-07-11T01:59:03.326Z","comments":true,"path":"summary/interview.html","link":"","permalink":"http://phachon.github.io/summary/interview.html","excerpt":"","text":"括号匹配问题 1000w 个 URL，只有 1M 的内存怎么排序 写出 10 个 array 相关的方法 写出 5 个魔术方法 __autoload 魔术方法的使用 PHP 的垃圾回收机制 redis 的持久化方法及实现 redis 的主从同步的实现 10w 的库存，4wqps 的秒杀实现 golang 的垃圾回收 进程线程协程","categories":[{"name":"Summary","slug":"Summary","permalink":"http://phachon.github.io/categories/Summary/"}],"tags":[]},{"title":"Sphinx 在 Linux 下的安装与基本配置","slug":"sphinx/sphinx-install","date":"2016-09-05T16:00:00.000Z","updated":"2022-07-11T01:59:03.326Z","comments":true,"path":"sphinx/sphinx-install.html","link":"","permalink":"http://phachon.github.io/sphinx/sphinx-install.html","excerpt":"下载Sphinx 官网：http://sphinxsearch.com/wget http://sphinxsearch.com/files/sphinx-2.2.10-release.tar.gz 安装解压压缩包12tar zxvf sphinx-2.2.10-release.tar.gzcd sphinx-2.2.10-release 找到 mysql 的安装目录，我的是在 /usr/bin/mysql 执行 /usr/lcoal/sphinx 为 sphinx 的安装目录。 123sudo ./configure --prefix=/usr/local/sphinx --with-mysql=/usr/local/mysqlmake make install 不出问题的话应该已经安装成功了","text":"下载Sphinx 官网：http://sphinxsearch.com/wget http://sphinxsearch.com/files/sphinx-2.2.10-release.tar.gz 安装解压压缩包12tar zxvf sphinx-2.2.10-release.tar.gzcd sphinx-2.2.10-release 找到 mysql 的安装目录，我的是在 /usr/bin/mysql 执行 /usr/lcoal/sphinx 为 sphinx 的安装目录。 123sudo ./configure --prefix=/usr/local/sphinx --with-mysql=/usr/local/mysqlmake make install 不出问题的话应该已经安装成功了 其他参数的配置 12345--with-mysql-includes=/usr/local/mysql/include/mysql/--with-mysql-libs=/usr/local/mysql/lib/mysql/--with-mmseg=/usr/local/mmseg/--with-mmseg-includes=/usr/local/mmseg/include/mmseg/--with-mmseg-libs=/usr/local/mmseg/lib/ 配置找到 sphinx 的安装目录 /usr/local/sphinx/etc .复制一份 sphinx.conf.dist 为 test.conf打开文件对照注释编写配置文件。由于都是英文，这里将经常用到的一些配置做解释如下： 数据源配置解析： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374source &#123; # 数据源类型 mysql，pgsql，mssql，xmlpipe，xmlpipe2，odbc type = mysql # -------------------------连接sql数据源的一些配置--------------------------- sql_host = localhost sql_user = root sql_pass = 123456 sql_db = test sql_port = 3306 # 使用 unix sock连接可以使用这个 #sql_sock = /tmp/mysql.sock # --------------------------mysql 相关配置---------------------------------------- # mysql 与 sphinx 之间的交互，0/32/2048/32768 无/使用压缩协议/握手后切换到ssl/Mysql 4.1版本身份认证。 mysql_connect_flags = 32 ## 当mysql_connect_flags设置为2048（ssl）的时候，下面几个就代表ssl连接所需要使用的几个参数。 # mysql_ssl_cert = /etc/ssl/client-cert.pem # mysql_ssl_key = /etc/ssl/client-key.pem # mysql_ssl_ca = /etc/ssl/cacert.pem #---------------------------mssql 相关配置---------------------------------------- # 是否使用 windows 登陆 # mssql_winauth = 1 # 使用unicode还是单字节数据 # mssql_unicode = 1 #----------------------------odbc 相关配置------------------------------------------- odbc_dsn = DBQ=C:\\data;DefaultDir=C:\\data;Driver=&#123;Microsoft Text Driver (*.txt; *.csv)&#125;; #-----------------------------sql 相关配置-------------------------------------------- # sql某一列的缓冲大小，一般是针对字符串来说的 # sql_column_buffers = content=12M, comments=1M # 索引的 sql 执行前需要执行的操作，比如设置字符串为 utf8 sql_query_pre = SET NAMES utf8 # 索引的 sql 执行语句 sql_query = SELECT id, name, age FROM test # 联合查询 # sql_joined_field是增加一个字段，这个字段是从其他表查询中查询出来的。 # 如果是query，则返回id和查询字段，如果是payload-query，则返回id，查询字段和权重 # 查询需要按照id进行升序排列 # sql_joined_field = tags from query; SELECT docid, CONCAT(&#x27;tag&#x27;,tagid) FROM tags ORDER BY docid ASC # sql_joined_field = wtags from payload-query; SELECT docid, tag, tagweight FROM tags ORDER BY docid ASC #----------------------------字段属性的配置（用于过滤和排序）---------------------------------------- # uint无符号整型属性 sql_attr_uint = id # 布尔值属性 # sql_attr_bool = is_deleted # 长整型属性(有负数用 bigint) # sql_attr_bigint = my_bigint_id # 时间戳属性，经常被用于做排序 sql_attr_timestamp = date_added # 字符串排序属性。一般我们按照字符串排序的话，我们会将这个字符串存下来进入到索引中，然后在查询的时候比较索引中得字符大小进行排序。 # 但是这个时候索引就会很大，于是我们就想到了一个方法，我们在建立索引的时候，先将字符串值从数据库中取出，暂存，排序。 # 然后给排序后的数组分配一个序号，然后在建立索引的时候，就将这个序号存入到索引中去。这样在查询的时候也就能完成字符串排序的操作。 # 这，就是这个字段的意义。 # sql_attr_str2ordinal = author_name # 浮点数属性 # sql_attr_float = lat_radians # sql_attr_float = long_radians # 字符串属性 # sql_attr_string = stitle # 文档词汇数记录属性。比如下面就是在索引建立的时候增加一个词汇数的字段 # sql_attr_str2wordcount = stitle&#125; # sphinx 的 source 有继承属性，也就是说共有的部分可以写在父级数据源中，比如数据库连接配置信息 source main_0: main&#123; sql_ranged_throttle = 100&#125; 索引配置解析： 12345678910111213141516index test1&#123; # 索引类型，包括有plain，distributed和rt。分别是普通索引/分布式索引/增量索引。默认是plain。 # type = plain # 索引数据源 source = src1 # 索引文件存放路径 path =/usr/local/sphinx/var/data/src1 # 字符集编码类型，可以为sbcs,utf-8 charset_type = utf-8 # 字符表和大小写转换规则 # &#x27;sbcs&#x27; default value is # charset_table = 0..9, A..Z-&gt;a..z, _, a..z, U+A8-&gt;U+B8, U+B8, U+C0..U+DF-&gt;U+E0..U+FF, U+E0..U+FF # &#x27;utf-8&#x27; default value is # charset_table = 0..9, A..Z-&gt;a..z, _, a..z, U+410..U+42F-&gt;U+430..U+44F, U+430..U+44F&#125; 搜索服务searchd 配置 12345678910111213141516171819202122232425262728293031323334353637searchd&#123; # 监听端口 listen = 9312 listen = 9307:mysql4 # 监听日志路径 log = /usr/local/sphinx/var/log/searchd.log # 查询日志路径 query_log = /usr/local/sphinx/var/log/query.log # 客户端读超时时间 read_timeout = 5 # 客户端持久时间 client_timeout = 300 #并行执行搜索数量 max_children = 0 #进程 pid 文件 pid_file = /usr/local/sphinx/var/log/searchd.pid #当进行索引轮换的时候，可能需要消耗大量的时间在轮换索引上。 # 启动了无缝轮转，就以消耗内存为代价减少轮转的时间 seamless_rotate = 1 # 索引预开启，强制重新打开所有索引文件 preopen_indexes = 1 # 索引轮换成功之后，是否删除以.old为扩展名的索引拷贝 unlink_old = 1 # 多值属性MVA更新的存储空间的内存共享池大小 mva_updates_pool = 1M #网络通讯时允许的最大的包的大小 max_packet_size = 8M # 每次查询允许设置的过滤器的最大个数 max_filters = 256 # 单个过滤器允许的值的最大个数 max_filter_values = 4096 # 每次批量查询的查询数限制 max_batch_queries = 32 # 多处理模式（MPM）。 可选项；可用值为none、fork、prefork，以及threads。 默认在Unix类系统为form，Windows系统为threads。 workers = form&#125; 开启sphinx生成索引1/usr/local/sphinx/bin/indexer --config /usr/local/sphinx/etc/test.conf --all 打开 sphinx 进程1/usr/local/sphinx/bin/searchd --config /usr/local/sphinx/etc/sphinx.conf 参考 http://www.cnblogs.com/yjf512/p/3598332.html","categories":[{"name":"Sphinx","slug":"Sphinx","permalink":"http://phachon.github.io/categories/Sphinx/"}],"tags":[{"name":"Sphinx","slug":"Sphinx","permalink":"http://phachon.github.io/tags/Sphinx/"}]},{"title":"Sphinx 在网站应用中的服务架构设计","slug":"sphinx/sphinx-web","date":"2016-09-05T16:00:00.000Z","updated":"2022-07-11T01:59:03.326Z","comments":true,"path":"sphinx/sphinx-web.html","link":"","permalink":"http://phachon.github.io/sphinx/sphinx-web.html","excerpt":"Sphinx 简单介绍 介绍Sphinx 是一个基于 SQL 的全文检索引擎，可以给 Mysql、PostgreSQL 做检索，提供比数据库更加专业的搜索功能。Sphinx 的搜索API接口支持 PHP,Python,Ruby,等。Sphinx 单一索引最大可包含1亿条记录，在1千万条记录情况下的查询速度为0.x秒（毫秒级）。Sphinx创建索引的速度为：创建100万条记录的索引只需 3～4分钟，创建1000万条记录的索引可以在50分钟内完成，而只包含最新10万条记录的增量索引，重建一次只需几十秒 主要特性 高速索引 高速搜索 支持分布式搜索 提供从Mysql 内部的插件式存储引擎上搜索 采用 UTF-8 字符集 支持 Windows/Linux/MacOX 使用场景如果数据库的数据量不是很多，百万级的数据，可以采用数据库索引来进行检索，但是对于上千万的数据量的话就用数据库直接检索的效率就会有所下降，特别对于采用分库分表的数据库设计，如果要检索非主键的字段的话，将会非常麻烦。比如用户表 user，用户量大的时候，我们一般会采用分表的方式来提高应用的访问性能。user_0 ~ user_63 ,总共 64 张表,user_id 作为 主键表结构如下。user_id name password ageint char(100) char(32) int如果知道 user_id = 65，那我们很容易找到用户的信息, 65 % 64 = 1，那就在 user_1 表中，采用 select from user_1 ….但是如果我想检索名字叫 “phachon” 的用户，这个就比较麻烦了，最笨的办法就是每一张表都去查找 select from user_* where name LIKE %phchon% ,这样要循环 64 次，再将数据合并起来，这样显然是不可行的，数据库的开销太大，造成应用程序的性能下降。 Sphinx 就可以帮我们解决上面所说的问题。当然，Sphinx 可以应用的场景很多，上面只是其中的一种。","text":"Sphinx 简单介绍 介绍Sphinx 是一个基于 SQL 的全文检索引擎，可以给 Mysql、PostgreSQL 做检索，提供比数据库更加专业的搜索功能。Sphinx 的搜索API接口支持 PHP,Python,Ruby,等。Sphinx 单一索引最大可包含1亿条记录，在1千万条记录情况下的查询速度为0.x秒（毫秒级）。Sphinx创建索引的速度为：创建100万条记录的索引只需 3～4分钟，创建1000万条记录的索引可以在50分钟内完成，而只包含最新10万条记录的增量索引，重建一次只需几十秒 主要特性 高速索引 高速搜索 支持分布式搜索 提供从Mysql 内部的插件式存储引擎上搜索 采用 UTF-8 字符集 支持 Windows/Linux/MacOX 使用场景如果数据库的数据量不是很多，百万级的数据，可以采用数据库索引来进行检索，但是对于上千万的数据量的话就用数据库直接检索的效率就会有所下降，特别对于采用分库分表的数据库设计，如果要检索非主键的字段的话，将会非常麻烦。比如用户表 user，用户量大的时候，我们一般会采用分表的方式来提高应用的访问性能。user_0 ~ user_63 ,总共 64 张表,user_id 作为 主键表结构如下。user_id name password ageint char(100) char(32) int如果知道 user_id = 65，那我们很容易找到用户的信息, 65 % 64 = 1，那就在 user_1 表中，采用 select from user_1 ….但是如果我想检索名字叫 “phachon” 的用户，这个就比较麻烦了，最笨的办法就是每一张表都去查找 select from user_* where name LIKE %phchon% ,这样要循环 64 次，再将数据合并起来，这样显然是不可行的，数据库的开销太大，造成应用程序的性能下降。 Sphinx 就可以帮我们解决上面所说的问题。当然，Sphinx 可以应用的场景很多，上面只是其中的一种。 Sphinx 在网站应用程序中的应用架构设计以下是最近在工作中使用 Sphinx 来进行后台数据检索的应用架构设计 web application 应用程序层 select 操作只用请求 Server Api 层的 select 接口；update/insert/delete 操作先操作数据库再请求 Server Api 的 update 更新接口。Server Api 层通过 Nginx + php 连接 Sphinx 客户端，主要提供了两个接口 select 查询接口和 update 更新接口。select 接口需要查询全量（main）索引和增量（delta）做索引的数据，取其数据的交集才是真正需要的数据。Sphinx 客户端建了两个索引，全量索引（main）和增量索引（delta），每天凌晨 1 点通过脚本进行定时任务重建索引，如果插入或者修改量很低的话，重建索引的频率可适当调整。应用层更新操作可通过消息队列来异步实现。DB 数据库层读库和写库及时同步保证数据的一致性。 Server Api 层连接 Sphinx 客户端的可使用 SphinxClinet 类或者 foolz/sphinxql-query-builder 类来实现。 Sphinx 配置Sphinx 在 Linux 下的安装可参考之前写的一篇文章《Sphinx 在Linux下的安装与基本配置》","categories":[{"name":"Sphinx","slug":"Sphinx","permalink":"http://phachon.github.io/categories/Sphinx/"}],"tags":[{"name":"Sphinx","slug":"Sphinx","permalink":"http://phachon.github.io/tags/Sphinx/"}]},{"title":"IO 模型简介","slug":"linux/io","date":"2016-09-04T16:00:00.000Z","updated":"2022-07-11T01:59:03.322Z","comments":true,"path":"linux/io.html","link":"","permalink":"http://phachon.github.io/linux/io.html","excerpt":"最近工作中接触到关于网络编程的一些东西，发现对于网络、IO编程、socket、进程、线程、协程、TCP/IP等基本知识理解不够深入。所以需要从头到尾总结一下。","text":"最近工作中接触到关于网络编程的一些东西，发现对于网络、IO编程、socket、进程、线程、协程、TCP/IP等基本知识理解不够深入。所以需要从头到尾总结一下。 什么是 IOIO 的英文来源是 Input/Output，即输入/输出，我们的程序和数据在运行过程中会在内存中驻留，由 CPU 来计算，涉及到数据交换的地方，就需要IO接口，IO 包括网络 IO, 内存 IO,磁盘IO等。 IO编程中，Stream（流）是一个很重要的概念，可以把流想象成一个水管，数据就是水管里的水，但是只能单向流动。Input Stream就是数据从外面（磁盘、网络）流进内存，Output Stream就是数据从内存流到外面去。对于浏览网页来说，浏览器和服务器之间至少需要建立两根水管，才可以既能发数据，又能收数据。（摘自http://www.liaoxuefeng.com/） IO 模型大概分为 阻塞 IO（blocking IO） 非阻塞 IO（non-blocking IO） IO 复用（IO multiplexing） 异步 IO（asynchronous IO） 同步 IO（synchronous IO） 但是这几种 IO 模型到底是什么，又分别有什么区别。这里我搜索了一些资料并融入自己的理解详细解释一下。 阻塞 IO（blocking IO）这里先从阻塞 IO 说起，因为 Linux 中默认的网路模型基本都是阻塞 IO。根据调用关系粗略画的时序图如下： 当用户进程调用 recvform 这个系统调用，linux 内核 kernel 开始工作：准备接受数据， 数据一开始往往还没有到达，（例如，网络IO还没有接受到一个完整的 UDP包），这个时候 kernel 需要等待一段时间来接受完数据。在这个过程中，用户进程就会什么也做不了，只能等 kernel 接受完数据并拷贝数据到用户内存中，然后返回消息给用户进程，进程才能继续操作。对于用户进程来说，等待 kernel 返回数据的过程就叫阻塞（block）。等数据返回才能解除阻塞。所以，阻塞 IO 模型的特点就是在 IO 执行的输入和输出，都被阻塞掉了。 打个比喻：去餐厅吃饭，点餐完，你在柜台一直等饭，柜台接受到你的订单开始准备做饭，这时候你只能一直等哪里也不能去，就像是被阻塞，等饭出来了，你拿着饭才走。解除阻塞。 非阻塞 IO non-blocking IO了解了阻塞 IO，我们来看看非阻塞IO模型的具体流程。还是以用户进程的一次调用为例，调用时序图大致如下： 当用户进程调用系统调用，kernel 内核开始准备接受数据，如果一开始没有接受到数据，会立刻返回 error 给用户进程，用户进程就知道数据还没有准备好，就会再次发送调用，直到数据准备好，然后立刻会将数据拷贝到内存中，并返回信息给用户进程，在这个过程中用户进程并不需要等待，每次调用开始到结束的过程，如果出错，kernel 都会立刻返回 error 消息给它。这种模型被称为非阻塞 IO 模型。非阻塞IO 模型的特点是不需要等待，但是需要用户进程不断的去调用。 需要注意的是， 在我的理解下，在系统调用时，如果没有准备好数据就立刻返回给进程 error 信息，这个过程确实是非阻塞的，但是，当数据准备好之后，kernel 开始将数据拷贝到内存中的这段时间内，用户进程其实还是阻塞的。 又打个比喻：还是上面说的去餐馆吃饭，当在柜台点完餐，这个时候服务员说现在做饭需要的食材还没有准备好，你知道了这个信息后，隔一会就去重新点一次餐，最终服务员说食材准备好了，并做好了饭给你。在做饭的过程中可能会不断遇到各种问题不能下单，你只能去不断的重新点餐。 IO 复用非阻塞模型中存在的问题是用户进程需要不断去调用内核，IO 复用模型的出现就是来解决这个问题的，IO 复用模型是建立在内核提供的多路分离函数 select 函数之上的，一个 select 中可以同时处理多个 socket 请求。所以用户一次调用可以注册多个 socket 请求。时序图大致如下： 用户进程使用select 函数注册多个 socket 请求，这时候整个进程就会被阻塞，kernel会“监视”所有select负责的socket，只要其中的一个 socket 请求的数据准备成功，select 就会返回给用户进程可读的消息，这个时候用户进程再调用 read 操作去讲数据拷贝到 内存中。在这个模型中，我们一般设置 select 中的每个 socket 为非阻塞的，但是其实整个进程是被 select 阻塞的。IO 复用的特点是需要两次系统调用（system），并且需要调用 select ，可以同时处理多个 socket 连接。如果处理的连接数不是很高的话，使用select/epoll的 web server 不一定比使用 multi-threading + blocking IO 的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。 异步IO（asynchronous IO）异步IO模型中，当用户发起请求之后，就会立刻得到返回，并去做其他事情去了，从 kernel 角度来讲，他在接受到请求会立刻返回给用户进程消息，不会对其造成任何的阻塞，然后 kernel 会自己等待数据接受完毕并将数据拷贝到内存中，当这一切都完成后 kernel 会发送一个消息给用户进程，告诉它已经操作完成。时序图如下: 相比于IO多路复用模型，异步IO并不十分常用，不少高性能并发服务程序使用IO多路复用模型+多线程任务处理的架构基本可以满足需求。况且目前操作系统对异步IO的支持并非特别完善，更多的是采用IO多路复用模型模拟异步IO的方式（IO事件触发时不直接通知用户线程，而是将数据读写完毕后放到用户指定的缓冲区中）。 同步IO同步IO 的概念是：一个同步 IO 的操作会导致请求的进程被阻塞，直到整个进程完成。有的人可能要说了，阻塞IO 和 IO 多路复用是同步 IO, 非阻塞IO 就是同步 IO。我的理解不是这样的，阻塞IO 和多路复用 IO 肯定是同步 IO，但非阻塞IO 其实本质上也是同步 IO。在非阻塞IO 那里，最后写了需要注意的一个问题，就是当数据准备好之后，kernel 拷贝数据到内存的过程中对于进程来说其实还是阻塞的。并不完全是非阻塞的。 所以，阻塞 IO、非阻塞 IO、IO 多路复用都是同步 IO 区别阻塞 IO 和非阻塞 IO 的区别：请求发起调用 IO 会一直被 block，直到操作完成。而 non-blocking IO在kernel还准备数据的情况下会立刻返回。同步 IO 和异步 IO 的区别：一个IO操作有没有对进程造成阻塞。 参考 https://segmentfault.com/a/1190000003063859#articleHeader11 http://blog.csdn.net/historyasamirror/article/details/5778378","categories":[{"name":"Linux","slug":"Linux","permalink":"http://phachon.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://phachon.github.io/tags/Linux/"},{"name":"IO","slug":"IO","permalink":"http://phachon.github.io/tags/IO/"}]},{"title":"CronTab 解决周期内未执行完重复执行","slug":"linux/crontab","date":"2016-08-22T16:00:00.000Z","updated":"2022-07-11T01:59:03.322Z","comments":true,"path":"linux/crontab.html","link":"","permalink":"http://phachon.github.io/linux/crontab.html","excerpt":"crontab 执行 php 脚本linux 下的 crontab 定时任务服务，可以用来定时运行脚本。工作中经常会用到这样的服务，使用起来比较简单。 12345678/sbin/service crond start # 开启服务/sbin/service crond stop # 停止服务/sbin/service crond restart #重启服务/sbin/service crond reload #重新加载服务sudo crontab -e #插入一条定时任务sudo crontab -l #查看所有的 root 用户下的定时任务列表tail -f /var/log/cron # 实时查看定时任务日志","text":"crontab 执行 php 脚本linux 下的 crontab 定时任务服务，可以用来定时运行脚本。工作中经常会用到这样的服务，使用起来比较简单。 12345678/sbin/service crond start # 开启服务/sbin/service crond stop # 停止服务/sbin/service crond restart #重启服务/sbin/service crond reload #重新加载服务sudo crontab -e #插入一条定时任务sudo crontab -l #查看所有的 root 用户下的定时任务列表tail -f /var/log/cron # 实时查看定时任务日志 123# 例如，添加如下一条定时任务# 分 时 日 月 周* * * * * php test.php 重复执行问题最近在工作中经常会用到定时任务，发现当我们的脚步的执行时间（假设：130s）大于定时任务的设定时间（假设：1分钟）时，定时任务会重复开始执行，即上次的任务还没有执行完，下次的任务的又开始执行。往往执行的脚本里的资源是不允许同时两个脚本同时共享资源，即保证操作的原子性。这样会造成执行出错，下面我们来验证一下。 以下是一个测试的 php 脚本，该脚本执行一次需要 130s 12345678910&lt;?php$time = time();$id = uniqid(); //一次执行的唯一标示file_put_contents(&#x27;/home/phachon/cron/test.log&#x27;, &quot;id: &quot;.$id.&quot; 时间：&quot;.date(&#x27;Y-m-d H:i:s&#x27;, $time).&quot;-开始\\n&quot;, FILE_APPEND);while(time() - $time &lt; 130) &#123; &#125;file_put_contents(&#x27;/home/phachon/cron/test.log&#x27;, &quot;id: &quot;.$id.&quot; 时间：&quot;.date(&#x27;Y-m-d H:i:s&#x27;, time()).&quot;-结束\\n&quot;, FILE_APPEND); 然后添加定时任务，每分钟（60s）执行一次 1*/1 * * * * php /home/phachon/cron/test.php 过一段时间后，查看日志： 1234567891011121314id: 57bbcd4d10262 时间：2016-08-23 12:13:01-开始id: 57bbcd890e7f7 时间：2016-08-23 12:14:01-开始id: 57bbcdc510685 时间：2016-08-23 12:15:01-开始id: 57bbcd4d10262 时间：2016-08-23 12:15:11-结束id: 57bbce010a78d 时间：2016-08-23 12:16:01-开始id: 57bbcd890e7f7 时间：2016-08-23 12:16:11-结束id: 57bbce3d0f68e 时间：2016-08-23 12:17:01-开始id: 57bbcdc510685 时间：2016-08-23 12:17:11-结束id: 57bbce790d90f 时间：2016-08-23 12:18:01-开始id: 57bbce010a78d 时间：2016-08-23 12:18:11-结束id: 57bbceb50eef8 时间：2016-08-23 12:19:01-开始id: 57bbce3d0f68e 时间：2016-08-23 12:19:11-结束id: 57bbce790d90f 时间：2016-08-23 12:20:11-结束id: 57bbceb50eef8 时间：2016-08-23 12:21:11-结束 分析日志我们会发现 id = 57bbcd4d10262 的任务在 12:13:01 开始，但是还没有结束的时候，id=57bbcd890e7f7 和 id=57bbcdc510685 的任务就已经开始了，这样明显存在问题。我们想要的是每次单独执行完后，下一个执行开始: 1234id: 57bbcd4d10262 时间：2016-08-23 12:13:01-开始id: 57bbcd4d10262 时间：2016-08-23 12:15:11-结束id: 57bbcd890e7f7 时间：2016-08-23 12:14:01-开始id: 57bbcd890e7f7 时间：2016-08-23 12:16:11-结束 解决办法 利用临时文件 思路很简单，在执行文件的开头先判断是否有一个 test.lock 的文件，如果有 test.lock 文件，则 exit()，如果没有的话，创建 test.lock 文件，然后执行脚本文件，执行完毕删除 test.lock;实现后代码： 12345678910111213141516&lt;?php $time = time(); $id = uniqid(); $lock = &#x27;/home/phachon/cron/lock/test.lock&#x27;; if(file_exists($lock)) &#123; exit(&#x27;no&#x27;); &#125; touch($lock); file_put_contents(&#x27;/home/phachon/cron/test2.log&#x27;, &quot;id: &quot;.$id.&quot; 时间：&quot;.date(&#x27;Y-m-d H:i:s&#x27;, $time).&quot;-开始\\n&quot;, FILE_APPEND); while(time() - $time &lt; 130) &#123; &#125; file_put_contents(&#x27;/home/phachon/cron/test2.log&#x27;, &quot;id: &quot;.$id.&quot; 时间：&quot;.date(&#x27;Y-m-d H:i:s&#x27;, time()).&quot;-结束\\n&quot;, FILE_APPEND); unlink($lock); 查看日志如下： 1234id: 57bbdd3d6b5e8 时间：2016-08-23 13:21:01-开始id: 57bbdd3d6b5e8 时间：2016-08-23 13:23:11-结束id: 57bbddf10ecb9 时间：2016-08-23 13:24:01-开始id: 57bbddf10ecb9 时间：2016-08-23 13:26:11-结束 利用脚本加锁 思路和第一种方式类似，只是不是用文件判断的方式，而是给文件加锁的方式 实现代码： 12345678910111213&lt;?php$fp = fopen(&quot;/tmp/lock.txt&quot;, &quot;w+&quot;);// 进行排它型锁定if (flock($fp, LOCK_EX | LOCK_NB)) &#123; //执行任务 run(); // 释放锁定 flock($fp, LOCK_UN); &#125; else &#123; echo &quot;文件被锁定&quot;;&#125;fclose($fp);?&gt; 第一种和第二种方法本质思路一样，确实也解决了问题，但是这样需要加代码在我们的脚本里，而且，这样其实 crontab 服务还是多了很多不必要的执行，浪费资源。我们需要找到更加好的方法，在执行代码前就已经判断是否可以执行脚本。 利用 linux flock 锁机制 利用 flock（FreeBSD lockf，CentOS下为 flock），在脚本执行前先检测能否获取某个文件锁，以防止脚本运行冲突。 格式： 12flock [-sxun][-w #] fd#flock [-sxon][-w #] file [-c] command 选项： 123456789-s, --shared: 获得一个共享锁 -x, --exclusive: 获得一个独占锁 -u, --unlock: 移除一个锁，脚本执行完会自动丢弃锁 -n, --nonblock: 如果没有立即获得锁，直接失败而不是等待 -w, --timeout: 如果没有立即获得锁，等待指定时间 -o, --close: 在运行命令前关闭文件的描述符号。用于如果命令产生子进程时会不受锁的管控 -c, --command: 在shell中运行一个单独的命令 -h, --help 显示帮助 -V, --version: 显示版本 锁类型： 共享锁：多个进程可以使用同一把锁，常被用作读共享锁 独占锁：同时只允许一个进程使用，又称排他锁，写锁。 这里我们需要同时只允许一个进程使用，所以使用独占锁。 修改后的定时任务如下： 1*/1 * * * * flock -xn /tmp/test.lock -c &#x27;php /home/phachon/cron/test.php&#x27; &gt;&gt; /home/phachon/cron/cron.log&#x27; 日志如下： 1234id: 57bbf255e4b2b 时间：2016-08-23 14:51:01-开始id: 57bbf255e4b2b 时间：2016-08-23 14:53:11-结束id: 57bbf3090eca0 时间：2016-08-23 14:54:01-开始id: 57bbf3090eca0 时间：2016-08-23 14:56:11-结束 完美的解决了我们的问题 总体看来，还是用第三种方法比较好，而且也方便.","categories":[{"name":"Linux","slug":"Linux","permalink":"http://phachon.github.io/categories/Linux/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"},{"name":"CronTab","slug":"CronTab","permalink":"http://phachon.github.io/tags/CronTab/"}]},{"title":"CentOS6.3+Apache2.2+php5.3.8+Mysql5.5.4源码搭建Lump环境","slug":"install/lump-install","date":"2016-07-28T16:00:00.000Z","updated":"2022-07-11T01:59:03.321Z","comments":true,"path":"install/lump-install.html","link":"","permalink":"http://phachon.github.io/install/lump-install.html","excerpt":"系统环境 虚拟机VMware 下CentOS 6.3最小化安装。 PHP版本：php-5.3.8.tar.gz Apache版本：httpd-2.2.31.tar.gz MySql版本：MySql-5.5.45.tar.gz","text":"系统环境 虚拟机VMware 下CentOS 6.3最小化安装。 PHP版本：php-5.3.8.tar.gz Apache版本：httpd-2.2.31.tar.gz MySql版本：MySql-5.5.45.tar.gz 安装前准备安装所需要的库文件在安装PHP之前，应先安装PHP5需要的最新版本库文件，例如libxml2、libmcrypt以及GD2库等文件。安装GD2库是为了让PHP5支 持GIF、PNG和JPEG图片格式，所以在安装GD2库之前还要先安装最新的zlib、libpng、freetype和jpegsrc等库文件。 autoconf-2.61.tar.gz freetype-2.3.5.tar.gz gd-2.0.35.tar.gz jpegsrc.v6b.tar.gz libmcrypt-2.5.8.tar.gz libpng-1.2.31.tar.gz libxml2-2.6.30.tar.gz zlib-1.2.3.tar.gz 下载安装包有两种方式： (1).利用wget 工具 先 yum install –y wget 安装wget .然后用 wgethttp://www.......com./ksk 下载 (2).利用 rz sz 命令将windows 下载好的包上传到 linux下 12yum install –y lrzsz 输入rz 弹出windows框选好安装包上传。cd /usr/local/src 进入到src目录下，将所有的安装包都放在这个目录下（方便管理）。 必须先安装gcc、gc-c++用来编译 这里采用yum安装即可。12yum install –y gccyum install –y gcc-c++ 会自动安装成功。 解压缩命令：tar –zxvf autoconf-2.61.tar.gz其他安装包一样。依次解压。 make 命令1Yum install -y make 安装库文件安装libxml2123# cd /usr/local/src/libxml2-2.6.30​# ./configure --prefix=/usr/local/libxml2# make &amp;&amp; make install 安装libmcrypt123# cd /usr/local/src/libmcrypt-2.5.8# ./configure --prefix=/usr/local/libmcrypt# make &amp;&amp; make install 安装zlib123# cd /usr/local/src/zlib-1.2.3# ./configure 注意：这里直接./configure 不用--prefix# make &amp;&amp; make install 安装libpng123# cd /usr/local/src/libpng-1.2.31# ./configure --prefix=/usr/local/libpng 注意：安装失败。原因很有可能是zlib 没有安装上# make &amp;&amp; make install 安装jpeg6这个软件包安装有些特殊，其它软件包安装时如果目录不存在，会自动创建，但这个软件包安装时需要手动创建。 12345678# mkdir /usr/local/jpeg6# mkdir /usr/local/jpeg6/bin# mkdir /usr/local/jpeg6/lib# mkdir /usr/local/jpeg6/include# mkdir -p /usr/local/jpeg6/man/man1# cd /usr/local/src/jpeg-6b# ./configure --prefix=/usr/local/jpeg6/ --enable-shared --enable-static# make &amp;&amp; make install 安装freetype1234# cd /usr/local/src/freetype-2.3.5# ./configure --prefix=/usr/local/freetype# make# make install 安装autoconf123# cd /usr/local/src/autoconf-2.61# ./configure# make &amp;&amp; make install 安装GD库123456789# cd /usr/local/src/gd-2.0.35# ./configure \\​--prefix=/usr/local/gd2/ \\​--enable-m4_pattern_allow \\​--with-zlib=/usr/local/zlib/ \\ --with-jpeg=/usr/local/jpeg6/ \\ --with-png=/usr/local/libpng/ \\ --with-freetype=/usr/local/freetype/# make 出现错误： 1234make[2]: *** [gd_png.lo] Error 1make[2]: Leaving directory `/usr/local/src/gd-2.0.35&#x27;make[1]: *** [all-recursive] Error 1make[1]: Leaving directory `/usr/local/src/gd-2.0.35&#x27;make: *** [all] Error 2 分析：这个问题是因为gd库中的gd_png.c这个源文件中包含png.h时，png.h没有找到导致的。 解决：在编译文件里 12# vi gd_png.c# 将include “png.h” 改成 include “/usr/local/libpng/include/png.h” 其中/usr/local/libpng/为libpng安装路径。 1# make install 开启80、3306端口1vi /etc/sysconfig/iptables 添加 12-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT 重启防火墙 1service iptables restart 关闭selinux修改/etc/selinux/config 文件 12vi /etc/selinux/config# 将SELINUX=enforcing改为SELINUX=disabled 重启防火墙 1service iptables restart 安装 Apache安装Apache123456789101112# cd /usr/local/src/httpd-2.2.9# ./configure \\ --prefix=/usr/local/apache2 \\ --sysconfdir=/etc/httpd \\ --with-z=/usr/local/zlib \\ --with-included-apr \\ --enable-so \\ --enable-deflate=shared \\ --enable-expires=shared \\ --enable-rewrite=shared \\ --enable-static-support# make &amp;&amp; make install 配置Apache启动Apache 1#/usr/local/apache2/bin/apachectl start 如果提示httpd: Could not reliably determine the server’s fully qualified domain name, using ::1 for ServerName 1vi /etc/http/httpd.conf 将里面的#ServerName www.example.com:80注释去掉,改成ServerName localhost:80 即可。再启动httpd 关闭Apache 1# /usr/local/apache2/bin/apachectl stop 查看80端口是否开启 ，之前我们已经开启 1# netstat -tnl|grep 80 然后可以通过浏览器访问http://localhost:80，如果页面显示正常显示测试页面，即表示apache已安装并启动成功。 添加自启动 1# echo &quot;/usr/local/apache2/bin/apachectl start&quot; &gt;&gt; /etc/rc.d/rc.local 安装 Mysqlcmake的安装12345[root@localhost]# tar -zxv -f cmake-2.8.10.2.tar.gz // 解压压缩包[root@localhost local]# cd cmake-2.8.10.2[root@localhost cmake-2.8.10.2]# ./configure[root@localhost cmake-2.8.10.2]# make[root@localhost cmake-2.8.10.2]# make install 将cmake永久加入系统环境变量用vi在文件/etc/profile文件中增加变量，使其永久有效， 1[root@localhost local]# vi /etc/profile 在文件末尾追加以下两行代码： 1PATH=/usr/local/cmake-2.8.10.2/bin:$PATHexport PATH 执行以下代码使刚才的修改生效： 1[root@localhost local]# source /etc/profile 用 export 命令查看PATH值 1[root@localhost local]# echo $PATH 注意：也可以直接yum install –y cmake 安装 yum install -y ncurses-devel必须安装，不然会出错 创建mysql的安装目录及数据库存放目录12[root@localhost]# mkdir -p /usr/local/mysql //安装mysql[root@localhost]# mkdir -p /usr/local/mysql/data //存放数据库 创建mysql用户及用户组1[root@localhost] groupadd mysql[root@localhost] useradd -r -g mysql mysql 编译安装mysql12345678910111213141516[root@localhost local]# tar -zxv -f mysql-5.5.45.tar.gz //解压[root@localhost local]# cd mysql-5.5.45 cmake -DCMAKE_INSTALL_PREFIX=/usr/local/mysql \\ -DMYSQL_UNIX_ADDR=/tmp/mysql.sock \\ -DDEFAULT_CHARSET=utf8 \\ -DDEFAULT_COLLATION=utf8_general_ci \\ -DWITH_EXTRA_CHARSETS=all \\ -DWITH_MYISAM_STORAGE_ENGINE=1 \\ -DWITH_INNOBASE_STORAGE_ENGINE=1 \\ -DWITH_MEMORY_STORAGE_ENGINE=1 \\ -DWITH_READLINE=1 \\ -DENABLED_LOCAL_INFILE=1 \\ -DMYSQL_DATADIR=/usr/local/mysql/data \\ -DMYSQL_USER=mysql[root@localhost mysql-5.5.45]# make[root@localhost mysql-5.5.45]# make install 检验是否安装成功1234[root@localhost mysql-5.5.45]# cd /usr/local/mysql/[root@localhost mysql]# lsbin COPYING data docs include INSTALL-BINARY lib man mysql-test README scripts share sql-bench support-files 有bin等以上文件的话，恭喜你已经成功安装了mysql。 设置mysql目录权限12345[root@localhost mysql]# cd /usr/local/mysql //把当前目录中所有文件的所有者设为root，所属组为mysql[root@localhost mysql]# chown -R root:mysql .[root@localhost mysql]# chown -R mysql:mysql data 将mysql的启动服务添加到系统服务中1[root@localhost mysql]# cp support-files/my-medium.cnf /etc/my.cnfcp：是否覆盖&quot;/etc/my.cnf&quot;？ y 创建系统数据库的表12[root@localhost mysql]# cd /usr/local/mysql[root@localhost mysql]# scripts/mysql_install_db --user=mysql 设置环境变量1[root@localhost ~]# vi /root/.bash_profile 修改为： 12PATH=$PATH:$HOME/bin:/usr/local/mysql/bin:/usr/local/mysql/lib[root@localhost ~]# source /root/.bash_profile //使刚才的修改生效 手动启动mysql12[root@localhost ~]# cd /usr/local/mysql[root@localhost mysql]# ./bin/mysqld_safe --user=mysql &amp; //启动MySQL，但不能停止 1mysqladmin -u root -p shutdown //此时root还没密码，所以为空值，提示输入密码时，直接回车即可。 将mysql的启动服务添加到系统服务中1[root@localhost mysql]# cp support-files/mysql.server /etc/init.d/mysql 启动mysql1[root@localhost mysql]# service mysql startStarting MySQL... ERROR! The server quit without updating PID file (/usr/local/mysql/data/localhost.localdomain.pid). 启动失败：我这里是权限问题，先改变权限 1[root@localhost mysql]# chown -R mysql:mysql /usr/local/mysql 接着启动服务器 1[root@localhost mysql]# /etc/init.d/mysql start 修改MySQL的root用户的密码以及打开远程连接123456789[root@localhost mysql]# mysql -u root mysqlmysql&gt; use mysql;mysql&gt; desc user;mysql&gt; GRANT ALL PRIVILEGES ON *.* TO root@&quot;%&quot; IDENTIFIED BY &quot;root&quot;; //为root添加远程连接的能力mysql&gt; update user set Password = password(&#x27;123456&#x27;) where User=&#x27;root&#x27;; //设置root用户密码mysql&gt; select Host,User,Password from user where User=&#x27;root&#x27;;mysql&gt; flush privileges;mysql&gt; exit; 重新登录1[root@localhost mysql]# mysql -u root -pEnter password:123456 若还不能进行远程连接，关闭防火墙 1[root@localhost]# /etc/rc.d/init.d/iptables stop 安装 php安装PHP12345678910111213141516# cd /usr/local/src/php-5.3.8# ./configure \\ --prefix=/usr/local/php \\ --with-config-file-path=/usr/local/php/etc \\ --with-apxs2=/usr/local/apache2/bin/apxs \\ --with-mysql=/usr/local/mysql/ \\ --with-libxml-dir=/usr/local/libxml2/ \\ --with-png-dir=/usr/local/libpng/ \\ --with-jpeg-dir=/usr/local/jpeg6/ \\ --with-freetype-dir=/usr/local/freetype/ \\​--with-gd=/usr/local/gd2/ \\ --with-zlib-dir=/usr/local/zlib/ \\​--with-mcrypt=/usr/local/libmcrypt/ \\​--with-mysqli=/usr/local/mysql/bin/mysql_config \\​--enable-mbstring=all \\​--enable-sockets 1# make &amp;&amp; make install 配置PHP创建配置文件 1# cp php.ini-development /usr/local/php/etc/php.ini 使用vi编辑apache配置文件 1# vi /etc/httpd/httpd.conf 最后一行添加这一条代码 1Addtype application/x-httpd-php .php .phtml 重启Apache 1# /usr/local/apache2/bin/apachectl restart 测试编写info.php文件，查看php配置详细1#vi /usr/local/apache2/htdocs/info.php","categories":[{"name":"Install","slug":"Install","permalink":"http://phachon.github.io/categories/Install/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/tags/Mysql/"},{"name":"CentOS","slug":"CentOS","permalink":"http://phachon.github.io/tags/CentOS/"},{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"},{"name":"Apache","slug":"Apache","permalink":"http://phachon.github.io/tags/Apache/"}]},{"title":"浅析 PHP 的几种运行方式","slug":"php/php-run-type","date":"2016-07-28T16:00:00.000Z","updated":"2022-07-11T01:59:03.324Z","comments":true,"path":"php/php-run-type.html","link":"","permalink":"http://phachon.github.io/php/php-run-type.html","excerpt":"PHP 的几种运行方式 CGI FAST-CGI Web-module CLI","text":"PHP 的几种运行方式 CGI FAST-CGI Web-module CLI CGICGI (Common Gateway Interface) 是通用网关型接口,CGI是外部应用程序（CGI程序）与Web服务器之间的接口标准，是在CGI程序和Web服务器之间传递信息的过程。简单的说，就是当你的 php引擎和web服务器相互传递消息时，CGI 规定了一套标准来规范如何传递数据以及数据传递的格式。 当 web 服务器接收到一个请求时，就会启动一个 CGI 进程，这里就会通知到PHP 引擎，然后去解析 php.ini 文件，开始处理请求，并且将处理的请求的结果以标准的格式返回给 web 服务器，并退出进程。 12345title:CGI工作原理浏览器-&gt;web服务器:发送请求web服务器-&gt;CGI应用程序(php引擎):启动一个 CGI 进程CGI应用程序(php引擎)-&gt;web服务器:发送解析好的信息web服务器-&gt;浏览器:发送 html 信息 显而易见的是，这样每一个请求过来的话都会重新去启动一个 CGI 进程,关键是每个进程又都会去启动引擎去解析 php.ini 文件，这样当请求多的时候，效率会非常的低。因而，已经逐渐被抛弃。 注意：需要明确的是 CGI 只是一套接口标准，具体的实现程序才是用来启动进程的。比如根据 CGI 实现的 php-cgi 程序。 FAST-CGI既然 CGI 是如此的效率低下，聪明的人类肯定能够想出更好的方法来使得 CGI 更加高效，对的，这就是 FAST-CGI。 FAST-CGI 也是一种通用网关型接口，是建立在 CGI 的基础上进化而来,FastCGI 像是一个常驻(long-live)型的 CGI，它可以一直执行着，只要激活后，不会每次都要花费时间去fork一次(这是CGI最为人诟病的fork-and-execute 模式)。它还支持分布式的运算, 即 FastCGI 程序可以在网站服务器以外的主机上执行并且接受来自其它网站服务器来的请求。简单理解呢，大概是这样：当web服务器启动时，会载入Fast-CGI 进程管理器，FastCGI进程管理器会同时开启多个 CGI 子进程，相当于一个进程池，当 web 请求到来时，会选择一个 CGI 解释器并连接，处理完成后将信息返回给web服务器，这时候，该子进程又会回到进程管理器中继续等待下一个连接，所以这样不需要每次都去重新启动进程，加载配置文件。 123456title:fast-cgi 工作原理web服务器-&gt;fastcgi进程管理:启动载入fastcgi进程管理-&gt;cgi子进程:启动多个web服务器-&gt;fastcgi进程管理:请求fastcgi进程管理-&gt;cgi子进程:连接一个cgi子进程-&gt;web服务器:返回解析并重新等待新的请求 php-cgi 只是用来处理 cgi 进程的程序，那 php fast-cgi 进程管理器是怎么实现的呢，php-fpm ,对的，就是它，php-fmp 用来管理和调度这些 php fast-cgi 进程。 注意：还是需要明确一下，fast-cgi 也只是一套协议标准，php fast-cgi才是具体的实现程序，php-fpm是实现了对 fast-cgi 的进程管理。 Web-module这个简称为 web 模块加载模式，想必用 apache 搭建过 php 环境的应该都了解，apahce 需要加载 mod-php5 模块，这个模块就是用来将 Apache 传递过来的 php 文件的请求，并处理这些请求，最终将处理的结果返回给 apache。在 apache 的配置文件中配置好了 php 模块，php 模块就会通过注册 apache2 的 ap_hook_post_config 挂钩，实现请求与返回。 windows 下： 1LoadModule php5_module d:/server/php/php5apache2_2.dll linux 下： 1LoadModule php5_module modules/mod_php5.so 该模块是 apache 在CGI的基础上进行的一种扩展，加快PHP的运行效率 CLIphp-CLI：PHP Command Line Interface 即 php 在命令行运行的接口，当然是相对于以上三种方式（web 请求）来说的 优点： 多进程池，子进程完成后，内核会回收掉 主进程只进行任务分发 CLI 模式在 windows 和 linux 都可以运行。 以上就是 php 的几种主要的运行方式，除此之外，还有一种运行方式是 ISAPI（Internet Server Application Program Interface）是微软提供的一套面向Internet服务的API接口，在这里就不多介绍了。因为现在几乎都是在 Linux 下部署 php 应用了。","categories":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"},{"name":"FAST-CGI","slug":"FAST-CGI","permalink":"http://phachon.github.io/tags/FAST-CGI/"},{"name":"PHP-FPM","slug":"PHP-FPM","permalink":"http://phachon.github.io/tags/PHP-FPM/"}]},{"title":"Linux 常用命令总结","slug":"linux/linux-command","date":"2016-07-27T16:00:00.000Z","updated":"2022-07-11T01:59:03.322Z","comments":true,"path":"linux/linux-command.html","link":"","permalink":"http://phachon.github.io/linux/linux-command.html","excerpt":"系统相关 who 显示在线登录用户 whoami 显示当前操作的用户 hostname 主机名 top 显示当前耗费最多的进程以及内存消耗 ps -aux 显示所有的进程信息 df 查看磁盘所占大小 -h 带单位 ifconfig 网络信息 ping 测试网络连接 netstat 网络状态信息 kill 杀死进程 clear 清屏 shutdown -r 关机重启 -h 关机不重启 now 立刻关机 reboot 重启","text":"系统相关 who 显示在线登录用户 whoami 显示当前操作的用户 hostname 主机名 top 显示当前耗费最多的进程以及内存消耗 ps -aux 显示所有的进程信息 df 查看磁盘所占大小 -h 带单位 ifconfig 网络信息 ping 测试网络连接 netstat 网络状态信息 kill 杀死进程 clear 清屏 shutdown -r 关机重启 -h 关机不重启 now 立刻关机 reboot 重启 目录相关 cd 切换目录 ls 列出目录下的文件或文件夹 -l 列出文件详细信息 -s 列出所有的文件及目录（包括隐藏） -f 列出的文件显示文件类型 mkdir 创建目录 -p 递归创建(父级不存在创建) pwd 显示当前目录路径 rmdir 删除目录 du 查看目录所占大小 -h 带有单位显示目录所占大小 zip 打包成 zip 文件 unzip 解压 zip 文件 tar 打包压缩 -c 归档文件 -x 解压 -z gzip压缩文件 -j bzip2压缩文件 -v 显示压缩或解压缩过程 -f 使用档名压缩：tar -zcvf /home/test.tar.gz /home/test解压：tar -zxvf test.tar.gz ./ 用户权限相关 useradd 添加用户 -c 注释信息 -d 目录指定用户主目录，如果此目录不存在，则同时使用-m选项，可以创建主目录 -g 用户组 指定用户所属的用户组 -G 用户组，用户组指定用户所属的附加组 -s Shell文件 指定用户的登录Shell -u 用户号 指定用户的用户号，如果同时有-o选项，则可以重复使用其他用户的标识号 useradd –d /usr/sam -m sam usermod 修改用户 参数和 useradd 一样 userdel 删除用户 -r 连同目录一起删除 普通用户增加 root 权限 修改 /etc/sudoers 文件，找到下面一行，把前面的注释（#）去掉12Allows people in group wheel to run all commands%wheel ALL=(ALL) ALL 然后修改用户，使其属于root组（wheel），命令如下： 1usermod -g root phachon 修改完毕，现在可以用 phachon 帐号登录，然后用命令 su - ，即可获取root 权限 sudo 命令可以不需要 root 密码来以 root 的权限执行 修改 /etc/sudoers 文件，找到下面一行，在root下面添加一行，如下所示： 1234Allow root to run any commands anywhereroot ALL=(ALL) ALLphachon ALL=(ALL) ALL #sudo 需要密码 phachon ALL=(ALL) NOPASSWD:ALL # sudo 不需要密码 ok , 你就可以用 root 权限了 chown 更改文件的用户用户组 sudo chown [-R] owner[:group] {File|Directory}1sudo chown redis:redis ./redis 更改文件权限 首先先来了解一下三种基本权限r -&gt; 读 数值表示为 4w -&gt; 写 数值表示为 2x -&gt; 可执行 数值表示为 1 假如某一个文件的权限为 -rw-rw-r– -rw-rw-r–一共十个字符，分成四段。第 1 个字符“-”表示普通文件，“l”链接，“d”表示目录第2、3、4个字符“rw-”表示当前所属用户的权限，所以用数值表示为4+2=6第5、6、7个字符“rw-”表示当前所属组的权限，所以用数值表示为4+2=6第8、9、10个字符“r–”表示其他用户权限，所以用数值表示为2所以操作此文件的权限用数值表示为662 777 对应的权限是 -rwxrwxrwx 1sudo chmod 0777 test.php 修改 test.php 权限为 777","categories":[{"name":"Linux","slug":"Linux","permalink":"http://phachon.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://phachon.github.io/tags/Linux/"}]},{"title":"PHP 魔术方法","slug":"php/php-call-callStatic","date":"2016-07-27T16:00:00.000Z","updated":"2022-07-11T01:59:03.324Z","comments":true,"path":"php/php-call-callStatic.html","link":"","permalink":"http://phachon.github.io/php/php-call-callStatic.html","excerpt":"__call 方法的使用定义：在对象中调用一个不可访问方法时，__call() 会被调用。","text":"__call 方法的使用定义：在对象中调用一个不可访问方法时，__call() 会被调用。 示例： 12345678910111213141516171819202122&lt;?php/** * __call 测试 * @author phachon@163.com */class Test &#123; public function __construct() &#123; &#125; public function show() &#123; echo &quot;show 一下\\n&quot;; &#125; public function __call($method, $arguments) &#123; echo &quot;不可访问的方法都来我这里了\\n&quot;; &#125;&#125;$test = new Test(); $test-&gt;show();//输出: show 一下$test-&gt;close(); //输出: 不可访问的方法都来我这里来了 上面例子中调用 close 方法时不存在，所以被 __call 接收了。 但是如果调用类里面的方法是 protected 或者是 private 的时候，是否可以被 __call 接收呢？ 123456789101112131415161718192021222324252627282930313233&lt;?php/** * __call 测试 * @author phachon@163.com */class Test &#123; public function __construct() &#123; echo &quot;我是构造方法\\n&quot;; &#125; public function show() &#123; echo &quot;show 一下\\n&quot;; &#125; public function __call($method, $arguments) &#123; echo &quot;不可访问的方法都来我这里了\\n&quot;; &#125; protected function _sing() &#123; echo &quot;我是唱歌的&quot;; &#125; private function _run() &#123; echo &quot;我是跑步的&quot;; &#125;&#125;$test = new Test();$test-&gt;show(); //输出：show 一下$test-&gt;_sing(); //输出：不可访问的方法都来我这里了$test-&gt;_run(); //输出：不可访问的方法都来我这里了$test-&gt;close(); //输出：不可访问的方法都来我这里了 事实证明除了没有定义的方法以及 private 和 protected 方法都会被魔术方法 __call 接收，所以定义为调用一个不可访问的方法时才被调用是十分准确的。（之前听有些人说是当访问一个未被定义的方法时被调用这是不准确的） 注意：__call 在使用时必须声明为 public 并且，方法必须有带两个参数，一个是 被调用的方法名，一个是方法携带的参数。 __callStatic 方法的使用定义：用静态方式中调用一个不可访问方法时，__callStatic() 会被调用。示例： 12345678910111213141516171819202122&lt;?php/** * __callStatic 测试 * @author phachon@163.com */class Test &#123; public function __construct() &#123; &#125; public static function show() &#123; echo &quot;show 一下\\n&quot;; &#125; public static function __callStatic($className, $arguments) &#123; echo &quot;不可访问的静态方法来这里吧&quot;; &#125;&#125;Test::show(); //输出：show 一下Test::close(); //输出：不可访问的静态方法来这里吧 同样对于没有定义的方法以及 private 和 protected 的静态方法，都会被__callStatic 接收。","categories":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"}]},{"title":"CentOS 下安装 Memcache 和 php 扩展","slug":"install/centos-install-memcache","date":"2016-07-25T16:00:00.000Z","updated":"2022-07-11T01:59:03.321Z","comments":true,"path":"install/centos-install-memcache.html","link":"","permalink":"http://phachon.github.io/install/centos-install-memcache.html","excerpt":"CentOS 下安装 Memcache 和 php memcache 扩展 下载安装查看相关软件包 1Yum search memcached 有了，可以进行安装了 1Yum -y install memcached","text":"CentOS 下安装 Memcache 和 php memcache 扩展 下载安装查看相关软件包 1Yum search memcached 有了，可以进行安装了 1Yum -y install memcached Memcache关联php 1yum -y install php-pecl-memcache 验证安装结果 12memcached -hphp -m | grep memcache Memcache的基本设置启动memcache的服务端： 1memcached -d -m 100 -u root -l 222.186.xx.xxx -p 11211 -c 512 -P /tmp/memcached.pid 参数说明-d 选项是启动一个守护进程；-m 是分配给Memcache使用的内存数量，单位是MB，我这里是100MB；-u 是运行Memcache的用户，我这里是root；-l 是监听的服务器IP地址我这里指定了服务器的IP地址222.186.xx.xxx；-p 是设置Memcache监听的端口，我这里设置了11211，最好是1024以上的端口；-c 选项是最大运行的并发连接数，默认是1024，我这里设置了512，按照你服务器的负载量来设定；-P 是设置保存Memcache的pid文件，我这里是保存在 /tmp/memcached.pid； 使用检查memcached是否启动 12Netstat -an | moretcp 0 0 222.186.xx.xxx:11211 0.0.0.0:* LIST 设置开机启动 1Chkconfig memcached on 启动和停止 12Service memcached start | stopOr /etc/init.d/memcached start | stop 重启centos 12Shutdown -r nowOr reboot 编写 php 文件来验证 memcache 是否可用吧。","categories":[{"name":"Install","slug":"Install","permalink":"http://phachon.github.io/categories/Install/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"http://phachon.github.io/tags/CentOS/"},{"name":"Memcache","slug":"Memcache","permalink":"http://phachon.github.io/tags/Memcache/"},{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"}]},{"title":"Wamp 环境的搭建","slug":"install/wamp-install","date":"2016-07-25T16:00:00.000Z","updated":"2022-07-11T01:59:03.321Z","comments":true,"path":"install/wamp-install.html","link":"","permalink":"http://phachon.github.io/install/wamp-install.html","excerpt":"Apache下载Apache是一种b/s结构的软件，Apache属于s服务端 下载地址：http://httpd.apache.org/download.cgi 选择相应的版本下载 我这里下载的是 httpd-2.2.22-win32-x86-no_ssl.msi解释一下下载的文件：版本：2.2.22操作系统：win32 x86是否提供ssl: no_ssl 不提供","text":"Apache下载Apache是一种b/s结构的软件，Apache属于s服务端 下载地址：http://httpd.apache.org/download.cgi 选择相应的版本下载 我这里下载的是 httpd-2.2.22-win32-x86-no_ssl.msi解释一下下载的文件：版本：2.2.22操作系统：win32 x86是否提供ssl: no_ssl 不提供 安装(1) 双击点击下载好的文件：httpd-2.2.22-win32-x86-no_ssl.msi (2) 点击 next,进入协议页面，勾选同意。 (3) 点击两次 next 进入到服务器配置页面 (4) 点击next，进入配置模式，选择自定义配置模式 (5) 点击next，进入路径配置界面 在 D 盘下创建一个server 目录（不要使用中文）将安装路劲选择到创建是server目录，并在server目录下创建一个Apache目录 (6) 点击next，进入到准备安装界面，点击install进行安装，之后点击finish完成,在电脑的任务栏会出现 apache 的图标，绿色代表已开启 (7) 验证是否成功 在浏览器输入 http://localhost ，页面 输出 It, works! 证明安装成功。 (8) apache 安装后的目录结构说明 D:/server/apache 下 bin: Apache 的可执行文件 cgi-bin：CGI 可执行文件 conf：配置文件 error：错误日志 htdocs：网站默认根目录 icons：图标 logs：日志 modules：Apache 可加载的模块 D:server/apache/bin httpd.exe apache 的服务端 (9) 几个简单的 httpd 命令 M：Apache可以加载的模块（功能） l：当前Apache已经加载的模块 t：验证配置文件的语法错误 在cmd控制台下，进入到 Apache 的bin目录，使用 httpd.exe 或者httpd 命令+空格+参数 配置文件验证 修改Apache配置文件：Apache/conf/httpd.conf 1Servername www.test.com:80 #将前面的&#x27;#&#x27;号去掉即可开启 修改完配置文件后记得要重启 apache ,否则配置不会生效。 Mysql下载1mysql是一种c/s结构的软件。 当前是在为web服务器增加可以访问数据库的能力。下载地址：http://www.mysql.com/downloads/我这里下载的是:mysql-5.5-win32 安装(1) 双击文件，进入安装界面 (2) 点击next，进入协议界面，选中同意协议，点击next进入配置模式 (3) 点击自定义安装，进入路径配置界面 在 D 盘 server 下创建一个目录 mysql修改mysql的安装目录 修改数据路径 (4) 点击 next 进入到准备安装界面，点击install进行安装，安装完成之后进入到安装完成页面,勾选 finish 完成 (5) 点击next进行配置，进入到配置选择界面 (6) 选择详细配置，点击next，进入到服务器类型配置界面 (7) 选择开发者机器，点击next，进入数据库用途配置 (8) 选择多功能数据库，点击next，进入到InnoDB驱动选择界面，可以直接点击next跳过 (9) 配置并发选项 (10) 选择手动选择，设置为默认的并发量15个，点击next，进入网络设置界面 (11) 勾选防火墙放行，其他默认，点击next进入到字符集设置界面 (12) 选择手动选择，设置字符集为utf8，点击next进入windows设置 (13) 勾选设置环境变量，点击next进入安全选项配置 (14) 输入root用户的密码，点击next进入到准备配置的界面 (15) 点击excute执行配置项，需要上面的四项都成功打上勾才算配置成功,点击finish完成安装。 (16) 检测是否安装成功 cmd控制台输入mysql –uroot –proot (17) mysql 安装目录结构解释 bin：执行文件 data：数据存放目录 include：包含文件 lib：核心文件 share：共享文件 my.ini：mysql 核心配置文件 mysql 的 bin 目录 mysql.exe mysql 的客户端 mysqld.exe mysql 服务器端 配置PHP下载php 下载地址：http://www.php.net/downloads.php 选择对应的版本下载 配置在 D:server/ 下创建 php 目录,将下载的 php 文件压缩包解压到该文件夹下 (1) 配置 apache,让 apache 能够识别 php在Apache中加载PHP模块（把PHP当做Apache的一个模块来运行）。/apache/conf/httpd.conf 12LoadModule php5_module d:/server/php/php5apache2_2.dll #加载PHP，当做Apache的模块 加载模式：LoadModule 模块名（不能随意） 模块的动态链接库所在的AddType application/x-httpd-php .php #增加PHP处理模块需要处理的文件,将以.php结尾的文件交给PHP模块去处理 (2) 配置 php ，让 php 去连接 mysql PHP本身没有能力去操作mysql，需要借助外部扩展才可以。在PHP中，提供一套mysql的扩展，能够连接mysql服务器。 在 php 的安装目录下有两个配置文件 php.ini-development php.ini-production,复制一份，修改为 php.ini 文件。打开 php.ini 将php的配置文件，加载到Apache的配置文件中。 /apache/conf/httpd.conf 1PHPIniDir d:/server/php/php.ini #增加php配置文件的路径 开启mysql扩展。/php/php.ini 1;extesion=php_mysql.dll #将前面的 ; 号去掉即可开启 指定扩展文件所在的目录。/php/php.ini 12;extension_dir = &quot;ext&quot;extension_dir = d:server/php/ext 修改 php 时区 在php的配置文件中去修改。/php/php.ini 12;date_timezone = date_timezone = PRC #中国时区 配置虚拟主机Apache的虚拟主机分为两种：基于IP地址的虚拟主机，基于域名的虚拟主机 基于域名的虚拟主机：通过域名来是的Apache区分对应的网站（文件夹） Apache提供了多个位置可以用来配置虚拟主机，httpd.conf和/extra/httpd_vhost.confhttpd.conf配置之后，只需要直接重启Apache即可生效/extra/httpd_vhost.conf配置之后，需要在httpd.conf下加载对应的配置文件 先加载虚拟主机配置文件找到 Include conf/extra/http-vhosts.conf,并开启 创建虚拟主机1234&lt;VirtualHost *:80&gt; ServerName www.test.com #域名 DocumentRoot &quot;d:code/php/test&quot; #路径&lt;/VirtualHost&gt; 重启 apache修改 hosts 文件hosts文件路径：C:\\Windows\\System32\\drivers\\etc\\hosts 12127.0.0.1 localhost127.0.0.1 test.com 设置访问权限123456&lt;Directory &quot;d:code/php/test&quot;&gt; # 目录访问权限 Order Deny,Allow #设置顺序 Deny from all Allow from all DirectoryIndex indexs #指定访问方式，如果没有请求文件，而默认的文件又不存在，则显示所有的文件列表（在开发环境中应该禁用）&lt;/Directory&gt; 注意：一旦开启虚拟主机，那么默认的localhost会被覆盖，被第一个虚拟主机覆盖，为了解决不被覆盖的问题，需要额外增加一个localhost的虚拟主机。 123456789101112&lt;VirtualHost *:80&gt; ServerName localhost DocumentRoot &quot;d:server/apache/htdocs&quot; #网站根目录 &lt;Directory &quot;d:code/php/test&quot;&gt; # 目录访问权限 Order Deny,Allow #设置顺序 Deny from all Allow from all DirectoryIndex indexs #指定访问方式，如果没有请求文件，而默认的文件又不存在，则显示所有的文件列表（在开发环境中应该禁用） &lt;/Directory&gt;&lt;/VirtualHost&gt; 更加清晰的配置方法上面的配置方法是通用的配置虚拟主机的方式，但是随着越来越多的开发应用，会发现 Include conf/extra/http-vhosts.conf 里面会有越来越多的配置写在一起,有些早已不用的和正在使用的配置都加载在一起，不利于管理和修改。因此还可以采取以下的方式配置。 重新回到第1步中，打开 http.conf 文件，这次不要打开 Include conf/extra/http-vhosts.conf 的配置。而是在 http.conf 的最后一行添加 Include conf/extra/test.com.conf。 在 conf/extra 下面创建一个 test.com.conf 文件，然后将配置信息写入到文件中。 12345678910111213NameVirtualHost *:80&lt;VirtualHost *:80&gt; ServerAdmin phachon@163.com DocumentRoot &quot;D:/server/apache/htdocs/test&quot; DirectoryIndex index.php ServerName test.com &lt;Directory &quot;D:/server/apache/htdocs/test&quot;&gt; Options Indexes FollowSymLinks AllowOverride None Order allow,deny Allow from all &lt;/Directory&gt;&lt;/VirtualHost&gt; 以后每新增一个虚拟主机配置就在 http.conf 的最后一行加载一下，并在 conf/extra 下创建对应的 conf 文件。","categories":[{"name":"Install","slug":"Install","permalink":"http://phachon.github.io/categories/Install/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/tags/Mysql/"},{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"},{"name":"Apache","slug":"Apache","permalink":"http://phachon.github.io/tags/Apache/"},{"name":"Windows","slug":"Windows","permalink":"http://phachon.github.io/tags/Windows/"}]},{"title":"Web 网站的基本工作原理","slug":"network/web-work","date":"2016-07-25T16:00:00.000Z","updated":"2022-07-11T01:59:03.324Z","comments":true,"path":"network/web-work.html","link":"","permalink":"http://phachon.github.io/network/web-work.html","excerpt":"静态页访问 示例：http://www.test.com/index.html 请求步骤： (1) 用户输入需要访问的地址或者具体的网页文件(2) 开始域名解析,会先找到本地的 hosts 文件，然后再找网络上的 DNS 服务器,最终解析到 ip 地址(3) ip 地址所在机器的 Web 服务器接收这个请求，获取请求文件 index.html(4) web 服务器将这个文件的信息返回给用户所用的浏览器(5) 浏览器解析 html 代码，显示出数据 123456Title: 静态网页资源的访问流程图用户-&gt;浏览器:输入资源地址浏览器-&gt;域名解析(DNS):解析 ip域名解析(DNS)-&gt;web 服务器:根据 ip 找到服务器资源web 服务器-&gt;浏览器:返回资源给浏览器浏览器-&gt;用户:解析html显示","text":"静态页访问 示例：http://www.test.com/index.html 请求步骤： (1) 用户输入需要访问的地址或者具体的网页文件(2) 开始域名解析,会先找到本地的 hosts 文件，然后再找网络上的 DNS 服务器,最终解析到 ip 地址(3) ip 地址所在机器的 Web 服务器接收这个请求，获取请求文件 index.html(4) web 服务器将这个文件的信息返回给用户所用的浏览器(5) 浏览器解析 html 代码，显示出数据 123456Title: 静态网页资源的访问流程图用户-&gt;浏览器:输入资源地址浏览器-&gt;域名解析(DNS):解析 ip域名解析(DNS)-&gt;web 服务器:根据 ip 找到服务器资源web 服务器-&gt;浏览器:返回资源给浏览器浏览器-&gt;用户:解析html显示 动态页访问示例：http://www.test.com/test.php 请求步骤： (1) 用户浏览器输入网址以及请求的动态文件的脚本(2) 域名解析，先找本地 hosts ,再找 DNS(3) web 服务器接收请求,获取请求文件 test.php(4) web 服务器将 test.php 交给 php 引擎处理(5) php 引擎解析 php 代码,如果连接了数据库，就调用 mysql 扩展，去操作数据库，最终将解析成 html 文件(6) 将解析的 html 文件返回给 web 服务器(Apache)(7) web服务器返回 test.php 得到的最终 html 文件给浏览器(8) 浏览器解析html代码，显示数据 12345678title:动态网页的访问流程图用户-&gt;浏览器:输入动态脚本地址浏览器-&gt;域名解析(DNS):解析域名域名解析(DNS)-&gt;Web服务器(Apache):ip定位到机器Web服务器(Apache)-&gt;php引擎:发送test.phpphp引擎-&gt;Web服务器(Apache):将解析成html文件返回Web服务器(Apache)-&gt;浏览器:将html返回浏览器-&gt;用户:解析html显示 apache 的工作原理Apache的诸多功能都是通过模块进行加载的，自己本身并不具备那么多能力（功能）,下图以 php 为例 12345678title:Apache 的工作示意图浏览器-&gt;Apache:http://test.com/test.phpApache-&gt;php引擎:test.phpphp引擎-&gt;php扩展:mysql扩展php扩展-&gt;mysql数据库:连接mysqlmysql数据库-&gt;php引擎:返回数据给php引擎php引擎-&gt;Apache:解析成html返回Apache-&gt;浏览器:返回html给浏览器","categories":[{"name":"Network","slug":"Network","permalink":"http://phachon.github.io/categories/Network/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"},{"name":"Apache","slug":"Apache","permalink":"http://phachon.github.io/tags/Apache/"}]},{"title":"CentOS下php安装 mcrypt 扩展","slug":"install/centos-install-php-mcrypt","date":"2016-07-24T16:00:00.000Z","updated":"2022-07-11T01:59:03.321Z","comments":true,"path":"install/centos-install-php-mcrypt.html","link":"","permalink":"http://phachon.github.io/install/centos-install-php-mcrypt.html","excerpt":"源码编译安装需要下载Libmcrypt,mhash,mcrypt安装包 下载地址：http://www.sourceforge.net libmcrypt(libmcrypt-2.5.8.tar.gz ); mcrypt(mcrypt-2.6.8.tar.gz ); mhash(mhash-0.9.9.9.tar.gz ); 123wget &quot;http://downloads.sourceforge.net/mcrypt/libmcrypt-2.5.8.tar.gz&quot;wget &quot;http://downloads.sourceforge.net/mcrypt/mcrypt-2.6.8.tar.gz&quot;wget &quot;http://downloads.sourceforge.net/mhash/mhash-0.9.9.9.tar.gz&quot;","text":"源码编译安装需要下载Libmcrypt,mhash,mcrypt安装包 下载地址：http://www.sourceforge.net libmcrypt(libmcrypt-2.5.8.tar.gz ); mcrypt(mcrypt-2.6.8.tar.gz ); mhash(mhash-0.9.9.9.tar.gz ); 123wget &quot;http://downloads.sourceforge.net/mcrypt/libmcrypt-2.5.8.tar.gz&quot;wget &quot;http://downloads.sourceforge.net/mcrypt/mcrypt-2.6.8.tar.gz&quot;wget &quot;http://downloads.sourceforge.net/mhash/mhash-0.9.9.9.tar.gz&quot; 安装Lmcrypt12345tar -zxvf libmcrypt-2.5.8.tar.gzcd libmcrypt-2.5.8./configuremakemake install #说明：libmcript默认安装在/usr/local 安装mhash12345tar -zxvf mhash-0.9.9.9.tar.gzcd mhash-0.9.9.9./configuremakemake install 安装mcrypt12345tar -zxvf mcrypt-2.6.8.tar.gzcd mcrypt-2.6.8LD_LIBRARY_PATH=/usr/local/lib ./configuremakemake install 安装php的mcrypt扩展(动态加载编译) 下载php下的mcrypt扩展或者直接下载php的完整安装包http://www.php.net/releases/ 网页下找到自己服务器的php版本，下载后tar解压（本人的是php5.3.3） 进入ext/mcrypt文件夹上传 mcrypt文件夹到你服务器的某个目录下然后进入此目录 执行phpize命令（phpize是用来扩展php扩展模块的，通过phpize可以建立php的外挂模块，如果没有？yum install php53-devel里包含了，或者其他方法） 1234567[root@phachon 14:48 mcrypt] whereis phpize #phpize是否存在phpize: /usr/bin/phpize /usr/share/man/man1/phpize.1.gz[root@phachon 14:48 mcrypt] phpizeConfiguring for:PHP Api Version: 20090626Zend Module Api No: 20090626Zend Extension Api No: 220090626 执行完后，会发现当前目录下多了一些configure文件，最后执行php-config命令就基本完成了执行以下命令，确保你的/usr/bin/php-config是存在的 123[root@phachon 15:02 mcrypt] whereis php-configphp-config: /usr/bin/php-config /usr/share/man/man1/php-config.1.gz[root@phachon 15:02 mcrypt] ./configure --with-php-config=/usr/bin/php-config 如果遇到以下错误，请先安装gcc，命令yum install gcc 1configure: error: no acceptable C compiler found in $PATH 直到不报错，出现：config.status: creating config.h，执行以下命令 1[root@phachon 15:06 mcrypt] make &amp;&amp; make install 提示如下，说明你安装成功 1Installing shared extensions: /usr/lib64/php/modules/ 顺便检查下/usr/lib64/php/modules/里的mrcypt.so扩展是否已经创建成功 然后的事就简单了，给你的php.ini添加一条extension=mcrypt.so 1[root@phachon 15:09 mcrypt] cd /etc/php.d 创建一个mrcypt.ini文件就行，里面写extension=mcrypt.so 1[root@phachon 15:17 php.d] echo &#x27;extension=mcrypt.so&#x27; &gt; mcrypt.ini 重启apache，phpinfo()，查看 mcrypt 模块扩展是不是加载了","categories":[{"name":"Install","slug":"Install","permalink":"http://phachon.github.io/categories/Install/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"http://phachon.github.io/tags/CentOS/"},{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"},{"name":"mcrypt","slug":"mcrypt","permalink":"http://phachon.github.io/tags/mcrypt/"}]},{"title":"Lump yum 安装与搭建","slug":"install/lamp-yum-install","date":"2016-07-24T16:00:00.000Z","updated":"2022-07-11T01:59:03.321Z","comments":true,"path":"install/lamp-yum-install.html","link":"","permalink":"http://phachon.github.io/install/lamp-yum-install.html","excerpt":"准备配置防火墙，开启 80，3306 端口打开iptables 1vi /etc/sysconfig/iptables 允许80端口通过防火墙 1-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT 允许3306端口通过防火墙 1-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT 允许21端口通过防火墙1-A INPUT -m state --state NEW -m tcp -p tcp --dport 21 -j ACCEPT","text":"准备配置防火墙，开启 80，3306 端口打开iptables 1vi /etc/sysconfig/iptables 允许80端口通过防火墙 1-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT 允许3306端口通过防火墙 1-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT 允许21端口通过防火墙1-A INPUT -m state --state NEW -m tcp -p tcp --dport 21 -j ACCEPT 备注：把这两条规则添加到防火墙配置的最后一行，导致防火墙启动失败，正确的应该是添加到默认的22端口这条规则的下面 如下所示： 12345678910111213141516#Firewall configuration written by system-config-firewall#Manual customization of this file is not recommended.*filter:INPUT ACCEPT [0:0]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [0:0]-A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT-A INPUT -p icmp -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 21 -j ACCEPT-A INPUT -j REJECT --reject-with icmp-host-prohibited-A FORWARD -j REJECT --reject-with icmp-host-prohibitedCOMMIT 1/etc/init.d/iptables restart #最后重启防火墙使配置生效 关闭SELINUX12345678vi /etc/selinux/configSELINUX=enforcing #注释掉SELINUXTYPE=targeted #注释掉SELINUX=disabled #增加:wq #保存，关闭shutdown -r now #重启系统 安装安装Apache1yum install httpd #根据提示，输入 y 安装即可 1/etc/init.d/httpd start #启动 Apache 备注：Apache 启动后可能会报错： 1正在启动 httpd:httpd: Could not reliably determine the server&#x27;s fully qualif domain name, using ::1 for ServerName 解决办法： 1vi /etc/httpd/conf/httpd.conf 找到 #ServerName www.example.com:80修改为 ServerName www.osyunwei.com:80 #这里设置为你自己的域名，如果没有域名，可以设置为localhost 123:wq! #保存退出chkconfig httpd on #设为开机启动/etc/init.d/httpd restart #重启Apache 安装Mysql安装1yum install mysql mysql-server #询问是否安装，输入Y自动安装 1/etc/init.d/mysqld start #启动MySQL 1chkconfig mysqld on #设为开机启动 1cp /usr/share/mysql/my-medium.cnf /etc/my.cnf #拷贝配置文件（注意：如果/etc目录下面默认有一个my.cnf，直接覆盖即可） 为 root 账户设置密码1mysql_secure_installation 回车，根据提示输入Y输入2次密码，回车根据提示一路输入Y最后出现：Thanks for using MySQL!MySql密码设置完成，重新启动 MySQL： 123/etc/init.d/mysqld restart #重启/etc/init.d/mysqld stop #停止/etc/init.d/mysqld start #启动 安装PHP5(1) 安装 1yum install php #根据提示输入Y直到安装完成 (2) 安装 php 组件，使 PHP5 支持Mysql 1yum install php-mysql php-gd libjpeg* php-imap php-ldap php-odbc php-pear php-xml php-xmlrpc php-mbstring php-mcrypt php-bcmath php-mhash libmcrypt 这里选择以上安装包进行安装根据提示输入Y回车 12/etc/init.d/mysqld restart #重启MySql/etc/init.d/httpd restart #重启Apche 配置Apache 配置1vi /etc/httpd/conf/httpd.conf #编辑 apache 配置文件 12345678910111213ServerTokens OS #在44行 修改为：ServerTokens Prod （在出现错误页的时候不显示服务器操作系统的名称）ServerSignature On #在536行 修改为：ServerSignature Off （在错误页中不显示Apache的版本）Options Indexes FollowSymLinks #在331行 修改为：Options Includes ExecCGI FollowSymLinks #允许服务器执行CGI及SSI，禁止列出目录AddHandler cgi-script .cgi #在796行 修改为：AddHandler cgi-script .cgi .pl （允许扩展名为.pl的CGI脚本运行）AllowOverride None #在338行 修改为：AllowOverride All （允许.htaccess）AddDefaultCharset UTF-8 #在759行 修改为：AddDefaultCharset GB2312 （添加GB2312为默认编码）Options Indexes MultiViews FollowSymLinks #在554行 修改为Options MultiViews FollowSymLinks #不在浏览器上显示树状目录结构DirectoryIndex index.html index.html.var #在402行 修改为DirectoryIndex index.html index.htm Default.html Default.htmindex.php Default.php index.html.var （设置默认首页文件，增加index.php）KeepAlive Off #在76行 修改为：KeepAlive On （允许程序性联机）MaxKeepAliveRequests 100 #在83行 修改为 MaxKeepAliveRequests 1000 （增加同时连接数） 123:wq! #保存退出/etc/init.d/httpd restart #重启rm -f /etc/httpd/conf.d/welcome.conf /var/www/error/noindex.html #删除默认测试页 php 配置1vi /etc/php.ini #编辑 12date.timezone = PRC #在946行 把前面的分号去掉，改为date.timezone = PRCdisable_functions = passthru,exec,system,chroot,scandir,chgrp,chown,shell_exec,proc_open,proc_get_status,ini_alter,ini_alter,ini_restore,dl,openlog,syslog,readlink,symlink,popepassthru,stream_socket_server,escapeshellcmd,dll,popen,disk_free_space,checkdnsrr,checkdnsrr,getservbyname,getservbyport,disk_total_space,posix_ctermid,posix_get_last_error,posix_getcwd, posix_getegid,posix_geteuid,posix_getgid, posix_getgrgid,posix_getgrnam,posix_getgroups,posix_getlogin,posix_getpgid,posix_getpgrp,posix_getpid, posix_getppid,posix_getpwnam,posix_getpwuid, posix_getrlimit, posix_getsid,posix_getuid,posix_isatty, posix_kill,posix_mkfifo,posix_setegid,posix_seteuid,posix_setgid, posix_setpgid,posix_setsid,posix_setuid,posix_strerror,posix_times,posix_ttyname,posix_uname 在386行 列出PHP可以禁用的函数，如果某些程序需要用到这个函数，可以删除，取消禁用。 12345expose_php = Off #在432行 禁止显示php版本的信息magic_quotes_gpc = On #在745行 打开magic_quotes_gpc来防止SQL注入short_open_tag = ON #在229行支持php短标签open_basedir = .:/tmp/ #在380行 设置表示允许访问当前目录(即PHP脚本文件所在之目录)和/tmp/目录,可以防止php木马跨站,如果改了之后安装程序有问题，可以注销此行，或者直接写上程序的目录/data/www.osyunwei.com/:/tmp/:wq! #保存退出 12/etc/init.d/mysqld restart #重启MySql/etc/init.d/httpd restart #重启Apche","categories":[{"name":"Install","slug":"Install","permalink":"http://phachon.github.io/categories/Install/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/tags/Mysql/"},{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"},{"name":"CentOS 6.4","slug":"CentOS-6-4","permalink":"http://phachon.github.io/tags/CentOS-6-4/"},{"name":"Apache","slug":"Apache","permalink":"http://phachon.github.io/tags/Apache/"}]},{"title":"Linux网络配置","slug":"linux/linux-network-config","date":"2016-07-23T16:00:00.000Z","updated":"2022-07-11T01:59:03.322Z","comments":true,"path":"linux/linux-network-config.html","link":"","permalink":"http://phachon.github.io/linux/linux-network-config.html","excerpt":"配置网络信息1vim /etc/sysconfig/network-scripts/ifcfg-eth0 打开ifcfg-eth0这个文件 在这个文件中，保存了第一块网卡的配置信息 DEVICE ：设备名 ONBOOT ：当系统启动后是否自动启动网卡设备 BOOTPROTO ：获取IP方式 static：静态获取 IPADDR ：ip地址 NETMASK ：子网掩码 GATEWAY ：网关","text":"配置网络信息1vim /etc/sysconfig/network-scripts/ifcfg-eth0 打开ifcfg-eth0这个文件 在这个文件中，保存了第一块网卡的配置信息 DEVICE ：设备名 ONBOOT ：当系统启动后是否自动启动网卡设备 BOOTPROTO ：获取IP方式 static：静态获取 IPADDR ：ip地址 NETMASK ：子网掩码 GATEWAY ：网关 如果没有IPADDR ：ip地址则添加IPADDR=自己设置的ip地址修改ONBOOT=”yes” BOOTPROTO=”static”修改完后： :wq 或者 :x 保存退出 启动网络设备(1) service 1service network start|restart|stop (2) ifup、ifdown ifup：启用ifdown：关闭 1ifup eth0 ifdown eth0 测试网络连接(1) ifconfig 查看当前网络设备 (2) ping 说明网络连接成功。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://phachon.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://phachon.github.io/tags/Linux/"},{"name":"CentOS","slug":"CentOS","permalink":"http://phachon.github.io/tags/CentOS/"}]},{"title":"知识点总结系列之：（八）GO","slug":"summary/my_summary_8_go","date":"2015-07-20T16:00:00.000Z","updated":"2022-07-11T01:59:03.327Z","comments":true,"path":"summary/my_summary_8_go.html","link":"","permalink":"http://phachon.github.io/summary/my_summary_8_go.html","excerpt":"","text":"go 相关的知识点总结 Go基本数据类型及占用的字节？ Go 值类型有哪些？ Go 引用类型有哪些？ 常量的声明？ 错误处理？（error, panic, recover） 基本命令（build,get,run,test） 除了 mutex 以外还有那些方式安全读写共享变量？ JSON 标准库对 nil slice 和 空 slice 的处理是一致的吗？ 1.9/1.10中，time.Now()返回的是什么时间？这样做的决定因素是什么? golang的sync.atomic和C++11的atomic最显著的在golang doc里提到的差别在哪里，如何解决或者说规避？ 1.10为止，sync.RWMutex最主要的性能问题最容易在什么常见场景下暴露。有哪些解决或者规避方法？ 如何做一个逻辑正确但golang调度器(1.10)无法正确应对，进而导致无法产生预期结果的程序。调度器如何改进可以解决此问题？ 列出下面操作延迟数量级(1ms, 10us或100ns等)，cgo调用c代码，c调用go代码，channel在单线程单case的select中被选中，high contention下对未满的buffered channel的写延迟。 如何设计实现一个简单的goroutine leak检测库，可用于在测试运行结束后打印出所测试程序泄露的goroutine的stacktrace以及goroutine被创建的文件名和行号。 选择三个常见golang组件（channel, goroutine, [], map, sync.Map等），列举它们常见的严重伤害性能的anti-pattern。 一个C/C++程序需要调用一个go库，某一export了的go函数需高频率调用，且调用间隔需要调用根据go函数的返回调用其它C/C++函数处理，无法改变调用次序、相互依赖关系的前提下，如何最小化这样高频调用的性能损耗？ 不考虑调度器修改本身，仅考虑runtime库的API扩展，如果要给调度器添加NUMA awareness且需要支持不同拓扑，runtime库需要添加哪些函数，哪些函数接口必须改动。 stw的pause绝大多数情况下在100us量级，但有时跳增一个数量级。描述几种可能引起这一现象的触发因素和他们的解决方法。 已经对GC做了较充分优化的程序，在无法减小内存使用量的情况下，如何继续显著减低stw pause长度。 有一个常见说法是“我能用channel简单封装出一个类似sync.Pool功能的实现”。在多线程、high contention、管理不同资源的前提下，两者各方面性能上有哪些显著不同 无缓冲 chan 的发送和接收是否同步？ Data Race问题怎么解决？能不能不加锁解决这个问题？ 使用goroutine以及channel设计TCP链接的消息收发，以及消息处理？ 使用go语言，编写并行计算的快速排序算法？ golang新手可能会踩的50大坑 uint不能直接相减，结果是负数会变成一个很大的uint，这点对动态语言出身的会可能坑 channel一定记得close goroutine记得return或者中断，不然容易造成goroutine占用大量CPU 从slice创建slice的时候，注意原slice的操作可能导致底层数组变化 如果你要创建一个很长的slice，尽量创建成一个slice里存引用，这样可以分批释放，避免gc在低配机器上stop the world 面试的时候尽量了解协程，线程，进程的区别。 什么是channel，为什么它可以做到线程安全？ channel 的实现机制？（通过注册相关goroutine id实现消息通知的） 如何用channel实现一个令牌桶？ 如何调试一个go程序？ 如何写单元测试和基准测试？ slice 底层数据结构的实现？ 抢占式goroutine调用？ 了解读写锁吗，原理是什么样的，为什么可以做到？ golang的内存模型，知道多小才是小对象，为什么小对象多了会造成gc压力？ Devops 用过吗？ golang 采用什么并发模型？体现在哪里？ goroutine 的调度是怎样的？ golang 的内存回收是如何做到的？ cap和len分别获取的是什么？ netgo，cgo有什么区别？ 什么是interface？ 在 Vendor 特性之前包管理工具是怎么实现的？","categories":[{"name":"Summary","slug":"Summary","permalink":"http://phachon.github.io/categories/Summary/"}],"tags":[{"name":"go","slug":"go","permalink":"http://phachon.github.io/tags/go/"}]},{"title":"知识点总结系列之：（七）PHP","slug":"summary/my_summary_7_php","date":"2015-07-19T16:00:00.000Z","updated":"2022-07-11T01:59:03.327Z","comments":true,"path":"summary/my_summary_7_php.html","link":"","permalink":"http://phachon.github.io/summary/my_summary_7_php.html","excerpt":"","text":"php 相关的知识点总结 简述 private、 protected、 public修饰符的访问权限。 使用过的魔术方法有哪些，及如何使用？ __call() 方法的使用场景？ __callStatic() 方法的使用场景？ get() 和 set() 方法的使用场景？ __autoload() 什么时候使用？ 合并两个数组怎么合并？区别？ 有哪些全局变量？并说明这些全局变量的意义？ 数组排序的函数有哪些？区别是什么？ 魔术常量有使用过么？有哪些，并介绍是什么意思？ php 文件处理？ echo print print_r的区别？ mysql_fetch_array() 与mysql_fetch_row()区别？ PHP面向对象中 _set() 与 _construct的作用？ PHP中session与cookie的区别？ PHP中session与cookie的区别？ 什么是PHP的MVC,MVC的作用及原理？ PHP中 include, include_once, require,, require_once 的区别？ php 中字符串使用单引号和双引号的区别？ 字符串常用函数有哪些？ PHP处理数组的常用函数？ PHP处理时间的常用函数？ 如何定义常量？区别是什么？ 定义变量区分大小写吗？定义函数区分大小写吗？ php中函数传递参数的方式有哪些？两者有什么区别？ 堆和栈的区别？ PHP 多态的实现？ 抽象类和接口的概念以及区别？ 什么是构造函数，什么是析构函数，作用是什么？ 如何重载父类的方法，举例说明？ $this和self、parent这三个关键词分别代表什么？在哪些场合下使用？ final关键字能定义类中的成员属性吗？ final关键字定义的类能够被继承吗？ 什么是抽象方法？ 如果一个类是抽象类，而类中的方法都是非抽象的方法，会报错吗？ 如果一个类既要继承一个父类，又要实现多个接口，该如何写？ 什么是 SQL 注入？如何防止 sql 注入？ 分页原理是什么？ php session 共享怎么做？怎么修改？session 相关的函数有哪些？ 正则表达式？ HEREDOC 是什么？ 一些编译php时的configure 参数？ 向php传入参数的三种方法？ error_reporting 等调试函数使用？ Safe_mode 打开后哪些地方受限？ 不用新变量直接交换现有两个变量的值？ PHP 如何获取客户端的IP地址？ 写一个函数，可以遍历文件夹下的所有文件和文件夹。 strlen()与mb_strlen的作用与区别？ 写一个函数，尽可能高效的从一个标准url中取出扩展名？ Isset() 、empty()与is_null的区别？ sessionId 如何保证唯一？ 什么是CSRF攻击？XSS攻击？如何防范？ 请写出自少两个支持回调处理的PHP函数，并自己实现一个支持回调的PHP函数？ PHP 的基本架构 PHP 执行过程 PHP SAPI生命周期 Apache 加载 PHP 模块 Apache 运行过程 PHP 的几种运行方式 PHP 程序的执行过程（内核） PHP5 变量存储结构 PHP7 变量存储优化 PHP5 HashTable 实现 PHP7 HashTable 优化 PHP5 内存管理架构 PHP 垃圾回收机制(refcount__gc, is_ref__gc) PHP-FPM 的优化","categories":[{"name":"Summary","slug":"Summary","permalink":"http://phachon.github.io/categories/Summary/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://phachon.github.io/tags/PHP/"}]},{"title":"知识点总结系列之：（六）网络","slug":"summary/my_summary_6_network","date":"2015-07-18T16:00:00.000Z","updated":"2022-07-11T01:59:03.327Z","comments":true,"path":"summary/my_summary_6_network.html","link":"","permalink":"http://phachon.github.io/summary/my_summary_6_network.html","excerpt":"","text":"网络相关知识点总结 OSI七层模型是什么？哪七层？ TCP/IP 4 层协议栈是哪 4 层？每一层具体的工作是什么，每一层有哪些协议？ TCP 和 UDP 的区别？ TCP 包头的组成？ TCP 网络状态查看？ TCP 的三次握手过程？并描述客户端和服务端状态的变化 为什么要三次握手？如果不是三次有什么问题？ DDOS 攻击了解吗？如何预防 DDOS 攻击？ TCP 四次挥手的过程？ 为什么要四次挥手？否则的话有什么问题？ Time_Wait状态是什么,为什么会有time_wait状态？哪一方会有time_wait状态，如何避免？ time_wait状态占用资源（尽可能的详细）? TCP 包为什么需要 Seq 数据包为什么会乱序？ TCP 如何实现的可靠传输？ TCP 的拥塞控制是怎样的？ TCP 几种拥塞机制的重传机制？ 什么是滑动窗口？ TCP 中客户端发送 SYN 后客户端和服务器分别处在什么状态？ 服务器调用 send 后返回发送数据大小，是否可以认为客户端已收到？如何确保客户端收到数据？ TCP 对网络拥堵的判断？ TCP 和 UDP 分别的使用场景有哪些？ UDP 包头的格式是什么？ UDP 协议的优点和缺点是什么？ 说说 HTTP 协议？ 什么是分块传输编码？ HTTP 和 TCP 有什么关系？ HTTP 1.0 和 HTTP 1.1 的差别？ HTTP pipeline 流水线机制？ 理解 HTTP 2.0 协议吗？ 如何使用 HTTP2.0 协议？ HTTP 头部常见字段有哪些？ 为什么 HTTP 是无连接的？ GET 和 POST 区别？ GET请求中URL编码的意义？ 有没有保持长连接的 HTTP ？ HTTP 常见状态码及原因短语？ 304 状态码的意义？在 HTTP 协议中的实现？ 如何判断服务器文件是否已修改？知道浏览器缓存的文件与服务器文件不一致？在 HTTP 中哪个字段？ Session 和 Cookie 机制？产生原因？对比一下？ 用过 HTTPS 吗？HTTPS 和 HTTP 的区别是什么？ 对称加密与非对称加密区别？ TLS/SSL 协议的握手过程？ CA 证书的签发原理？ SSL 握手需要几个随机数？ HTTPS 性能如何优化？ IP 有几类地址，A 类地址和 B 类地址的区别是什么？ 局域网没有 IP 时如何通信？如何得知 mac 地址？ 什么是网络虚拟化？ 简单描述一下 VPN 工作原理？ 简单描述一下 DNS 工作原理？ 了解代理服务吗？什么是代码服务？ 代理请求的过程？ 代理协议有哪些？ 代理的功能有哪些？ 什么是反向代理？ 反向代理的作用？ 如何抓包？ netstat、tcpdump、ipcs、ipcrm 命令使用过吗？ 大规模连接上来，并发模型怎么设计怎么选择？（并发服务器实现） select, poll 和 epoll 的区别？","categories":[{"name":"Summary","slug":"Summary","permalink":"http://phachon.github.io/categories/Summary/"}],"tags":[{"name":"Network","slug":"Network","permalink":"http://phachon.github.io/tags/Network/"}]},{"title":"知识点总结系列之：（五）架构","slug":"summary/my_summary_5_jiagou","date":"2015-07-17T16:00:00.000Z","updated":"2022-07-11T01:59:03.327Z","comments":true,"path":"summary/my_summary_5_jiagou.html","link":"","permalink":"http://phachon.github.io/summary/my_summary_5_jiagou.html","excerpt":"","text":"架构相关知识点总结 Nginx 的工作原理？ Nginx 的进程模型？ Master 进程工作方式？ Worker 进程的工作方式？ Nginx + Fastcgi 运行原理？ Nginx + PHP-fpm 配置？ Nginx采用多进程模型好处？ Nginx支持的事件模型如下？ Nginx.conf 的优化？ Nginx 为什么高性能？ Apache 的工作原理 Apache 和 Nginx 网络模型比较 什么是Memcache？ Memcache 使用场景？ Memcache 工作原理？ Memcache 内存管理 Memcache 分布式 Memcache 线程管理 Memcached 特性与限制 Redis 和 Memcache 对比方案 单点登录 OAuth2.0 认证 常见设计模式，应用场景 MVC IOC AOP 微服务思想","categories":[{"name":"Summary","slug":"Summary","permalink":"http://phachon.github.io/categories/Summary/"}],"tags":[{"name":"Architecture","slug":"Architecture","permalink":"http://phachon.github.io/tags/Architecture/"}]},{"title":"知识点总结系列之：（四）Redis","slug":"summary/my_summary_4_redis","date":"2015-07-16T16:00:00.000Z","updated":"2022-07-11T01:59:03.327Z","comments":true,"path":"summary/my_summary_4_redis.html","link":"","permalink":"http://phachon.github.io/summary/my_summary_4_redis.html","excerpt":"","text":"Redis 相关知识点总结 为什么使用redis？ 使用redis有什么缺点？ 单线程的redis为什么这么快？ redis的数据类型，以及每种数据类型的使用场景？ redis的过期策略以及内存淘汰机制？ redis和数据库双写一致性问题？ 如何应对缓存穿透问题？ 如何应对缓存雪崩问题？ 如何解决 redis 的并发竞争问题？ redis 底层的数据结构有哪些？各自有什么用？ redis 的主从复制原理？ redis 存储的实现方法？ redis 相对 memcached 有哪些优势？ 如何实现 redis 集群？ redis_cluster 的实现机制？ redis 集群的最大结点个数？ 怎么用 redis 实现分布式锁？ 假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？ 使用过Redis做异步队列么，你是怎么用的？ redis 能不能生产一次消费多次呢？ pub/sub有什么缺点？ redis如何实现延时队列？ 有大量的key需要设置同一时间过期，一般需要注意什么？ Pipeline 有什么好处，为什么要用pipeline？ 为什么redis小等于39字节的字符串是embstr编码，大于39是raw编码？ redis 中 zset 数据结构的实现？ 为什么 zset 用跳表而不用平衡树？ redis 常用配置？ redis 主从复制的实现原理？ redis 内存管理和优化？ redis 持久化方案？","categories":[{"name":"Summary","slug":"Summary","permalink":"http://phachon.github.io/categories/Summary/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://phachon.github.io/tags/Redis/"}]},{"title":"知识点总结系列之：（三）Mysql","slug":"summary/my_summary_3_mysql","date":"2015-07-15T16:00:00.000Z","updated":"2022-07-11T01:59:03.326Z","comments":true,"path":"summary/my_summary_3_mysql.html","link":"","permalink":"http://phachon.github.io/summary/my_summary_3_mysql.html","excerpt":"","text":"MySQL 常见知识点总结 Mysql的技术特点是什么？ MySQL 逻辑架构？每一部门的具体作用？ MySQL 的查询过程？ MySQL 常用的存储引擎有哪些？ Heap 表是什么？ Heap 表的大小可通过称为max_heap_table_size的Mysql配置变量来控制？ InnoDB 存储引擎的特点？ MyISAM 存储引擎的特点？ 一张表，里面有ID自增主键，当insert了17 条记录之后，删除了第15,16,17条记录，再把Mysql重启，再insert一条记录，这条记录的ID是18还是15？ 使用过哪些 Mysql 的索引？ 覆盖索引的使用？ 唯一索引的使用？ Mysql 有哪些锁？ 什么时候会发生表锁？ 什么时候用行锁？ FLOAT 和 DOUBLE 的区别？ CHAR 和 VARCHAR 的区别？ 区分CHAR_LENGTH和LENGTH？ 在 Mysql 中ENUM的用法是什么？ 请简洁描述 Mysql 中InnoDB支持的四种事务隔离级别名称，以及逐级之间的区别？ 如何定义REGEXP？ 列的字符串类型有哪些？ 如何获取当前的 Mysql 版本？ TIMESTAMP在UPDATE CURRENT_TIMESTAMP数据类型上做什么？ 主键和候选键有什么区别？ MyISAMchk是用来做什么的？ MYSQL数据库服务器性能分析的方法命令有哪些？ federated 表是什么？ 如果一个表有一列定义为TIMESTAMP，将发生什么？ 列设置为AUTO INCREMENT时，如果在表中达到最大值，会发生什么情况？ 怎样才能找出最后一次插入时分配了哪个自动增量？ 你怎么看到为表格定义的所有索引？ LIKE声明中的％和_是什么意思？ 如何在Unix和Mysql时间戳之间进行转换？ LIKE和REGEXP操作有什么区别？ BLOB和TEXT有什么区别？ Mysql如何优化DISTINCT？ 可以使用多少列创建索引？ 解释访问控制列表？ MYSQL支持事务吗？ Mysql里记录货币用什么字段类型好？ MYSQL数据表在什么情况下容易损坏？ Mysql中有哪几种锁？如何使用？什么时候发生？ 索引实现机制？ 数据库查询过慢的优化？ 建立 A 列和 B 列的索引需要考虑什么？ 高并发访问 MYSQL 时，如何保持数据一致性？ 什么时候 MySQL 会对表上锁？对一行上锁？ 怎么保证主从服务器中数据库的同步？ 怎么保证数据库同时操作几个表的一致性？ 数据库之间如何同步？ 数据库三大范式？ 字符编码选择？ 熟悉基本 SQL 操作 db 的各种性能指标？ 怎么进行数据库优化？ Mysql 主从复制的原理是什么？ 主从复制中断了怎么办？ 主从复制出现延迟怎么处理？ 主库崩溃了怎么办？ 聚集索引和非聚集索引区别？","categories":[{"name":"Summary","slug":"Summary","permalink":"http://phachon.github.io/categories/Summary/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://phachon.github.io/tags/Mysql/"}]},{"title":"知识点总结系列之：（二）Linux 与操作系统","slug":"summary/my_summary_2_linux","date":"2015-07-14T16:00:00.000Z","updated":"2022-07-11T01:59:03.326Z","comments":true,"path":"summary/my_summary_2_linux.html","link":"","permalink":"http://phachon.github.io/summary/my_summary_2_linux.html","excerpt":"","text":"Linux 与操作系统的知识点总结 操作系统内核 什么是孤儿进程僵尸进程? 指针对应的地址是不是物理地址？ 物理地址和虚拟地址通常叫做什么？缩写是什么？ 操作系统的寻址方式？ Linux 中如何计算可用内存？ Linux 中如何用 top 命令中查看虚地址和实地址的信息？ 如何用搜索引擎去了解 top 中的虚地址？不用搜索引擎怎么知道？ top 的输出中哪些是表明了内存？ 根据 top 计算可用内存有多少？ 用 top 看耗性能的线程？ 还有哪些命令可以找出性能瓶颈？ epoll 与 select 比较？ epoll 的缺点，如何克服缺点？ epoll 机制中文件描述符就绪时如何从内核态通知到用户态的进程？ epoll 实现？ 说说同步异步的区别？ 进程间通信的方式？ 进程间的通信有哪些机制？在资源内存方面比较如何？ 同一进程线程间的通信；不同进程线程间的通信； 如何判断系统在哪些地方耗费性能？ cpu 调度的单位是什么？ 如何让多核 cpu 更好的利用资源？ 什么是缺页？缺页的算法？缺页中断时操作系统怎么做？ 如何控制两个进程对一个数据的访问？怎么处理加锁问题？ 说一说协程？ 是否了解 netstat？ 在 shell 中用 ./a.out | wc- l 结果是多少？管道的输入是哪个进程的？ 谈谈 Linux 的文件权限。让只有拥有者才能读写？让拥有者只能读和执行？ 删除文件需要什么权限？ 假如一个进程在对文件进行读写，管理员把文件删除了怎么办？ 协程与进程线程比较有什么优势？ 计算机从电源加载开始的启动过程？ 什么是中断调用？中断程序的分类？ 内核态和用户态的区别？ 为什么需要内核态？ 什么时候进入内核态？ 多线程需要加锁的变量？ 程序在内存中的布局？ 什么是死锁，如何防止死锁？ lsof作用和使用？ strace作用和使用？ ptrace作用和使用？ 什么是内存管理？ Linux 内存管理的方案有哪些？ 内存池的理解？ 什么是内存泄漏？如何发现内存泄漏？如何避免内存泄漏？ 栈空间的大小？ 操作系统自旋锁？ 进程调度的算法？ 文件被如何加载到内存中？ linux中各种 I/O 模型原理 —— select 和 epoll 阻塞和非阻塞 I/O 区别 linux系统文件机制 多进程同步方式 使用过哪些进程间通讯机制，并详细说明（重点） linux系统的各类异步机制 信号：列出常见的信号，信号怎么处理？ i++ 是否原子操作？ exit() _exit()的区别？ linux的内存管理机制是什么？ linux的任务调度机制是什么？ 系统如何将一个信号通知到进程？ 什么是死锁？如何避免死锁？ 共享内存的使用实现原理？ 多线程和多进程的区别（从cpu调度，上下文切换，数据共享，多核cup利用率，资源占用，等等各方面回答。哪些东西是一个线程私有的？答案中必须包含寄存器）； 标准库函数和系统调用的区别？ 地址空间的栈和堆的大小限制？ 静态库和动态库的区别？ Linux 命令 ln 硬链接和软链接区别？ kill 进程杀不掉的原因？ linux 查看日志文件的方式？ 常用的命令 ls -l -a mkdir (-p) cd touch echo cat cp mv rm (-r,-f) find wc grep rmdir tree pwd ln more,less head,tail 系统管道命令 stat who whoami hostname top ps du df ifconfig ping netstat man clear alias kill 解压缩 gzip bzip tar(c,x,z,j,v,f) 关机重启 shutdown(-r,-h now) halt reboot","categories":[{"name":"Summary","slug":"Summary","permalink":"http://phachon.github.io/categories/Summary/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://phachon.github.io/tags/Linux/"}]},{"title":"知识点总结系列","slug":"summary/my_summary","date":"2015-07-13T16:00:00.000Z","updated":"2022-07-11T01:59:03.326Z","comments":true,"path":"summary/my_summary.html","link":"","permalink":"http://phachon.github.io/summary/my_summary.html","excerpt":"","text":"数据结构与算法 Linux 与操作系统 Mysql Redis 架构 网络 PHP Go","categories":[{"name":"Summary","slug":"Summary","permalink":"http://phachon.github.io/categories/Summary/"}],"tags":[{"name":"dataStructure","slug":"dataStructure","permalink":"http://phachon.github.io/tags/dataStructure/"}]},{"title":"知识点总结系列之：（一）数据结构算法","slug":"summary/my_summary_1_data","date":"2015-07-13T16:00:00.000Z","updated":"2022-07-11T01:59:03.326Z","comments":true,"path":"summary/my_summary_1_data.html","link":"","permalink":"http://phachon.github.io/summary/my_summary_1_data.html","excerpt":"","text":"一些常见的数据结构和算法总结 数据结构 数组和链表的区别？ 链表的一些操作（反转，链表环路判断，双向链表，循环链表）？ 队列的应用？ 栈的应用？ 二叉树的遍历（三种遍历的递归和非递归的实现）？ 二叉树的层序遍历？ AVL 树是什么？ AVL 树的旋转？ 红黑树是什么？ 有哪些地方应用到红黑树？ 红黑树和 AVL 树的比较？ B 树、B+ 树的原理？ 算法 请简单解释算法是什么？ 知道哪些排序算法？ 解释什么是快速排序算法？ 解释算法的时间复杂度？ 有没有 O(n) 的排序算法？ 说明什么是Skip list？ 解释什么是“哈希算法”，它们用于什么？ 列出一些常用的加密算法？ 输出所有和为 S 的连续正数序列。序列内按照从小至大的顺序，序列间按照开始数字从小到大的顺序 字符序列 S=”abcXYZdef”,要求输出循环左移3位后的结果，即“XYZdefabc” 输入一棵二叉树，判断该二叉树是否是平衡二叉树 给定一个二叉树和其中的一个结点，请找出中序遍历顺序的下一个结点并且返回 判断二叉树是否对称 查找字符串中第一个不重复的字符 统计一个数字在排序数组中出现的次数 实现非递归先序、中序、后序遍历二叉树 输入一颗二叉树和一个整数，打印出二叉树中结点值的和为输入整数的所有路径 输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示 用两个栈来实现一个队列，完成队列的 Push 和 Pop 操作 定义栈的数据结构，请在该类型中实现一个能够得到栈最小元素的 main 函数 在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数 请实现一个函数，将一个字符串中的空格替换成“%20” 输入两个单调递增的链表，输出两个链表合成后的链表，当然我们需要合成后的链表满足单调不减规则 输入一个链表，输出该链表中倒数第k个结点 输入两个整数序列，第一个序列表示栈的压入顺序，请判断第二个序列是否为该栈的弹出顺序 从上往下打印出二叉树的每个节点，同层节点从左至右打印 输入一棵二叉树，求该树的深度 给定的二叉树，将其变换为源二叉树的镜像 输入一个矩阵，按照从外向里以顺时针的顺序依次打印出每一个数字 输入两棵二叉树 A，B，判断 B 是不是 A 的子结构。（我们约定空树不是任意一个树的子结构） 输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树 输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，所有的偶数位于位于数组的后半部分，并保证奇数和奇数，偶数和偶数之间的相对位置不变 给定一个 double 类型的浮点数 base 和 int 类型的整数 exponent。求 base 的 exponent 次方 数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字 TopK 问题：输入n个整数，找出其中最小的K个数 在一个字符串(1&lt;=字符串长度&lt;=10000，全部由字母组成)中找到第一个只出现一次的字符,并返回它的位置 从上到下按层打印二叉树，同一层结点从左至右输出 请实现一个函数按照之字形打印二叉树（第一行按照从左到右打印，第二层按照从右至左打印，第三行按照从左到右打印） 一个链表中包含环，请找出该链表的环的入口结点 输入一个链表，反转链表后，输出链表的所有元素 输入一个链表，从尾到头打印链表每个节点的值 大家都知道斐波那契数列，现在要求输入一个整数n，请你输出斐波那契数列的第n项 一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法 假设淘宝一天有5亿条成交数据，求出销量最高的100个商品并给出算法的时间复杂度 有10亿个杂乱无章的数，怎样最快地求出其中前1000大的数 给一列无序数组，求出中位数并给出算法的时间复杂度 输入一个整型数组，求出子数组和的最大值，并给出算法的时间复杂度 给出10W条人和人之间的朋友关系，求出这些朋友关系中有多少个朋友圈（如A-B、B-C、D-E、E-F，这4对关系中存在两个朋友圈），并给出算法的时间复杂度 如图所示的数字三角形，从顶部出发，在每一结点可以选择向左走或得向右走，一直走到底层，要求找出一条路径，使路径上的值的和最大 有一个很长二进制串，求出除以3的余数是多少 答案待补充.","categories":[{"name":"Summary","slug":"Summary","permalink":"http://phachon.github.io/categories/Summary/"}],"tags":[{"name":"dataStructure","slug":"dataStructure","permalink":"http://phachon.github.io/tags/dataStructure/"}]}]}